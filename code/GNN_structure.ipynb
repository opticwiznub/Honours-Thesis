{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ssp_data():\n",
    "    def __init__(self, n=39) -> None:\n",
    "        self.n = n\n",
    "        self.raw = {}\n",
    "        self.init_edge_list(n)\n",
    "        self.y_file = 'data\\\\tas_scenario_245\\\\tas_mon_mod_ssp245_192_000.nc'\n",
    "        self.x_file_list = [item for item in glob('data\\\\tas_scenario_245\\\\tas_mon_mod_ssp245_192_*.nc') if item not in [self.y_file]][0 : self.n]\n",
    "        self.create_df()\n",
    "        self.x = self.x.drop(columns=['tas_9', 'tas_8'])\n",
    "        # self.x_tensor = self.create_tensors(self.x).T\n",
    "        # self.y_tensor = self.create_tensors(self.y)\n",
    "        # self.data = torch_geometric.data.Data(x=self.x_tensor, edge_index=self.edge_index.t().contiguous(), y=self.y_tensor)\n",
    "        # self.split_data()\n",
    "        # self.mini_graphs()\n",
    "\n",
    "    def init_edge_list(self, n):\n",
    "        self.edge_index = []\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                if i != j:\n",
    "                    self.edge_index.append([i, j])\n",
    "        self.edge_index = torch.tensor(self.edge_index, dtype=torch.long)\n",
    "\n",
    "    def create_df(self):\n",
    "        self.x = pd.DataFrame()\n",
    "        i = 1\n",
    "        for filename in self.x_file_list:\n",
    "            print('Processing', filename)\n",
    "            if self.x.empty:\n",
    "                self.x = self.create_vector(filename)\n",
    "            else:\n",
    "                self.x[f'tas_{i}'] = self.create_vector(filename)['tas']\n",
    "                # self.x = self.x.merge(self.create_vector(filename), how='inner', on=['time', 'lat', 'lon'], suffixes=(None, f'_{i}'))\n",
    "            \n",
    "            # print(self.x)\n",
    "            i += 1\n",
    "        \n",
    "        self.y = self.create_vector(self.y_file)['tas']\n",
    "\n",
    "    def create_vector(self, filename):\n",
    "        data = xr.open_dataset(filename)\n",
    "        try:\n",
    "            datetimeindex = data.indexes['time'].to_datetimeindex()\n",
    "            data['time'] = datetimeindex\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        self.raw[filename] = data\n",
    "        df = self.raw[filename].to_dataframe().reset_index()\n",
    "        # for col in ['lat', 'lon', 'tas']:\n",
    "            # df[col] = df[col].round(2)\n",
    "        # self.raw_df[filename] = df\n",
    "        # cftime_1960 = cftime.DatetimeNoLeap(1960, 1, 1, 12, 0, 0, 0, has_year_zero=True)\n",
    "        # cftime_1970 = cftime.DatetimeNoLeap(1970, 12, 30, 12, 0, 0, 0, has_year_zero=True)\n",
    "        # print(df)\n",
    "        df = df.query('lat >= -44 & lat <= -12 & lon >= 288 & lon <= 336')\n",
    "        ret = df[['time', 'lat', 'lon', 'tas']]#.loc[(df['time'].dt.year > 1960) & (df['time'].dt.year < 1980), ['time', 'lat', 'lon', 'tas']]\n",
    "\n",
    "        # print(ret, ret.dtypes)\n",
    "        return ret\n",
    "\n",
    "    \n",
    "    def get_device(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cpu') # don't have GPU \n",
    "        return device\n",
    "\n",
    "    def create_tensors(self, df):\n",
    "        device = self.get_device()\n",
    "        return torch.from_numpy(df.values).float().to(device)\n",
    "    \n",
    "    def mini_graphs(self):\n",
    "        df = self.x\n",
    "        df['x_tensor'] = df.apply(lambda row: torch.tensor(row.values.flatten()), axis=1)\n",
    "        df['y'] = self.y\n",
    "        df['y_tensor'] = df['y'].apply(lambda y: torch.tensor(y))\n",
    "        df['data_obj'] = df.apply(lambda row: torch_geometric.data.Data(x=df['x_tensor'], edge_index=self.edge_index.t().contiguous(), y=df['y_tensor']), axis=1)\n",
    "        self.batch_graphs = df['data_obj']\n",
    "    \n",
    "    def split_data(self):\n",
    "        transform = T.Compose([T.RandomNodeSplit(num_test=1000, num_val=1000)])\n",
    "        self.data = transform(self.data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_001.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_002.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_003.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_004.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_005.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_006.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_007.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_008.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_009.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_010.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\2637710815.py:43: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    }
   ],
   "source": [
    "ssp_data = ssp_data(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_2</th>\n",
       "      <th>tas_3</th>\n",
       "      <th>tas_4</th>\n",
       "      <th>tas_5</th>\n",
       "      <th>tas_6</th>\n",
       "      <th>tas_7</th>\n",
       "      <th>tas_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21861096</th>\n",
       "      <td>1850-01-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>284.172943</td>\n",
       "      <td>280.155243</td>\n",
       "      <td>284.810547</td>\n",
       "      <td>284.570770</td>\n",
       "      <td>284.548645</td>\n",
       "      <td>283.363861</td>\n",
       "      <td>283.986420</td>\n",
       "      <td>283.968140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861097</th>\n",
       "      <td>1850-02-15 00:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>283.968536</td>\n",
       "      <td>281.496246</td>\n",
       "      <td>285.178925</td>\n",
       "      <td>284.472595</td>\n",
       "      <td>284.182495</td>\n",
       "      <td>283.724731</td>\n",
       "      <td>283.756561</td>\n",
       "      <td>285.327301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861098</th>\n",
       "      <td>1850-03-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>283.372498</td>\n",
       "      <td>280.635193</td>\n",
       "      <td>283.098633</td>\n",
       "      <td>280.817993</td>\n",
       "      <td>281.858978</td>\n",
       "      <td>281.619659</td>\n",
       "      <td>281.791290</td>\n",
       "      <td>281.982056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861099</th>\n",
       "      <td>1850-04-16 00:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>280.703217</td>\n",
       "      <td>276.897705</td>\n",
       "      <td>279.815308</td>\n",
       "      <td>278.452454</td>\n",
       "      <td>276.804077</td>\n",
       "      <td>277.914673</td>\n",
       "      <td>277.956970</td>\n",
       "      <td>278.064484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21861100</th>\n",
       "      <td>1850-05-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>277.591003</td>\n",
       "      <td>273.773193</td>\n",
       "      <td>276.833496</td>\n",
       "      <td>275.143402</td>\n",
       "      <td>275.067902</td>\n",
       "      <td>275.281189</td>\n",
       "      <td>275.322113</td>\n",
       "      <td>275.609619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35818699</th>\n",
       "      <td>2100-08-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>296.761230</td>\n",
       "      <td>296.783752</td>\n",
       "      <td>299.635040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.350067</td>\n",
       "      <td>298.096161</td>\n",
       "      <td>298.048889</td>\n",
       "      <td>298.975952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35818700</th>\n",
       "      <td>2100-09-16 00:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>296.622650</td>\n",
       "      <td>296.726624</td>\n",
       "      <td>299.606720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.110535</td>\n",
       "      <td>297.840057</td>\n",
       "      <td>297.826385</td>\n",
       "      <td>298.944855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35818701</th>\n",
       "      <td>2100-10-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>297.122528</td>\n",
       "      <td>297.602753</td>\n",
       "      <td>299.904297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.409607</td>\n",
       "      <td>298.267426</td>\n",
       "      <td>298.292328</td>\n",
       "      <td>299.364166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35818702</th>\n",
       "      <td>2100-11-16 00:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>297.918610</td>\n",
       "      <td>298.609894</td>\n",
       "      <td>300.415588</td>\n",
       "      <td>NaN</td>\n",
       "      <td>299.297119</td>\n",
       "      <td>299.203888</td>\n",
       "      <td>299.236328</td>\n",
       "      <td>300.075256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35818703</th>\n",
       "      <td>2100-12-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>298.721375</td>\n",
       "      <td>299.435089</td>\n",
       "      <td>301.292603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300.391449</td>\n",
       "      <td>300.367432</td>\n",
       "      <td>300.375641</td>\n",
       "      <td>300.736908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1957800 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time     lat      lon         tas       tas_2  \\\n",
       "21861096 1850-01-16 12:00:00 -43.125  288.750  284.172943  280.155243   \n",
       "21861097 1850-02-15 00:00:00 -43.125  288.750  283.968536  281.496246   \n",
       "21861098 1850-03-16 12:00:00 -43.125  288.750  283.372498  280.635193   \n",
       "21861099 1850-04-16 00:00:00 -43.125  288.750  280.703217  276.897705   \n",
       "21861100 1850-05-16 12:00:00 -43.125  288.750  277.591003  273.773193   \n",
       "...                      ...     ...      ...         ...         ...   \n",
       "35818699 2100-08-16 12:00:00 -13.125  335.625  296.761230  296.783752   \n",
       "35818700 2100-09-16 00:00:00 -13.125  335.625  296.622650  296.726624   \n",
       "35818701 2100-10-16 12:00:00 -13.125  335.625  297.122528  297.602753   \n",
       "35818702 2100-11-16 00:00:00 -13.125  335.625  297.918610  298.609894   \n",
       "35818703 2100-12-16 12:00:00 -13.125  335.625  298.721375  299.435089   \n",
       "\n",
       "               tas_3       tas_4       tas_5       tas_6       tas_7  \\\n",
       "21861096  284.810547  284.570770  284.548645  283.363861  283.986420   \n",
       "21861097  285.178925  284.472595  284.182495  283.724731  283.756561   \n",
       "21861098  283.098633  280.817993  281.858978  281.619659  281.791290   \n",
       "21861099  279.815308  278.452454  276.804077  277.914673  277.956970   \n",
       "21861100  276.833496  275.143402  275.067902  275.281189  275.322113   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "35818699  299.635040         NaN  298.350067  298.096161  298.048889   \n",
       "35818700  299.606720         NaN  298.110535  297.840057  297.826385   \n",
       "35818701  299.904297         NaN  298.409607  298.267426  298.292328   \n",
       "35818702  300.415588         NaN  299.297119  299.203888  299.236328   \n",
       "35818703  301.292603         NaN  300.391449  300.367432  300.375641   \n",
       "\n",
       "              tas_10  \n",
       "21861096  283.968140  \n",
       "21861097  285.327301  \n",
       "21861098  281.982056  \n",
       "21861099  278.064484  \n",
       "21861100  275.609619  \n",
       "...              ...  \n",
       "35818699  298.975952  \n",
       "35818700  298.944855  \n",
       "35818701  299.364166  \n",
       "35818702  300.075256  \n",
       "35818703  300.736908  \n",
       "\n",
       "[1957800 rows x 11 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = ssp_data.x.reset_index(drop=True)\n",
    "df['y'] = ssp_data.y\n",
    "df1 = df.query('lat==-43.125 & lon==288.750')\n",
    "df.plot(y=['y', 'tas_5', 'tas_6'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[8, 70200], edge_index=[2, 56], y=[70200])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "70200\n",
      "70200\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for col in ssp_data.x.columns:\n",
    "    print(ssp_data.x[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_2</th>\n",
       "      <th>tas_3</th>\n",
       "      <th>tas_4</th>\n",
       "      <th>tas_5</th>\n",
       "      <th>tas_6</th>\n",
       "      <th>tas_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1964-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>286.610809</td>\n",
       "      <td>279.847229</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1968-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>286.647003</td>\n",
       "      <td>281.439758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1964-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>290.625</td>\n",
       "      <td>289.057434</td>\n",
       "      <td>284.443146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1968-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>290.625</td>\n",
       "      <td>289.101013</td>\n",
       "      <td>286.768890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1964-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>292.500</td>\n",
       "      <td>292.429688</td>\n",
       "      <td>288.975159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69961</th>\n",
       "      <td>1968-02-15 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>331.875</td>\n",
       "      <td>297.861481</td>\n",
       "      <td>300.113892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70021</th>\n",
       "      <td>1964-02-15 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>333.750</td>\n",
       "      <td>297.736603</td>\n",
       "      <td>299.800446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70069</th>\n",
       "      <td>1968-02-15 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>333.750</td>\n",
       "      <td>297.684784</td>\n",
       "      <td>300.062622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70129</th>\n",
       "      <td>1964-02-15 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>297.670563</td>\n",
       "      <td>299.548645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70177</th>\n",
       "      <td>1968-02-15 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>297.402405</td>\n",
       "      <td>299.797913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     time     lat      lon         tas       tas_2  tas_3  \\\n",
       "37    1964-02-15 12:00:00 -43.125  288.750  286.610809  279.847229    NaN   \n",
       "85    1968-02-15 12:00:00 -43.125  288.750  286.647003  281.439758    NaN   \n",
       "145   1964-02-15 12:00:00 -43.125  290.625  289.057434  284.443146    NaN   \n",
       "193   1968-02-15 12:00:00 -43.125  290.625  289.101013  286.768890    NaN   \n",
       "253   1964-02-15 12:00:00 -43.125  292.500  292.429688  288.975159    NaN   \n",
       "...                   ...     ...      ...         ...         ...    ...   \n",
       "69961 1968-02-15 12:00:00 -13.125  331.875  297.861481  300.113892    NaN   \n",
       "70021 1964-02-15 12:00:00 -13.125  333.750  297.736603  299.800446    NaN   \n",
       "70069 1968-02-15 12:00:00 -13.125  333.750  297.684784  300.062622    NaN   \n",
       "70129 1964-02-15 12:00:00 -13.125  335.625  297.670563  299.548645    NaN   \n",
       "70177 1968-02-15 12:00:00 -13.125  335.625  297.402405  299.797913    NaN   \n",
       "\n",
       "       tas_4  tas_5  tas_6  tas_7  \n",
       "37       NaN    NaN    NaN    NaN  \n",
       "85       NaN    NaN    NaN    NaN  \n",
       "145      NaN    NaN    NaN    NaN  \n",
       "193      NaN    NaN    NaN    NaN  \n",
       "253      NaN    NaN    NaN    NaN  \n",
       "...      ...    ...    ...    ...  \n",
       "69961    NaN    NaN    NaN    NaN  \n",
       "70021    NaN    NaN    NaN    NaN  \n",
       "70069    NaN    NaN    NaN    NaN  \n",
       "70129    NaN    NaN    NaN    NaN  \n",
       "70177    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[1300 rows x 10 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_data.x[ssp_data.x.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.edge_weight = torch.nn.Parameter(torch.ones(ssp_data.data.num_edges))\n",
    "        self.conv1 = GCNConv(ssp_data.data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, ssp_data.data.num_node_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        x = self.conv2(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\3127271258.py:11: UserWarning: Using a target size (torch.Size([70200])) that is different to the input size (torch.Size([8, 70200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = F.mse_loss(out, data.y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(85159.6875, grad_fn=<MseLossBackward0>)\n",
      "1 tensor(85159.7266, grad_fn=<MseLossBackward0>)\n",
      "2 tensor(85039.5547, grad_fn=<MseLossBackward0>)\n",
      "3 tensor(1388156.3750, grad_fn=<MseLossBackward0>)\n",
      "4 tensor(70265.1641, grad_fn=<MseLossBackward0>)\n",
      "5 tensor(85030.5078, grad_fn=<MseLossBackward0>)\n",
      "6 tensor(85028.9766, grad_fn=<MseLossBackward0>)\n",
      "7 tensor(85026.9766, grad_fn=<MseLossBackward0>)\n",
      "8 tensor(85024.6016, grad_fn=<MseLossBackward0>)\n",
      "9 tensor(85021.9141, grad_fn=<MseLossBackward0>)\n",
      "10 tensor(85018.9609, grad_fn=<MseLossBackward0>)\n",
      "11 tensor(85015.7812, grad_fn=<MseLossBackward0>)\n",
      "12 tensor(85012.4062, grad_fn=<MseLossBackward0>)\n",
      "13 tensor(85008.8672, grad_fn=<MseLossBackward0>)\n",
      "14 tensor(85005.1719, grad_fn=<MseLossBackward0>)\n",
      "15 tensor(85001.3438, grad_fn=<MseLossBackward0>)\n",
      "16 tensor(84997.3984, grad_fn=<MseLossBackward0>)\n",
      "17 tensor(84993.3516, grad_fn=<MseLossBackward0>)\n",
      "18 tensor(84989.2031, grad_fn=<MseLossBackward0>)\n",
      "19 tensor(84984.9688, grad_fn=<MseLossBackward0>)\n",
      "20 tensor(84980.6641, grad_fn=<MseLossBackward0>)\n",
      "21 tensor(84976.2734, grad_fn=<MseLossBackward0>)\n",
      "22 tensor(84971.8359, grad_fn=<MseLossBackward0>)\n",
      "23 tensor(84967.3359, grad_fn=<MseLossBackward0>)\n",
      "24 tensor(84962.7812, grad_fn=<MseLossBackward0>)\n",
      "25 tensor(84958.1719, grad_fn=<MseLossBackward0>)\n",
      "26 tensor(84953.5234, grad_fn=<MseLossBackward0>)\n",
      "27 tensor(84948.8281, grad_fn=<MseLossBackward0>)\n",
      "28 tensor(84944.0859, grad_fn=<MseLossBackward0>)\n",
      "29 tensor(84939.3281, grad_fn=<MseLossBackward0>)\n",
      "30 tensor(84934.5312, grad_fn=<MseLossBackward0>)\n",
      "31 tensor(84929.7031, grad_fn=<MseLossBackward0>)\n",
      "32 tensor(84924.8359, grad_fn=<MseLossBackward0>)\n",
      "33 tensor(84919.9531, grad_fn=<MseLossBackward0>)\n",
      "34 tensor(84915.0391, grad_fn=<MseLossBackward0>)\n",
      "35 tensor(84910.1094, grad_fn=<MseLossBackward0>)\n",
      "36 tensor(84905.1641, grad_fn=<MseLossBackward0>)\n",
      "37 tensor(84900.1797, grad_fn=<MseLossBackward0>)\n",
      "38 tensor(84895.1953, grad_fn=<MseLossBackward0>)\n",
      "39 tensor(84890.1797, grad_fn=<MseLossBackward0>)\n",
      "40 tensor(84885.1562, grad_fn=<MseLossBackward0>)\n",
      "41 tensor(84880.1172, grad_fn=<MseLossBackward0>)\n",
      "42 tensor(84875.0547, grad_fn=<MseLossBackward0>)\n",
      "43 tensor(84869.9844, grad_fn=<MseLossBackward0>)\n",
      "44 tensor(84864.8984, grad_fn=<MseLossBackward0>)\n",
      "45 tensor(84859.8047, grad_fn=<MseLossBackward0>)\n",
      "46 tensor(84854.7031, grad_fn=<MseLossBackward0>)\n",
      "47 tensor(84849.5703, grad_fn=<MseLossBackward0>)\n",
      "48 tensor(84844.4531, grad_fn=<MseLossBackward0>)\n",
      "49 tensor(84839.3125, grad_fn=<MseLossBackward0>)\n",
      "50 tensor(84834.1641, grad_fn=<MseLossBackward0>)\n",
      "51 tensor(84829.0078, grad_fn=<MseLossBackward0>)\n",
      "52 tensor(84823.8438, grad_fn=<MseLossBackward0>)\n",
      "53 tensor(84818.6641, grad_fn=<MseLossBackward0>)\n",
      "54 tensor(84813.4766, grad_fn=<MseLossBackward0>)\n",
      "55 tensor(84808.2891, grad_fn=<MseLossBackward0>)\n",
      "56 tensor(84803.1016, grad_fn=<MseLossBackward0>)\n",
      "57 tensor(84797.8984, grad_fn=<MseLossBackward0>)\n",
      "58 tensor(84792.6953, grad_fn=<MseLossBackward0>)\n",
      "59 tensor(84787.4766, grad_fn=<MseLossBackward0>)\n",
      "60 tensor(84782.2578, grad_fn=<MseLossBackward0>)\n",
      "61 tensor(84777.0312, grad_fn=<MseLossBackward0>)\n",
      "62 tensor(84771.7969, grad_fn=<MseLossBackward0>)\n",
      "63 tensor(84766.5703, grad_fn=<MseLossBackward0>)\n",
      "64 tensor(84761.3203, grad_fn=<MseLossBackward0>)\n",
      "65 tensor(84756.0781, grad_fn=<MseLossBackward0>)\n",
      "66 tensor(84750.8281, grad_fn=<MseLossBackward0>)\n",
      "67 tensor(84745.5703, grad_fn=<MseLossBackward0>)\n",
      "68 tensor(84740.3125, grad_fn=<MseLossBackward0>)\n",
      "69 tensor(84735.0547, grad_fn=<MseLossBackward0>)\n",
      "70 tensor(84729.7891, grad_fn=<MseLossBackward0>)\n",
      "71 tensor(84724.5156, grad_fn=<MseLossBackward0>)\n",
      "72 tensor(84719.2422, grad_fn=<MseLossBackward0>)\n",
      "73 tensor(84713.9609, grad_fn=<MseLossBackward0>)\n",
      "74 tensor(84708.6875, grad_fn=<MseLossBackward0>)\n",
      "75 tensor(84703.3984, grad_fn=<MseLossBackward0>)\n",
      "76 tensor(84698.1094, grad_fn=<MseLossBackward0>)\n",
      "77 tensor(84692.8203, grad_fn=<MseLossBackward0>)\n",
      "78 tensor(84687.5312, grad_fn=<MseLossBackward0>)\n",
      "79 tensor(84682.2422, grad_fn=<MseLossBackward0>)\n",
      "80 tensor(84676.9375, grad_fn=<MseLossBackward0>)\n",
      "81 tensor(84671.6406, grad_fn=<MseLossBackward0>)\n",
      "82 tensor(84666.3438, grad_fn=<MseLossBackward0>)\n",
      "83 tensor(84661.0391, grad_fn=<MseLossBackward0>)\n",
      "84 tensor(84655.7266, grad_fn=<MseLossBackward0>)\n",
      "85 tensor(84650.4219, grad_fn=<MseLossBackward0>)\n",
      "86 tensor(84645.1094, grad_fn=<MseLossBackward0>)\n",
      "87 tensor(84639.7969, grad_fn=<MseLossBackward0>)\n",
      "88 tensor(84634.4844, grad_fn=<MseLossBackward0>)\n",
      "89 tensor(84629.1641, grad_fn=<MseLossBackward0>)\n",
      "90 tensor(84623.8516, grad_fn=<MseLossBackward0>)\n",
      "91 tensor(84618.5234, grad_fn=<MseLossBackward0>)\n",
      "92 tensor(84613.2109, grad_fn=<MseLossBackward0>)\n",
      "93 tensor(84607.8828, grad_fn=<MseLossBackward0>)\n",
      "94 tensor(84602.5625, grad_fn=<MseLossBackward0>)\n",
      "95 tensor(84597.2344, grad_fn=<MseLossBackward0>)\n",
      "96 tensor(84591.9141, grad_fn=<MseLossBackward0>)\n",
      "97 tensor(84586.5781, grad_fn=<MseLossBackward0>)\n",
      "98 tensor(84581.2578, grad_fn=<MseLossBackward0>)\n",
      "99 tensor(84575.9219, grad_fn=<MseLossBackward0>)\n",
      "100 tensor(84570.5938, grad_fn=<MseLossBackward0>)\n",
      "101 tensor(84565.2578, grad_fn=<MseLossBackward0>)\n",
      "102 tensor(84559.9219, grad_fn=<MseLossBackward0>)\n",
      "103 tensor(84554.5938, grad_fn=<MseLossBackward0>)\n",
      "104 tensor(84549.2578, grad_fn=<MseLossBackward0>)\n",
      "105 tensor(84543.9219, grad_fn=<MseLossBackward0>)\n",
      "106 tensor(84538.5859, grad_fn=<MseLossBackward0>)\n",
      "107 tensor(84533.2422, grad_fn=<MseLossBackward0>)\n",
      "108 tensor(84527.9141, grad_fn=<MseLossBackward0>)\n",
      "109 tensor(84522.5703, grad_fn=<MseLossBackward0>)\n",
      "110 tensor(84517.2344, grad_fn=<MseLossBackward0>)\n",
      "111 tensor(84511.8906, grad_fn=<MseLossBackward0>)\n",
      "112 tensor(84506.5469, grad_fn=<MseLossBackward0>)\n",
      "113 tensor(84501.2109, grad_fn=<MseLossBackward0>)\n",
      "114 tensor(84495.8672, grad_fn=<MseLossBackward0>)\n",
      "115 tensor(84490.5156, grad_fn=<MseLossBackward0>)\n",
      "116 tensor(84485.1797, grad_fn=<MseLossBackward0>)\n",
      "117 tensor(84479.8359, grad_fn=<MseLossBackward0>)\n",
      "118 tensor(84474.5000, grad_fn=<MseLossBackward0>)\n",
      "119 tensor(84469.1641, grad_fn=<MseLossBackward0>)\n",
      "120 tensor(84463.8047, grad_fn=<MseLossBackward0>)\n",
      "121 tensor(84458.4609, grad_fn=<MseLossBackward0>)\n",
      "122 tensor(84453.1250, grad_fn=<MseLossBackward0>)\n",
      "123 tensor(84447.7812, grad_fn=<MseLossBackward0>)\n",
      "124 tensor(84442.4375, grad_fn=<MseLossBackward0>)\n",
      "125 tensor(84437.0938, grad_fn=<MseLossBackward0>)\n",
      "126 tensor(84431.7500, grad_fn=<MseLossBackward0>)\n",
      "127 tensor(84426.3906, grad_fn=<MseLossBackward0>)\n",
      "128 tensor(84421.0547, grad_fn=<MseLossBackward0>)\n",
      "129 tensor(84415.7188, grad_fn=<MseLossBackward0>)\n",
      "130 tensor(84410.3750, grad_fn=<MseLossBackward0>)\n",
      "131 tensor(84405.0234, grad_fn=<MseLossBackward0>)\n",
      "132 tensor(84399.6797, grad_fn=<MseLossBackward0>)\n",
      "133 tensor(84394.3281, grad_fn=<MseLossBackward0>)\n",
      "134 tensor(84388.9922, grad_fn=<MseLossBackward0>)\n",
      "135 tensor(84383.6406, grad_fn=<MseLossBackward0>)\n",
      "136 tensor(84378.2969, grad_fn=<MseLossBackward0>)\n",
      "137 tensor(84372.9609, grad_fn=<MseLossBackward0>)\n",
      "138 tensor(84367.6172, grad_fn=<MseLossBackward0>)\n",
      "139 tensor(84362.2734, grad_fn=<MseLossBackward0>)\n",
      "140 tensor(84356.9297, grad_fn=<MseLossBackward0>)\n",
      "141 tensor(84351.5938, grad_fn=<MseLossBackward0>)\n",
      "142 tensor(84346.2422, grad_fn=<MseLossBackward0>)\n",
      "143 tensor(84340.8984, grad_fn=<MseLossBackward0>)\n",
      "144 tensor(84335.5625, grad_fn=<MseLossBackward0>)\n",
      "145 tensor(84330.2266, grad_fn=<MseLossBackward0>)\n",
      "146 tensor(84324.8828, grad_fn=<MseLossBackward0>)\n",
      "147 tensor(84319.5469, grad_fn=<MseLossBackward0>)\n",
      "148 tensor(84314.2031, grad_fn=<MseLossBackward0>)\n",
      "149 tensor(84308.8672, grad_fn=<MseLossBackward0>)\n",
      "150 tensor(84303.5234, grad_fn=<MseLossBackward0>)\n",
      "151 tensor(84298.1797, grad_fn=<MseLossBackward0>)\n",
      "152 tensor(84292.8516, grad_fn=<MseLossBackward0>)\n",
      "153 tensor(84287.5078, grad_fn=<MseLossBackward0>)\n",
      "154 tensor(84282.1719, grad_fn=<MseLossBackward0>)\n",
      "155 tensor(84276.8359, grad_fn=<MseLossBackward0>)\n",
      "156 tensor(84271.5078, grad_fn=<MseLossBackward0>)\n",
      "157 tensor(84266.1719, grad_fn=<MseLossBackward0>)\n",
      "158 tensor(84260.8281, grad_fn=<MseLossBackward0>)\n",
      "159 tensor(84255.5000, grad_fn=<MseLossBackward0>)\n",
      "160 tensor(84250.1719, grad_fn=<MseLossBackward0>)\n",
      "161 tensor(84244.8281, grad_fn=<MseLossBackward0>)\n",
      "162 tensor(84239.5078, grad_fn=<MseLossBackward0>)\n",
      "163 tensor(84234.1641, grad_fn=<MseLossBackward0>)\n",
      "164 tensor(84228.8438, grad_fn=<MseLossBackward0>)\n",
      "165 tensor(84223.5156, grad_fn=<MseLossBackward0>)\n",
      "166 tensor(84218.1797, grad_fn=<MseLossBackward0>)\n",
      "167 tensor(84212.8516, grad_fn=<MseLossBackward0>)\n",
      "168 tensor(84207.5234, grad_fn=<MseLossBackward0>)\n",
      "169 tensor(84202.2031, grad_fn=<MseLossBackward0>)\n",
      "170 tensor(84196.8750, grad_fn=<MseLossBackward0>)\n",
      "171 tensor(84191.5547, grad_fn=<MseLossBackward0>)\n",
      "172 tensor(84186.2266, grad_fn=<MseLossBackward0>)\n",
      "173 tensor(84180.9062, grad_fn=<MseLossBackward0>)\n",
      "174 tensor(84175.5781, grad_fn=<MseLossBackward0>)\n",
      "175 tensor(84170.2656, grad_fn=<MseLossBackward0>)\n",
      "176 tensor(84164.9375, grad_fn=<MseLossBackward0>)\n",
      "177 tensor(84159.6172, grad_fn=<MseLossBackward0>)\n",
      "178 tensor(84154.2969, grad_fn=<MseLossBackward0>)\n",
      "179 tensor(84148.9766, grad_fn=<MseLossBackward0>)\n",
      "180 tensor(84143.6562, grad_fn=<MseLossBackward0>)\n",
      "181 tensor(84138.3516, grad_fn=<MseLossBackward0>)\n",
      "182 tensor(84133.0234, grad_fn=<MseLossBackward0>)\n",
      "183 tensor(84127.7109, grad_fn=<MseLossBackward0>)\n",
      "184 tensor(84122.4062, grad_fn=<MseLossBackward0>)\n",
      "185 tensor(84117.0938, grad_fn=<MseLossBackward0>)\n",
      "186 tensor(84111.7812, grad_fn=<MseLossBackward0>)\n",
      "187 tensor(84106.4688, grad_fn=<MseLossBackward0>)\n",
      "188 tensor(84101.1562, grad_fn=<MseLossBackward0>)\n",
      "189 tensor(84095.8438, grad_fn=<MseLossBackward0>)\n",
      "190 tensor(84090.5469, grad_fn=<MseLossBackward0>)\n",
      "191 tensor(84085.2422, grad_fn=<MseLossBackward0>)\n",
      "192 tensor(84079.9297, grad_fn=<MseLossBackward0>)\n",
      "193 tensor(84074.6172, grad_fn=<MseLossBackward0>)\n",
      "194 tensor(84069.3203, grad_fn=<MseLossBackward0>)\n",
      "195 tensor(84064.0156, grad_fn=<MseLossBackward0>)\n",
      "196 tensor(84058.7109, grad_fn=<MseLossBackward0>)\n",
      "197 tensor(84053.4062, grad_fn=<MseLossBackward0>)\n",
      "198 tensor(84048.1172, grad_fn=<MseLossBackward0>)\n",
      "199 tensor(84042.8125, grad_fn=<MseLossBackward0>)\n",
      "200 tensor(84037.5234, grad_fn=<MseLossBackward0>)\n",
      "201 tensor(84032.2266, grad_fn=<MseLossBackward0>)\n",
      "202 tensor(84026.9297, grad_fn=<MseLossBackward0>)\n",
      "203 tensor(84021.6328, grad_fn=<MseLossBackward0>)\n",
      "204 tensor(84016.3438, grad_fn=<MseLossBackward0>)\n",
      "205 tensor(84011.0469, grad_fn=<MseLossBackward0>)\n",
      "206 tensor(84005.7656, grad_fn=<MseLossBackward0>)\n",
      "207 tensor(84000.4609, grad_fn=<MseLossBackward0>)\n",
      "208 tensor(83995.1719, grad_fn=<MseLossBackward0>)\n",
      "209 tensor(83989.8984, grad_fn=<MseLossBackward0>)\n",
      "210 tensor(83984.6172, grad_fn=<MseLossBackward0>)\n",
      "211 tensor(83979.3203, grad_fn=<MseLossBackward0>)\n",
      "212 tensor(83974.0391, grad_fn=<MseLossBackward0>)\n",
      "213 tensor(83968.7578, grad_fn=<MseLossBackward0>)\n",
      "214 tensor(83963.4766, grad_fn=<MseLossBackward0>)\n",
      "215 tensor(83958.1953, grad_fn=<MseLossBackward0>)\n",
      "216 tensor(83952.9141, grad_fn=<MseLossBackward0>)\n",
      "217 tensor(83947.6406, grad_fn=<MseLossBackward0>)\n",
      "218 tensor(83942.3594, grad_fn=<MseLossBackward0>)\n",
      "219 tensor(83937.0859, grad_fn=<MseLossBackward0>)\n",
      "220 tensor(83931.8203, grad_fn=<MseLossBackward0>)\n",
      "221 tensor(83926.5469, grad_fn=<MseLossBackward0>)\n",
      "222 tensor(83921.2656, grad_fn=<MseLossBackward0>)\n",
      "223 tensor(83916., grad_fn=<MseLossBackward0>)\n",
      "224 tensor(83910.7266, grad_fn=<MseLossBackward0>)\n",
      "225 tensor(83905.4688, grad_fn=<MseLossBackward0>)\n",
      "226 tensor(83900.2031, grad_fn=<MseLossBackward0>)\n",
      "227 tensor(83894.9219, grad_fn=<MseLossBackward0>)\n",
      "228 tensor(83889.6719, grad_fn=<MseLossBackward0>)\n",
      "229 tensor(83884.4062, grad_fn=<MseLossBackward0>)\n",
      "230 tensor(83879.1328, grad_fn=<MseLossBackward0>)\n",
      "231 tensor(83873.8828, grad_fn=<MseLossBackward0>)\n",
      "232 tensor(83868.6250, grad_fn=<MseLossBackward0>)\n",
      "233 tensor(83863.3594, grad_fn=<MseLossBackward0>)\n",
      "234 tensor(83858.1016, grad_fn=<MseLossBackward0>)\n",
      "235 tensor(83852.8516, grad_fn=<MseLossBackward0>)\n",
      "236 tensor(83847.6016, grad_fn=<MseLossBackward0>)\n",
      "237 tensor(83842.3594, grad_fn=<MseLossBackward0>)\n",
      "238 tensor(83837.0938, grad_fn=<MseLossBackward0>)\n",
      "239 tensor(83831.8594, grad_fn=<MseLossBackward0>)\n",
      "240 tensor(83826.6094, grad_fn=<MseLossBackward0>)\n",
      "241 tensor(83821.3594, grad_fn=<MseLossBackward0>)\n",
      "242 tensor(83816.1172, grad_fn=<MseLossBackward0>)\n",
      "243 tensor(83810.8594, grad_fn=<MseLossBackward0>)\n",
      "244 tensor(83805.6250, grad_fn=<MseLossBackward0>)\n",
      "245 tensor(83800.3828, grad_fn=<MseLossBackward0>)\n",
      "246 tensor(83795.1406, grad_fn=<MseLossBackward0>)\n",
      "247 tensor(83789.8984, grad_fn=<MseLossBackward0>)\n",
      "248 tensor(83784.6719, grad_fn=<MseLossBackward0>)\n",
      "249 tensor(83779.4375, grad_fn=<MseLossBackward0>)\n",
      "250 tensor(83774.1953, grad_fn=<MseLossBackward0>)\n",
      "251 tensor(83768.9688, grad_fn=<MseLossBackward0>)\n",
      "252 tensor(83763.7266, grad_fn=<MseLossBackward0>)\n",
      "253 tensor(83758.4922, grad_fn=<MseLossBackward0>)\n",
      "254 tensor(83753.2656, grad_fn=<MseLossBackward0>)\n",
      "255 tensor(83748.0469, grad_fn=<MseLossBackward0>)\n",
      "256 tensor(83742.8203, grad_fn=<MseLossBackward0>)\n",
      "257 tensor(83737.6016, grad_fn=<MseLossBackward0>)\n",
      "258 tensor(83732.3672, grad_fn=<MseLossBackward0>)\n",
      "259 tensor(83727.1562, grad_fn=<MseLossBackward0>)\n",
      "260 tensor(83721.9297, grad_fn=<MseLossBackward0>)\n",
      "261 tensor(83716.7031, grad_fn=<MseLossBackward0>)\n",
      "262 tensor(83711.4922, grad_fn=<MseLossBackward0>)\n",
      "263 tensor(83706.2812, grad_fn=<MseLossBackward0>)\n",
      "264 tensor(83701.0703, grad_fn=<MseLossBackward0>)\n",
      "265 tensor(83695.8516, grad_fn=<MseLossBackward0>)\n",
      "266 tensor(83690.6406, grad_fn=<MseLossBackward0>)\n",
      "267 tensor(83685.4297, grad_fn=<MseLossBackward0>)\n",
      "268 tensor(83680.2188, grad_fn=<MseLossBackward0>)\n",
      "269 tensor(83675.0078, grad_fn=<MseLossBackward0>)\n",
      "270 tensor(83669.7969, grad_fn=<MseLossBackward0>)\n",
      "271 tensor(83664.6016, grad_fn=<MseLossBackward0>)\n",
      "272 tensor(83659.3984, grad_fn=<MseLossBackward0>)\n",
      "273 tensor(83654.2031, grad_fn=<MseLossBackward0>)\n",
      "274 tensor(83649., grad_fn=<MseLossBackward0>)\n",
      "275 tensor(83643.7969, grad_fn=<MseLossBackward0>)\n",
      "276 tensor(83638.6016, grad_fn=<MseLossBackward0>)\n",
      "277 tensor(83633.3984, grad_fn=<MseLossBackward0>)\n",
      "278 tensor(83628.2109, grad_fn=<MseLossBackward0>)\n",
      "279 tensor(83623.0234, grad_fn=<MseLossBackward0>)\n",
      "280 tensor(83617.8281, grad_fn=<MseLossBackward0>)\n",
      "281 tensor(83612.6406, grad_fn=<MseLossBackward0>)\n",
      "282 tensor(83607.4531, grad_fn=<MseLossBackward0>)\n",
      "283 tensor(83602.2734, grad_fn=<MseLossBackward0>)\n",
      "284 tensor(83597.0938, grad_fn=<MseLossBackward0>)\n",
      "285 tensor(83591.9062, grad_fn=<MseLossBackward0>)\n",
      "286 tensor(83586.7188, grad_fn=<MseLossBackward0>)\n",
      "287 tensor(83581.5312, grad_fn=<MseLossBackward0>)\n",
      "288 tensor(83576.3672, grad_fn=<MseLossBackward0>)\n",
      "289 tensor(83571.1797, grad_fn=<MseLossBackward0>)\n",
      "290 tensor(83566.0156, grad_fn=<MseLossBackward0>)\n",
      "291 tensor(83560.8359, grad_fn=<MseLossBackward0>)\n",
      "292 tensor(83555.6562, grad_fn=<MseLossBackward0>)\n",
      "293 tensor(83550.4922, grad_fn=<MseLossBackward0>)\n",
      "294 tensor(83545.3125, grad_fn=<MseLossBackward0>)\n",
      "295 tensor(83540.1484, grad_fn=<MseLossBackward0>)\n",
      "296 tensor(83534.9844, grad_fn=<MseLossBackward0>)\n",
      "297 tensor(83529.8281, grad_fn=<MseLossBackward0>)\n",
      "298 tensor(83524.6641, grad_fn=<MseLossBackward0>)\n",
      "299 tensor(83519.5000, grad_fn=<MseLossBackward0>)\n",
      "300 tensor(83514.3359, grad_fn=<MseLossBackward0>)\n",
      "301 tensor(83509.1797, grad_fn=<MseLossBackward0>)\n",
      "302 tensor(83504.0234, grad_fn=<MseLossBackward0>)\n",
      "303 tensor(83498.8672, grad_fn=<MseLossBackward0>)\n",
      "304 tensor(83493.7109, grad_fn=<MseLossBackward0>)\n",
      "305 tensor(83488.5547, grad_fn=<MseLossBackward0>)\n",
      "306 tensor(83483.4062, grad_fn=<MseLossBackward0>)\n",
      "307 tensor(83478.2578, grad_fn=<MseLossBackward0>)\n",
      "308 tensor(83473.1094, grad_fn=<MseLossBackward0>)\n",
      "309 tensor(83467.9609, grad_fn=<MseLossBackward0>)\n",
      "310 tensor(83462.8203, grad_fn=<MseLossBackward0>)\n",
      "311 tensor(83457.6797, grad_fn=<MseLossBackward0>)\n",
      "312 tensor(83452.5391, grad_fn=<MseLossBackward0>)\n",
      "313 tensor(83447.3906, grad_fn=<MseLossBackward0>)\n",
      "314 tensor(83442.2578, grad_fn=<MseLossBackward0>)\n",
      "315 tensor(83437.1250, grad_fn=<MseLossBackward0>)\n",
      "316 tensor(83431.9922, grad_fn=<MseLossBackward0>)\n",
      "317 tensor(83426.8516, grad_fn=<MseLossBackward0>)\n",
      "318 tensor(83421.7266, grad_fn=<MseLossBackward0>)\n",
      "319 tensor(83416.5859, grad_fn=<MseLossBackward0>)\n",
      "320 tensor(83411.4688, grad_fn=<MseLossBackward0>)\n",
      "321 tensor(83406.3438, grad_fn=<MseLossBackward0>)\n",
      "322 tensor(83401.2188, grad_fn=<MseLossBackward0>)\n",
      "323 tensor(83396.0938, grad_fn=<MseLossBackward0>)\n",
      "324 tensor(83390.9688, grad_fn=<MseLossBackward0>)\n",
      "325 tensor(83385.8516, grad_fn=<MseLossBackward0>)\n",
      "326 tensor(83380.7344, grad_fn=<MseLossBackward0>)\n",
      "327 tensor(83375.6094, grad_fn=<MseLossBackward0>)\n",
      "328 tensor(83370.4922, grad_fn=<MseLossBackward0>)\n",
      "329 tensor(83365.3828, grad_fn=<MseLossBackward0>)\n",
      "330 tensor(83360.2734, grad_fn=<MseLossBackward0>)\n",
      "331 tensor(83355.1641, grad_fn=<MseLossBackward0>)\n",
      "332 tensor(83350.0469, grad_fn=<MseLossBackward0>)\n",
      "333 tensor(83344.9375, grad_fn=<MseLossBackward0>)\n",
      "334 tensor(83339.8359, grad_fn=<MseLossBackward0>)\n",
      "335 tensor(83334.7344, grad_fn=<MseLossBackward0>)\n",
      "336 tensor(83329.6328, grad_fn=<MseLossBackward0>)\n",
      "337 tensor(83324.5312, grad_fn=<MseLossBackward0>)\n",
      "338 tensor(83319.4375, grad_fn=<MseLossBackward0>)\n",
      "339 tensor(83314.3359, grad_fn=<MseLossBackward0>)\n",
      "340 tensor(83309.2422, grad_fn=<MseLossBackward0>)\n",
      "341 tensor(83304.1406, grad_fn=<MseLossBackward0>)\n",
      "342 tensor(83299.0547, grad_fn=<MseLossBackward0>)\n",
      "343 tensor(83293.9531, grad_fn=<MseLossBackward0>)\n",
      "344 tensor(83288.8672, grad_fn=<MseLossBackward0>)\n",
      "345 tensor(83283.7969, grad_fn=<MseLossBackward0>)\n",
      "346 tensor(83278.6953, grad_fn=<MseLossBackward0>)\n",
      "347 tensor(83273.6094, grad_fn=<MseLossBackward0>)\n",
      "348 tensor(83268.5312, grad_fn=<MseLossBackward0>)\n",
      "349 tensor(83263.4531, grad_fn=<MseLossBackward0>)\n",
      "350 tensor(83258.3672, grad_fn=<MseLossBackward0>)\n",
      "351 tensor(83253.2969, grad_fn=<MseLossBackward0>)\n",
      "352 tensor(83248.2188, grad_fn=<MseLossBackward0>)\n",
      "353 tensor(83243.1484, grad_fn=<MseLossBackward0>)\n",
      "354 tensor(83238.0703, grad_fn=<MseLossBackward0>)\n",
      "355 tensor(83233., grad_fn=<MseLossBackward0>)\n",
      "356 tensor(83227.9375, grad_fn=<MseLossBackward0>)\n",
      "357 tensor(83222.8594, grad_fn=<MseLossBackward0>)\n",
      "358 tensor(83217.7969, grad_fn=<MseLossBackward0>)\n",
      "359 tensor(83212.7344, grad_fn=<MseLossBackward0>)\n",
      "360 tensor(83207.6719, grad_fn=<MseLossBackward0>)\n",
      "361 tensor(83202.6094, grad_fn=<MseLossBackward0>)\n",
      "362 tensor(83197.5469, grad_fn=<MseLossBackward0>)\n",
      "363 tensor(83192.4922, grad_fn=<MseLossBackward0>)\n",
      "364 tensor(83187.4375, grad_fn=<MseLossBackward0>)\n",
      "365 tensor(83182.3828, grad_fn=<MseLossBackward0>)\n",
      "366 tensor(83177.3281, grad_fn=<MseLossBackward0>)\n",
      "367 tensor(83172.2812, grad_fn=<MseLossBackward0>)\n",
      "368 tensor(83167.2344, grad_fn=<MseLossBackward0>)\n",
      "369 tensor(83162.1797, grad_fn=<MseLossBackward0>)\n",
      "370 tensor(83157.1406, grad_fn=<MseLossBackward0>)\n",
      "371 tensor(83152.0938, grad_fn=<MseLossBackward0>)\n",
      "372 tensor(83147.0469, grad_fn=<MseLossBackward0>)\n",
      "373 tensor(83142.0156, grad_fn=<MseLossBackward0>)\n",
      "374 tensor(83136.9766, grad_fn=<MseLossBackward0>)\n",
      "375 tensor(83131.9375, grad_fn=<MseLossBackward0>)\n",
      "376 tensor(83126.9062, grad_fn=<MseLossBackward0>)\n",
      "377 tensor(83121.8672, grad_fn=<MseLossBackward0>)\n",
      "378 tensor(83116.8359, grad_fn=<MseLossBackward0>)\n",
      "379 tensor(83111.8047, grad_fn=<MseLossBackward0>)\n",
      "380 tensor(83106.7734, grad_fn=<MseLossBackward0>)\n",
      "381 tensor(83101.7422, grad_fn=<MseLossBackward0>)\n",
      "382 tensor(83096.7266, grad_fn=<MseLossBackward0>)\n",
      "383 tensor(83091.7031, grad_fn=<MseLossBackward0>)\n",
      "384 tensor(83086.6719, grad_fn=<MseLossBackward0>)\n",
      "385 tensor(83081.6641, grad_fn=<MseLossBackward0>)\n",
      "386 tensor(83076.6484, grad_fn=<MseLossBackward0>)\n",
      "387 tensor(83071.6250, grad_fn=<MseLossBackward0>)\n",
      "388 tensor(83066.6016, grad_fn=<MseLossBackward0>)\n",
      "389 tensor(83061.6016, grad_fn=<MseLossBackward0>)\n",
      "390 tensor(83056.5781, grad_fn=<MseLossBackward0>)\n",
      "391 tensor(83051.5781, grad_fn=<MseLossBackward0>)\n",
      "392 tensor(83046.5625, grad_fn=<MseLossBackward0>)\n",
      "393 tensor(83041.5547, grad_fn=<MseLossBackward0>)\n",
      "394 tensor(83036.5469, grad_fn=<MseLossBackward0>)\n",
      "395 tensor(83031.5547, grad_fn=<MseLossBackward0>)\n",
      "396 tensor(83026.5547, grad_fn=<MseLossBackward0>)\n",
      "397 tensor(83021.5547, grad_fn=<MseLossBackward0>)\n",
      "398 tensor(83016.5547, grad_fn=<MseLossBackward0>)\n",
      "399 tensor(83011.5703, grad_fn=<MseLossBackward0>)\n",
      "400 tensor(83006.5625, grad_fn=<MseLossBackward0>)\n",
      "401 tensor(83001.5703, grad_fn=<MseLossBackward0>)\n",
      "402 tensor(82996.5859, grad_fn=<MseLossBackward0>)\n",
      "403 tensor(82991.5859, grad_fn=<MseLossBackward0>)\n",
      "404 tensor(82986.6094, grad_fn=<MseLossBackward0>)\n",
      "405 tensor(82981.6172, grad_fn=<MseLossBackward0>)\n",
      "406 tensor(82976.6406, grad_fn=<MseLossBackward0>)\n",
      "407 tensor(82971.6562, grad_fn=<MseLossBackward0>)\n",
      "408 tensor(82966.6719, grad_fn=<MseLossBackward0>)\n",
      "409 tensor(82961.6953, grad_fn=<MseLossBackward0>)\n",
      "410 tensor(82956.7188, grad_fn=<MseLossBackward0>)\n",
      "411 tensor(82951.7500, grad_fn=<MseLossBackward0>)\n",
      "412 tensor(82946.7656, grad_fn=<MseLossBackward0>)\n",
      "413 tensor(82941.7969, grad_fn=<MseLossBackward0>)\n",
      "414 tensor(82936.8203, grad_fn=<MseLossBackward0>)\n",
      "415 tensor(82931.8594, grad_fn=<MseLossBackward0>)\n",
      "416 tensor(82926.8906, grad_fn=<MseLossBackward0>)\n",
      "417 tensor(82921.9297, grad_fn=<MseLossBackward0>)\n",
      "418 tensor(82916.9609, grad_fn=<MseLossBackward0>)\n",
      "419 tensor(82912., grad_fn=<MseLossBackward0>)\n",
      "420 tensor(82907.0547, grad_fn=<MseLossBackward0>)\n",
      "421 tensor(82902.1016, grad_fn=<MseLossBackward0>)\n",
      "422 tensor(82897.1328, grad_fn=<MseLossBackward0>)\n",
      "423 tensor(82892.1797, grad_fn=<MseLossBackward0>)\n",
      "424 tensor(82887.2266, grad_fn=<MseLossBackward0>)\n",
      "425 tensor(82882.2734, grad_fn=<MseLossBackward0>)\n",
      "426 tensor(82877.3281, grad_fn=<MseLossBackward0>)\n",
      "427 tensor(82872.3750, grad_fn=<MseLossBackward0>)\n",
      "428 tensor(82867.4297, grad_fn=<MseLossBackward0>)\n",
      "429 tensor(82862.4922, grad_fn=<MseLossBackward0>)\n",
      "430 tensor(82857.5469, grad_fn=<MseLossBackward0>)\n",
      "431 tensor(82852.6094, grad_fn=<MseLossBackward0>)\n",
      "432 tensor(82847.6719, grad_fn=<MseLossBackward0>)\n",
      "433 tensor(82842.7344, grad_fn=<MseLossBackward0>)\n",
      "434 tensor(82837.8047, grad_fn=<MseLossBackward0>)\n",
      "435 tensor(82832.8750, grad_fn=<MseLossBackward0>)\n",
      "436 tensor(82827.9297, grad_fn=<MseLossBackward0>)\n",
      "437 tensor(82823., grad_fn=<MseLossBackward0>)\n",
      "438 tensor(82818.0781, grad_fn=<MseLossBackward0>)\n",
      "439 tensor(82813.1562, grad_fn=<MseLossBackward0>)\n",
      "440 tensor(82808.2344, grad_fn=<MseLossBackward0>)\n",
      "441 tensor(82803.3125, grad_fn=<MseLossBackward0>)\n",
      "442 tensor(82798.3828, grad_fn=<MseLossBackward0>)\n",
      "443 tensor(82793.4688, grad_fn=<MseLossBackward0>)\n",
      "444 tensor(82788.5469, grad_fn=<MseLossBackward0>)\n",
      "445 tensor(82783.6328, grad_fn=<MseLossBackward0>)\n",
      "446 tensor(82778.7344, grad_fn=<MseLossBackward0>)\n",
      "447 tensor(82773.8125, grad_fn=<MseLossBackward0>)\n",
      "448 tensor(82768.8984, grad_fn=<MseLossBackward0>)\n",
      "449 tensor(82763.9922, grad_fn=<MseLossBackward0>)\n",
      "450 tensor(82759.0859, grad_fn=<MseLossBackward0>)\n",
      "451 tensor(82754.1797, grad_fn=<MseLossBackward0>)\n",
      "452 tensor(82749.2891, grad_fn=<MseLossBackward0>)\n",
      "453 tensor(82744.3750, grad_fn=<MseLossBackward0>)\n",
      "454 tensor(82739.4766, grad_fn=<MseLossBackward0>)\n",
      "455 tensor(82734.5781, grad_fn=<MseLossBackward0>)\n",
      "456 tensor(82729.6875, grad_fn=<MseLossBackward0>)\n",
      "457 tensor(82724.7891, grad_fn=<MseLossBackward0>)\n",
      "458 tensor(82719.8984, grad_fn=<MseLossBackward0>)\n",
      "459 tensor(82715.0156, grad_fn=<MseLossBackward0>)\n",
      "460 tensor(82710.1250, grad_fn=<MseLossBackward0>)\n",
      "461 tensor(82705.2344, grad_fn=<MseLossBackward0>)\n",
      "462 tensor(82700.3438, grad_fn=<MseLossBackward0>)\n",
      "463 tensor(82695.4688, grad_fn=<MseLossBackward0>)\n",
      "464 tensor(82690.5781, grad_fn=<MseLossBackward0>)\n",
      "465 tensor(82685.7031, grad_fn=<MseLossBackward0>)\n",
      "466 tensor(82680.8203, grad_fn=<MseLossBackward0>)\n",
      "467 tensor(82675.9531, grad_fn=<MseLossBackward0>)\n",
      "468 tensor(82671.0703, grad_fn=<MseLossBackward0>)\n",
      "469 tensor(82666.2109, grad_fn=<MseLossBackward0>)\n",
      "470 tensor(82661.3359, grad_fn=<MseLossBackward0>)\n",
      "471 tensor(82656.4688, grad_fn=<MseLossBackward0>)\n",
      "472 tensor(82651.6016, grad_fn=<MseLossBackward0>)\n",
      "473 tensor(82646.7266, grad_fn=<MseLossBackward0>)\n",
      "474 tensor(82641.8750, grad_fn=<MseLossBackward0>)\n",
      "475 tensor(82637.0078, grad_fn=<MseLossBackward0>)\n",
      "476 tensor(82632.1641, grad_fn=<MseLossBackward0>)\n",
      "477 tensor(82627.2891, grad_fn=<MseLossBackward0>)\n",
      "478 tensor(82622.4297, grad_fn=<MseLossBackward0>)\n",
      "479 tensor(82617.5781, grad_fn=<MseLossBackward0>)\n",
      "480 tensor(82612.7188, grad_fn=<MseLossBackward0>)\n",
      "481 tensor(82607.8750, grad_fn=<MseLossBackward0>)\n",
      "482 tensor(82603.0312, grad_fn=<MseLossBackward0>)\n",
      "483 tensor(82598.1797, grad_fn=<MseLossBackward0>)\n",
      "484 tensor(82593.3359, grad_fn=<MseLossBackward0>)\n",
      "485 tensor(82588.4922, grad_fn=<MseLossBackward0>)\n",
      "486 tensor(82583.6562, grad_fn=<MseLossBackward0>)\n",
      "487 tensor(82578.8203, grad_fn=<MseLossBackward0>)\n",
      "488 tensor(82573.9766, grad_fn=<MseLossBackward0>)\n",
      "489 tensor(82569.1406, grad_fn=<MseLossBackward0>)\n",
      "490 tensor(82564.3047, grad_fn=<MseLossBackward0>)\n",
      "491 tensor(82559.4609, grad_fn=<MseLossBackward0>)\n",
      "492 tensor(82554.6406, grad_fn=<MseLossBackward0>)\n",
      "493 tensor(82549.8125, grad_fn=<MseLossBackward0>)\n",
      "494 tensor(82544.9844, grad_fn=<MseLossBackward0>)\n",
      "495 tensor(82540.1562, grad_fn=<MseLossBackward0>)\n",
      "496 tensor(82535.3281, grad_fn=<MseLossBackward0>)\n",
      "497 tensor(82530.5156, grad_fn=<MseLossBackward0>)\n",
      "498 tensor(82525.6953, grad_fn=<MseLossBackward0>)\n",
      "499 tensor(82520.8750, grad_fn=<MseLossBackward0>)\n",
      "500 tensor(82516.0547, grad_fn=<MseLossBackward0>)\n",
      "501 tensor(82511.2344, grad_fn=<MseLossBackward0>)\n",
      "502 tensor(82506.4297, grad_fn=<MseLossBackward0>)\n",
      "503 tensor(82501.6172, grad_fn=<MseLossBackward0>)\n",
      "504 tensor(82496.8047, grad_fn=<MseLossBackward0>)\n",
      "505 tensor(82491.9922, grad_fn=<MseLossBackward0>)\n",
      "506 tensor(82487.1953, grad_fn=<MseLossBackward0>)\n",
      "507 tensor(82482.3906, grad_fn=<MseLossBackward0>)\n",
      "508 tensor(82477.5938, grad_fn=<MseLossBackward0>)\n",
      "509 tensor(82472.7969, grad_fn=<MseLossBackward0>)\n",
      "510 tensor(82467.9844, grad_fn=<MseLossBackward0>)\n",
      "511 tensor(82463.1953, grad_fn=<MseLossBackward0>)\n",
      "512 tensor(82458.3984, grad_fn=<MseLossBackward0>)\n",
      "513 tensor(82453.6016, grad_fn=<MseLossBackward0>)\n",
      "514 tensor(82448.8203, grad_fn=<MseLossBackward0>)\n",
      "515 tensor(82444.0234, grad_fn=<MseLossBackward0>)\n",
      "516 tensor(82439.2344, grad_fn=<MseLossBackward0>)\n",
      "517 tensor(82434.4531, grad_fn=<MseLossBackward0>)\n",
      "518 tensor(82429.6641, grad_fn=<MseLossBackward0>)\n",
      "519 tensor(82424.8906, grad_fn=<MseLossBackward0>)\n",
      "520 tensor(82420.1094, grad_fn=<MseLossBackward0>)\n",
      "521 tensor(82415.3281, grad_fn=<MseLossBackward0>)\n",
      "522 tensor(82410.5547, grad_fn=<MseLossBackward0>)\n",
      "523 tensor(82405.7812, grad_fn=<MseLossBackward0>)\n",
      "524 tensor(82401., grad_fn=<MseLossBackward0>)\n",
      "525 tensor(82396.2422, grad_fn=<MseLossBackward0>)\n",
      "526 tensor(82391.4609, grad_fn=<MseLossBackward0>)\n",
      "527 tensor(82386.7031, grad_fn=<MseLossBackward0>)\n",
      "528 tensor(82381.9297, grad_fn=<MseLossBackward0>)\n",
      "529 tensor(82377.1641, grad_fn=<MseLossBackward0>)\n",
      "530 tensor(82372.4062, grad_fn=<MseLossBackward0>)\n",
      "531 tensor(82367.6406, grad_fn=<MseLossBackward0>)\n",
      "532 tensor(82362.8906, grad_fn=<MseLossBackward0>)\n",
      "533 tensor(82358.1328, grad_fn=<MseLossBackward0>)\n",
      "534 tensor(82353.3828, grad_fn=<MseLossBackward0>)\n",
      "535 tensor(82348.6250, grad_fn=<MseLossBackward0>)\n",
      "536 tensor(82343.8750, grad_fn=<MseLossBackward0>)\n",
      "537 tensor(82339.1250, grad_fn=<MseLossBackward0>)\n",
      "538 tensor(82334.3750, grad_fn=<MseLossBackward0>)\n",
      "539 tensor(82329.6328, grad_fn=<MseLossBackward0>)\n",
      "540 tensor(82324.8906, grad_fn=<MseLossBackward0>)\n",
      "541 tensor(82320.1484, grad_fn=<MseLossBackward0>)\n",
      "542 tensor(82315.4062, grad_fn=<MseLossBackward0>)\n",
      "543 tensor(82310.6641, grad_fn=<MseLossBackward0>)\n",
      "544 tensor(82305.9297, grad_fn=<MseLossBackward0>)\n",
      "545 tensor(82301.2031, grad_fn=<MseLossBackward0>)\n",
      "546 tensor(82296.4766, grad_fn=<MseLossBackward0>)\n",
      "547 tensor(82291.7344, grad_fn=<MseLossBackward0>)\n",
      "548 tensor(82287.0078, grad_fn=<MseLossBackward0>)\n",
      "549 tensor(82282.2812, grad_fn=<MseLossBackward0>)\n",
      "550 tensor(82277.5547, grad_fn=<MseLossBackward0>)\n",
      "551 tensor(82272.8281, grad_fn=<MseLossBackward0>)\n",
      "552 tensor(82268.1094, grad_fn=<MseLossBackward0>)\n",
      "553 tensor(82263.3906, grad_fn=<MseLossBackward0>)\n",
      "554 tensor(82258.6797, grad_fn=<MseLossBackward0>)\n",
      "555 tensor(82253.9609, grad_fn=<MseLossBackward0>)\n",
      "556 tensor(82249.2422, grad_fn=<MseLossBackward0>)\n",
      "557 tensor(82244.5312, grad_fn=<MseLossBackward0>)\n",
      "558 tensor(82239.8203, grad_fn=<MseLossBackward0>)\n",
      "559 tensor(82235.1172, grad_fn=<MseLossBackward0>)\n",
      "560 tensor(82230.4062, grad_fn=<MseLossBackward0>)\n",
      "561 tensor(82225.6953, grad_fn=<MseLossBackward0>)\n",
      "562 tensor(82221., grad_fn=<MseLossBackward0>)\n",
      "563 tensor(82216.2969, grad_fn=<MseLossBackward0>)\n",
      "564 tensor(82211.6016, grad_fn=<MseLossBackward0>)\n",
      "565 tensor(82206.8984, grad_fn=<MseLossBackward0>)\n",
      "566 tensor(82202.1953, grad_fn=<MseLossBackward0>)\n",
      "567 tensor(82197.5156, grad_fn=<MseLossBackward0>)\n",
      "568 tensor(82192.8047, grad_fn=<MseLossBackward0>)\n",
      "569 tensor(82188.1328, grad_fn=<MseLossBackward0>)\n",
      "570 tensor(82183.4297, grad_fn=<MseLossBackward0>)\n",
      "571 tensor(82178.7578, grad_fn=<MseLossBackward0>)\n",
      "572 tensor(82174.0703, grad_fn=<MseLossBackward0>)\n",
      "573 tensor(82169.3750, grad_fn=<MseLossBackward0>)\n",
      "574 tensor(82164.7031, grad_fn=<MseLossBackward0>)\n",
      "575 tensor(82160.0312, grad_fn=<MseLossBackward0>)\n",
      "576 tensor(82155.3438, grad_fn=<MseLossBackward0>)\n",
      "577 tensor(82150.6719, grad_fn=<MseLossBackward0>)\n",
      "578 tensor(82145.9922, grad_fn=<MseLossBackward0>)\n",
      "579 tensor(82141.3203, grad_fn=<MseLossBackward0>)\n",
      "580 tensor(82136.6484, grad_fn=<MseLossBackward0>)\n",
      "581 tensor(82131.9844, grad_fn=<MseLossBackward0>)\n",
      "582 tensor(82127.3125, grad_fn=<MseLossBackward0>)\n",
      "583 tensor(82122.6562, grad_fn=<MseLossBackward0>)\n",
      "584 tensor(82117.9844, grad_fn=<MseLossBackward0>)\n",
      "585 tensor(82113.3359, grad_fn=<MseLossBackward0>)\n",
      "586 tensor(82108.6641, grad_fn=<MseLossBackward0>)\n",
      "587 tensor(82104.0234, grad_fn=<MseLossBackward0>)\n",
      "588 tensor(82099.3594, grad_fn=<MseLossBackward0>)\n",
      "589 tensor(82094.7109, grad_fn=<MseLossBackward0>)\n",
      "590 tensor(82090.0625, grad_fn=<MseLossBackward0>)\n",
      "591 tensor(82085.4062, grad_fn=<MseLossBackward0>)\n",
      "592 tensor(82080.7656, grad_fn=<MseLossBackward0>)\n",
      "593 tensor(82076.1250, grad_fn=<MseLossBackward0>)\n",
      "594 tensor(82071.4688, grad_fn=<MseLossBackward0>)\n",
      "595 tensor(82066.8281, grad_fn=<MseLossBackward0>)\n",
      "596 tensor(82062.1953, grad_fn=<MseLossBackward0>)\n",
      "597 tensor(82057.5547, grad_fn=<MseLossBackward0>)\n",
      "598 tensor(82052.9141, grad_fn=<MseLossBackward0>)\n",
      "599 tensor(82048.2812, grad_fn=<MseLossBackward0>)\n",
      "600 tensor(82043.6484, grad_fn=<MseLossBackward0>)\n",
      "601 tensor(82039.0234, grad_fn=<MseLossBackward0>)\n",
      "602 tensor(82034.3828, grad_fn=<MseLossBackward0>)\n",
      "603 tensor(82029.7578, grad_fn=<MseLossBackward0>)\n",
      "604 tensor(82025.1328, grad_fn=<MseLossBackward0>)\n",
      "605 tensor(82020.5078, grad_fn=<MseLossBackward0>)\n",
      "606 tensor(82015.8906, grad_fn=<MseLossBackward0>)\n",
      "607 tensor(82011.2734, grad_fn=<MseLossBackward0>)\n",
      "608 tensor(82006.6562, grad_fn=<MseLossBackward0>)\n",
      "609 tensor(82002.0469, grad_fn=<MseLossBackward0>)\n",
      "610 tensor(81997.4297, grad_fn=<MseLossBackward0>)\n",
      "611 tensor(81992.8125, grad_fn=<MseLossBackward0>)\n",
      "612 tensor(81988.2031, grad_fn=<MseLossBackward0>)\n",
      "613 tensor(81983.5938, grad_fn=<MseLossBackward0>)\n",
      "614 tensor(81978.9844, grad_fn=<MseLossBackward0>)\n",
      "615 tensor(81974.3828, grad_fn=<MseLossBackward0>)\n",
      "616 tensor(81969.7812, grad_fn=<MseLossBackward0>)\n",
      "617 tensor(81965.1719, grad_fn=<MseLossBackward0>)\n",
      "618 tensor(81960.5781, grad_fn=<MseLossBackward0>)\n",
      "619 tensor(81955.9766, grad_fn=<MseLossBackward0>)\n",
      "620 tensor(81951.3828, grad_fn=<MseLossBackward0>)\n",
      "621 tensor(81946.7969, grad_fn=<MseLossBackward0>)\n",
      "622 tensor(81942.1953, grad_fn=<MseLossBackward0>)\n",
      "623 tensor(81937.6094, grad_fn=<MseLossBackward0>)\n",
      "624 tensor(81933.0234, grad_fn=<MseLossBackward0>)\n",
      "625 tensor(81928.4297, grad_fn=<MseLossBackward0>)\n",
      "626 tensor(81923.8516, grad_fn=<MseLossBackward0>)\n",
      "627 tensor(81919.2734, grad_fn=<MseLossBackward0>)\n",
      "628 tensor(81914.6875, grad_fn=<MseLossBackward0>)\n",
      "629 tensor(81910.1016, grad_fn=<MseLossBackward0>)\n",
      "630 tensor(81905.5312, grad_fn=<MseLossBackward0>)\n",
      "631 tensor(81900.9531, grad_fn=<MseLossBackward0>)\n",
      "632 tensor(81896.3750, grad_fn=<MseLossBackward0>)\n",
      "633 tensor(81891.8125, grad_fn=<MseLossBackward0>)\n",
      "634 tensor(81887.2344, grad_fn=<MseLossBackward0>)\n",
      "635 tensor(81882.6719, grad_fn=<MseLossBackward0>)\n",
      "636 tensor(81878.1094, grad_fn=<MseLossBackward0>)\n",
      "637 tensor(81873.5391, grad_fn=<MseLossBackward0>)\n",
      "638 tensor(81868.9844, grad_fn=<MseLossBackward0>)\n",
      "639 tensor(81864.4219, grad_fn=<MseLossBackward0>)\n",
      "640 tensor(81859.8594, grad_fn=<MseLossBackward0>)\n",
      "641 tensor(81855.3047, grad_fn=<MseLossBackward0>)\n",
      "642 tensor(81850.7500, grad_fn=<MseLossBackward0>)\n",
      "643 tensor(81846.2031, grad_fn=<MseLossBackward0>)\n",
      "644 tensor(81841.6562, grad_fn=<MseLossBackward0>)\n",
      "645 tensor(81837.1016, grad_fn=<MseLossBackward0>)\n",
      "646 tensor(81832.5547, grad_fn=<MseLossBackward0>)\n",
      "647 tensor(81828.0156, grad_fn=<MseLossBackward0>)\n",
      "648 tensor(81823.4609, grad_fn=<MseLossBackward0>)\n",
      "649 tensor(81818.9219, grad_fn=<MseLossBackward0>)\n",
      "650 tensor(81814.3828, grad_fn=<MseLossBackward0>)\n",
      "651 tensor(81809.8438, grad_fn=<MseLossBackward0>)\n",
      "652 tensor(81805.3203, grad_fn=<MseLossBackward0>)\n",
      "653 tensor(81800.7812, grad_fn=<MseLossBackward0>)\n",
      "654 tensor(81796.2344, grad_fn=<MseLossBackward0>)\n",
      "655 tensor(81791.7109, grad_fn=<MseLossBackward0>)\n",
      "656 tensor(81787.1797, grad_fn=<MseLossBackward0>)\n",
      "657 tensor(81782.6641, grad_fn=<MseLossBackward0>)\n",
      "658 tensor(81778.1328, grad_fn=<MseLossBackward0>)\n",
      "659 tensor(81773.6094, grad_fn=<MseLossBackward0>)\n",
      "660 tensor(81769.0938, grad_fn=<MseLossBackward0>)\n",
      "661 tensor(81764.5781, grad_fn=<MseLossBackward0>)\n",
      "662 tensor(81760.0547, grad_fn=<MseLossBackward0>)\n",
      "663 tensor(81755.5312, grad_fn=<MseLossBackward0>)\n",
      "664 tensor(81751.0312, grad_fn=<MseLossBackward0>)\n",
      "665 tensor(81746.5078, grad_fn=<MseLossBackward0>)\n",
      "666 tensor(81742.0078, grad_fn=<MseLossBackward0>)\n",
      "667 tensor(81737.4922, grad_fn=<MseLossBackward0>)\n",
      "668 tensor(81732.9922, grad_fn=<MseLossBackward0>)\n",
      "669 tensor(81728.4922, grad_fn=<MseLossBackward0>)\n",
      "670 tensor(81723.9922, grad_fn=<MseLossBackward0>)\n",
      "671 tensor(81719.4844, grad_fn=<MseLossBackward0>)\n",
      "672 tensor(81714.9922, grad_fn=<MseLossBackward0>)\n",
      "673 tensor(81710.4922, grad_fn=<MseLossBackward0>)\n",
      "674 tensor(81706., grad_fn=<MseLossBackward0>)\n",
      "675 tensor(81701.5000, grad_fn=<MseLossBackward0>)\n",
      "676 tensor(81697.0078, grad_fn=<MseLossBackward0>)\n",
      "677 tensor(81692.5312, grad_fn=<MseLossBackward0>)\n",
      "678 tensor(81688.0391, grad_fn=<MseLossBackward0>)\n",
      "679 tensor(81683.5547, grad_fn=<MseLossBackward0>)\n",
      "680 tensor(81679.0703, grad_fn=<MseLossBackward0>)\n",
      "681 tensor(81674.5938, grad_fn=<MseLossBackward0>)\n",
      "682 tensor(81670.1094, grad_fn=<MseLossBackward0>)\n",
      "683 tensor(81665.6328, grad_fn=<MseLossBackward0>)\n",
      "684 tensor(81661.1562, grad_fn=<MseLossBackward0>)\n",
      "685 tensor(81656.6875, grad_fn=<MseLossBackward0>)\n",
      "686 tensor(81652.2109, grad_fn=<MseLossBackward0>)\n",
      "687 tensor(81647.7344, grad_fn=<MseLossBackward0>)\n",
      "688 tensor(81643.2734, grad_fn=<MseLossBackward0>)\n",
      "689 tensor(81638.8047, grad_fn=<MseLossBackward0>)\n",
      "690 tensor(81634.3438, grad_fn=<MseLossBackward0>)\n",
      "691 tensor(81629.8750, grad_fn=<MseLossBackward0>)\n",
      "692 tensor(81625.4141, grad_fn=<MseLossBackward0>)\n",
      "693 tensor(81620.9531, grad_fn=<MseLossBackward0>)\n",
      "694 tensor(81616.5078, grad_fn=<MseLossBackward0>)\n",
      "695 tensor(81612.0469, grad_fn=<MseLossBackward0>)\n",
      "696 tensor(81607.5938, grad_fn=<MseLossBackward0>)\n",
      "697 tensor(81603.1328, grad_fn=<MseLossBackward0>)\n",
      "698 tensor(81598.6953, grad_fn=<MseLossBackward0>)\n",
      "699 tensor(81594.2500, grad_fn=<MseLossBackward0>)\n",
      "700 tensor(81589.7969, grad_fn=<MseLossBackward0>)\n",
      "701 tensor(81585.3516, grad_fn=<MseLossBackward0>)\n",
      "702 tensor(81580.9141, grad_fn=<MseLossBackward0>)\n",
      "703 tensor(81576.4766, grad_fn=<MseLossBackward0>)\n",
      "704 tensor(81572.0469, grad_fn=<MseLossBackward0>)\n",
      "705 tensor(81567.6016, grad_fn=<MseLossBackward0>)\n",
      "706 tensor(81563.1719, grad_fn=<MseLossBackward0>)\n",
      "707 tensor(81558.7344, grad_fn=<MseLossBackward0>)\n",
      "708 tensor(81554.3047, grad_fn=<MseLossBackward0>)\n",
      "709 tensor(81549.8750, grad_fn=<MseLossBackward0>)\n",
      "710 tensor(81545.4453, grad_fn=<MseLossBackward0>)\n",
      "711 tensor(81541.0156, grad_fn=<MseLossBackward0>)\n",
      "712 tensor(81536.6016, grad_fn=<MseLossBackward0>)\n",
      "713 tensor(81532.1797, grad_fn=<MseLossBackward0>)\n",
      "714 tensor(81527.7578, grad_fn=<MseLossBackward0>)\n",
      "715 tensor(81523.3359, grad_fn=<MseLossBackward0>)\n",
      "716 tensor(81518.9297, grad_fn=<MseLossBackward0>)\n",
      "717 tensor(81514.5156, grad_fn=<MseLossBackward0>)\n",
      "718 tensor(81510.1094, grad_fn=<MseLossBackward0>)\n",
      "719 tensor(81505.6953, grad_fn=<MseLossBackward0>)\n",
      "720 tensor(81501.2812, grad_fn=<MseLossBackward0>)\n",
      "721 tensor(81496.8750, grad_fn=<MseLossBackward0>)\n",
      "722 tensor(81492.4766, grad_fn=<MseLossBackward0>)\n",
      "723 tensor(81488.0781, grad_fn=<MseLossBackward0>)\n",
      "724 tensor(81483.6719, grad_fn=<MseLossBackward0>)\n",
      "725 tensor(81479.2734, grad_fn=<MseLossBackward0>)\n",
      "726 tensor(81474.8828, grad_fn=<MseLossBackward0>)\n",
      "727 tensor(81470.4844, grad_fn=<MseLossBackward0>)\n",
      "728 tensor(81466.0859, grad_fn=<MseLossBackward0>)\n",
      "729 tensor(81461.7031, grad_fn=<MseLossBackward0>)\n",
      "730 tensor(81457.3203, grad_fn=<MseLossBackward0>)\n",
      "731 tensor(81452.9297, grad_fn=<MseLossBackward0>)\n",
      "732 tensor(81448.5469, grad_fn=<MseLossBackward0>)\n",
      "733 tensor(81444.1562, grad_fn=<MseLossBackward0>)\n",
      "734 tensor(81439.7812, grad_fn=<MseLossBackward0>)\n",
      "735 tensor(81435.3906, grad_fn=<MseLossBackward0>)\n",
      "736 tensor(81431.0156, grad_fn=<MseLossBackward0>)\n",
      "737 tensor(81426.6406, grad_fn=<MseLossBackward0>)\n",
      "738 tensor(81422.2656, grad_fn=<MseLossBackward0>)\n",
      "739 tensor(81417.8984, grad_fn=<MseLossBackward0>)\n",
      "740 tensor(81413.5312, grad_fn=<MseLossBackward0>)\n",
      "741 tensor(81409.1562, grad_fn=<MseLossBackward0>)\n",
      "742 tensor(81404.7891, grad_fn=<MseLossBackward0>)\n",
      "743 tensor(81400.4297, grad_fn=<MseLossBackward0>)\n",
      "744 tensor(81396.0703, grad_fn=<MseLossBackward0>)\n",
      "745 tensor(81391.7031, grad_fn=<MseLossBackward0>)\n",
      "746 tensor(81387.3438, grad_fn=<MseLossBackward0>)\n",
      "747 tensor(81382.9922, grad_fn=<MseLossBackward0>)\n",
      "748 tensor(81378.6328, grad_fn=<MseLossBackward0>)\n",
      "749 tensor(81374.2734, grad_fn=<MseLossBackward0>)\n",
      "750 tensor(81369.9297, grad_fn=<MseLossBackward0>)\n",
      "751 tensor(81365.5781, grad_fn=<MseLossBackward0>)\n",
      "752 tensor(81361.2266, grad_fn=<MseLossBackward0>)\n",
      "753 tensor(81356.8906, grad_fn=<MseLossBackward0>)\n",
      "754 tensor(81352.5391, grad_fn=<MseLossBackward0>)\n",
      "755 tensor(81348.2031, grad_fn=<MseLossBackward0>)\n",
      "756 tensor(81343.8594, grad_fn=<MseLossBackward0>)\n",
      "757 tensor(81339.5312, grad_fn=<MseLossBackward0>)\n",
      "758 tensor(81335.1797, grad_fn=<MseLossBackward0>)\n",
      "759 tensor(81330.8516, grad_fn=<MseLossBackward0>)\n",
      "760 tensor(81326.5156, grad_fn=<MseLossBackward0>)\n",
      "761 tensor(81322.1875, grad_fn=<MseLossBackward0>)\n",
      "762 tensor(81317.8672, grad_fn=<MseLossBackward0>)\n",
      "763 tensor(81313.5391, grad_fn=<MseLossBackward0>)\n",
      "764 tensor(81309.2031, grad_fn=<MseLossBackward0>)\n",
      "765 tensor(81304.8828, grad_fn=<MseLossBackward0>)\n",
      "766 tensor(81300.5703, grad_fn=<MseLossBackward0>)\n",
      "767 tensor(81296.2500, grad_fn=<MseLossBackward0>)\n",
      "768 tensor(81291.9297, grad_fn=<MseLossBackward0>)\n",
      "769 tensor(81287.6250, grad_fn=<MseLossBackward0>)\n",
      "770 tensor(81283.3047, grad_fn=<MseLossBackward0>)\n",
      "771 tensor(81278.9922, grad_fn=<MseLossBackward0>)\n",
      "772 tensor(81274.6797, grad_fn=<MseLossBackward0>)\n",
      "773 tensor(81270.3828, grad_fn=<MseLossBackward0>)\n",
      "774 tensor(81266.0781, grad_fn=<MseLossBackward0>)\n",
      "775 tensor(81261.7656, grad_fn=<MseLossBackward0>)\n",
      "776 tensor(81257.4609, grad_fn=<MseLossBackward0>)\n",
      "777 tensor(81253.1719, grad_fn=<MseLossBackward0>)\n",
      "778 tensor(81248.8750, grad_fn=<MseLossBackward0>)\n",
      "779 tensor(81244.5703, grad_fn=<MseLossBackward0>)\n",
      "780 tensor(81240.2891, grad_fn=<MseLossBackward0>)\n",
      "781 tensor(81235.9844, grad_fn=<MseLossBackward0>)\n",
      "782 tensor(81231.7031, grad_fn=<MseLossBackward0>)\n",
      "783 tensor(81227.4141, grad_fn=<MseLossBackward0>)\n",
      "784 tensor(81223.1094, grad_fn=<MseLossBackward0>)\n",
      "785 tensor(81218.8359, grad_fn=<MseLossBackward0>)\n",
      "786 tensor(81214.5547, grad_fn=<MseLossBackward0>)\n",
      "787 tensor(81210.2734, grad_fn=<MseLossBackward0>)\n",
      "788 tensor(81205.9922, grad_fn=<MseLossBackward0>)\n",
      "789 tensor(81201.7188, grad_fn=<MseLossBackward0>)\n",
      "790 tensor(81197.4375, grad_fn=<MseLossBackward0>)\n",
      "791 tensor(81193.1797, grad_fn=<MseLossBackward0>)\n",
      "792 tensor(81188.8984, grad_fn=<MseLossBackward0>)\n",
      "793 tensor(81184.6250, grad_fn=<MseLossBackward0>)\n",
      "794 tensor(81180.3672, grad_fn=<MseLossBackward0>)\n",
      "795 tensor(81176.0938, grad_fn=<MseLossBackward0>)\n",
      "796 tensor(81171.8359, grad_fn=<MseLossBackward0>)\n",
      "797 tensor(81167.5703, grad_fn=<MseLossBackward0>)\n",
      "798 tensor(81163.3047, grad_fn=<MseLossBackward0>)\n",
      "799 tensor(81159.0469, grad_fn=<MseLossBackward0>)\n",
      "800 tensor(81154.7969, grad_fn=<MseLossBackward0>)\n",
      "801 tensor(81150.5391, grad_fn=<MseLossBackward0>)\n",
      "802 tensor(81146.2812, grad_fn=<MseLossBackward0>)\n",
      "803 tensor(81142.0469, grad_fn=<MseLossBackward0>)\n",
      "804 tensor(81137.7812, grad_fn=<MseLossBackward0>)\n",
      "805 tensor(81133.5469, grad_fn=<MseLossBackward0>)\n",
      "806 tensor(81129.2969, grad_fn=<MseLossBackward0>)\n",
      "807 tensor(81125.0547, grad_fn=<MseLossBackward0>)\n",
      "808 tensor(81120.8125, grad_fn=<MseLossBackward0>)\n",
      "809 tensor(81116.5859, grad_fn=<MseLossBackward0>)\n",
      "810 tensor(81112.3516, grad_fn=<MseLossBackward0>)\n",
      "811 tensor(81108.1094, grad_fn=<MseLossBackward0>)\n",
      "812 tensor(81103.8750, grad_fn=<MseLossBackward0>)\n",
      "813 tensor(81099.6484, grad_fn=<MseLossBackward0>)\n",
      "814 tensor(81095.4141, grad_fn=<MseLossBackward0>)\n",
      "815 tensor(81091.1875, grad_fn=<MseLossBackward0>)\n",
      "816 tensor(81086.9609, grad_fn=<MseLossBackward0>)\n",
      "817 tensor(81082.7344, grad_fn=<MseLossBackward0>)\n",
      "818 tensor(81078.5078, grad_fn=<MseLossBackward0>)\n",
      "819 tensor(81074.2969, grad_fn=<MseLossBackward0>)\n",
      "820 tensor(81070.0703, grad_fn=<MseLossBackward0>)\n",
      "821 tensor(81065.8672, grad_fn=<MseLossBackward0>)\n",
      "822 tensor(81061.6484, grad_fn=<MseLossBackward0>)\n",
      "823 tensor(81057.4297, grad_fn=<MseLossBackward0>)\n",
      "824 tensor(81053.2266, grad_fn=<MseLossBackward0>)\n",
      "825 tensor(81049.0156, grad_fn=<MseLossBackward0>)\n",
      "826 tensor(81044.8125, grad_fn=<MseLossBackward0>)\n",
      "827 tensor(81040.6016, grad_fn=<MseLossBackward0>)\n",
      "828 tensor(81036.4062, grad_fn=<MseLossBackward0>)\n",
      "829 tensor(81032.1953, grad_fn=<MseLossBackward0>)\n",
      "830 tensor(81028.0078, grad_fn=<MseLossBackward0>)\n",
      "831 tensor(81023.8047, grad_fn=<MseLossBackward0>)\n",
      "832 tensor(81019.6094, grad_fn=<MseLossBackward0>)\n",
      "833 tensor(81015.4219, grad_fn=<MseLossBackward0>)\n",
      "834 tensor(81011.2188, grad_fn=<MseLossBackward0>)\n",
      "835 tensor(81007.0391, grad_fn=<MseLossBackward0>)\n",
      "836 tensor(81002.8516, grad_fn=<MseLossBackward0>)\n",
      "837 tensor(80998.6641, grad_fn=<MseLossBackward0>)\n",
      "838 tensor(80994.4844, grad_fn=<MseLossBackward0>)\n",
      "839 tensor(80990.2969, grad_fn=<MseLossBackward0>)\n",
      "840 tensor(80986.1172, grad_fn=<MseLossBackward0>)\n",
      "841 tensor(80981.9375, grad_fn=<MseLossBackward0>)\n",
      "842 tensor(80977.7734, grad_fn=<MseLossBackward0>)\n",
      "843 tensor(80973.5938, grad_fn=<MseLossBackward0>)\n",
      "844 tensor(80969.4219, grad_fn=<MseLossBackward0>)\n",
      "845 tensor(80965.2500, grad_fn=<MseLossBackward0>)\n",
      "846 tensor(80961.0859, grad_fn=<MseLossBackward0>)\n",
      "847 tensor(80956.9141, grad_fn=<MseLossBackward0>)\n",
      "848 tensor(80952.7578, grad_fn=<MseLossBackward0>)\n",
      "849 tensor(80948.5859, grad_fn=<MseLossBackward0>)\n",
      "850 tensor(80944.4297, grad_fn=<MseLossBackward0>)\n",
      "851 tensor(80940.2734, grad_fn=<MseLossBackward0>)\n",
      "852 tensor(80936.1172, grad_fn=<MseLossBackward0>)\n",
      "853 tensor(80931.9531, grad_fn=<MseLossBackward0>)\n",
      "854 tensor(80927.8125, grad_fn=<MseLossBackward0>)\n",
      "855 tensor(80923.6562, grad_fn=<MseLossBackward0>)\n",
      "856 tensor(80919.5078, grad_fn=<MseLossBackward0>)\n",
      "857 tensor(80915.3594, grad_fn=<MseLossBackward0>)\n",
      "858 tensor(80911.2031, grad_fn=<MseLossBackward0>)\n",
      "859 tensor(80907.0703, grad_fn=<MseLossBackward0>)\n",
      "860 tensor(80902.9297, grad_fn=<MseLossBackward0>)\n",
      "861 tensor(80898.7969, grad_fn=<MseLossBackward0>)\n",
      "862 tensor(80894.6484, grad_fn=<MseLossBackward0>)\n",
      "863 tensor(80890.5156, grad_fn=<MseLossBackward0>)\n",
      "864 tensor(80886.3906, grad_fn=<MseLossBackward0>)\n",
      "865 tensor(80882.2422, grad_fn=<MseLossBackward0>)\n",
      "866 tensor(80878.1172, grad_fn=<MseLossBackward0>)\n",
      "867 tensor(80873.9922, grad_fn=<MseLossBackward0>)\n",
      "868 tensor(80869.8594, grad_fn=<MseLossBackward0>)\n",
      "869 tensor(80865.7422, grad_fn=<MseLossBackward0>)\n",
      "870 tensor(80861.6250, grad_fn=<MseLossBackward0>)\n",
      "871 tensor(80857.4922, grad_fn=<MseLossBackward0>)\n",
      "872 tensor(80853.3750, grad_fn=<MseLossBackward0>)\n",
      "873 tensor(80849.2656, grad_fn=<MseLossBackward0>)\n",
      "874 tensor(80845.1406, grad_fn=<MseLossBackward0>)\n",
      "875 tensor(80841.0312, grad_fn=<MseLossBackward0>)\n",
      "876 tensor(80836.9219, grad_fn=<MseLossBackward0>)\n",
      "877 tensor(80832.8203, grad_fn=<MseLossBackward0>)\n",
      "878 tensor(80828.7109, grad_fn=<MseLossBackward0>)\n",
      "879 tensor(80824.6016, grad_fn=<MseLossBackward0>)\n",
      "880 tensor(80820.5078, grad_fn=<MseLossBackward0>)\n",
      "881 tensor(80816.3984, grad_fn=<MseLossBackward0>)\n",
      "882 tensor(80812.2969, grad_fn=<MseLossBackward0>)\n",
      "883 tensor(80808.2031, grad_fn=<MseLossBackward0>)\n",
      "884 tensor(80804.1016, grad_fn=<MseLossBackward0>)\n",
      "885 tensor(80800.0078, grad_fn=<MseLossBackward0>)\n",
      "886 tensor(80795.9219, grad_fn=<MseLossBackward0>)\n",
      "887 tensor(80791.8281, grad_fn=<MseLossBackward0>)\n",
      "888 tensor(80787.7422, grad_fn=<MseLossBackward0>)\n",
      "889 tensor(80783.6484, grad_fn=<MseLossBackward0>)\n",
      "890 tensor(80779.5781, grad_fn=<MseLossBackward0>)\n",
      "891 tensor(80775.4922, grad_fn=<MseLossBackward0>)\n",
      "892 tensor(80771.4141, grad_fn=<MseLossBackward0>)\n",
      "893 tensor(80767.3281, grad_fn=<MseLossBackward0>)\n",
      "894 tensor(80763.2578, grad_fn=<MseLossBackward0>)\n",
      "895 tensor(80759.1875, grad_fn=<MseLossBackward0>)\n",
      "896 tensor(80755.1094, grad_fn=<MseLossBackward0>)\n",
      "897 tensor(80751.0391, grad_fn=<MseLossBackward0>)\n",
      "898 tensor(80746.9688, grad_fn=<MseLossBackward0>)\n",
      "899 tensor(80742.9062, grad_fn=<MseLossBackward0>)\n",
      "900 tensor(80738.8359, grad_fn=<MseLossBackward0>)\n",
      "901 tensor(80734.7812, grad_fn=<MseLossBackward0>)\n",
      "902 tensor(80730.7266, grad_fn=<MseLossBackward0>)\n",
      "903 tensor(80726.6562, grad_fn=<MseLossBackward0>)\n",
      "904 tensor(80722.6016, grad_fn=<MseLossBackward0>)\n",
      "905 tensor(80718.5469, grad_fn=<MseLossBackward0>)\n",
      "906 tensor(80714.4922, grad_fn=<MseLossBackward0>)\n",
      "907 tensor(80710.4375, grad_fn=<MseLossBackward0>)\n",
      "908 tensor(80706.3906, grad_fn=<MseLossBackward0>)\n",
      "909 tensor(80702.3438, grad_fn=<MseLossBackward0>)\n",
      "910 tensor(80698.3047, grad_fn=<MseLossBackward0>)\n",
      "911 tensor(80694.2578, grad_fn=<MseLossBackward0>)\n",
      "912 tensor(80690.2109, grad_fn=<MseLossBackward0>)\n",
      "913 tensor(80686.1719, grad_fn=<MseLossBackward0>)\n",
      "914 tensor(80682.1250, grad_fn=<MseLossBackward0>)\n",
      "915 tensor(80678.1016, grad_fn=<MseLossBackward0>)\n",
      "916 tensor(80674.0703, grad_fn=<MseLossBackward0>)\n",
      "917 tensor(80670.0312, grad_fn=<MseLossBackward0>)\n",
      "918 tensor(80666.0078, grad_fn=<MseLossBackward0>)\n",
      "919 tensor(80661.9766, grad_fn=<MseLossBackward0>)\n",
      "920 tensor(80657.9453, grad_fn=<MseLossBackward0>)\n",
      "921 tensor(80653.9219, grad_fn=<MseLossBackward0>)\n",
      "922 tensor(80649.9062, grad_fn=<MseLossBackward0>)\n",
      "923 tensor(80645.8750, grad_fn=<MseLossBackward0>)\n",
      "924 tensor(80641.8672, grad_fn=<MseLossBackward0>)\n",
      "925 tensor(80637.8594, grad_fn=<MseLossBackward0>)\n",
      "926 tensor(80633.8281, grad_fn=<MseLossBackward0>)\n",
      "927 tensor(80629.8203, grad_fn=<MseLossBackward0>)\n",
      "928 tensor(80625.8047, grad_fn=<MseLossBackward0>)\n",
      "929 tensor(80621.7969, grad_fn=<MseLossBackward0>)\n",
      "930 tensor(80617.7812, grad_fn=<MseLossBackward0>)\n",
      "931 tensor(80613.7891, grad_fn=<MseLossBackward0>)\n",
      "932 tensor(80609.7891, grad_fn=<MseLossBackward0>)\n",
      "933 tensor(80605.7812, grad_fn=<MseLossBackward0>)\n",
      "934 tensor(80601.7812, grad_fn=<MseLossBackward0>)\n",
      "935 tensor(80597.7891, grad_fn=<MseLossBackward0>)\n",
      "936 tensor(80593.7891, grad_fn=<MseLossBackward0>)\n",
      "937 tensor(80589.7891, grad_fn=<MseLossBackward0>)\n",
      "938 tensor(80585.8125, grad_fn=<MseLossBackward0>)\n",
      "939 tensor(80581.8125, grad_fn=<MseLossBackward0>)\n",
      "940 tensor(80577.8203, grad_fn=<MseLossBackward0>)\n",
      "941 tensor(80573.8516, grad_fn=<MseLossBackward0>)\n",
      "942 tensor(80569.8594, grad_fn=<MseLossBackward0>)\n",
      "943 tensor(80565.8672, grad_fn=<MseLossBackward0>)\n",
      "944 tensor(80561.8906, grad_fn=<MseLossBackward0>)\n",
      "945 tensor(80557.9062, grad_fn=<MseLossBackward0>)\n",
      "946 tensor(80553.9375, grad_fn=<MseLossBackward0>)\n",
      "947 tensor(80549.9688, grad_fn=<MseLossBackward0>)\n",
      "948 tensor(80546., grad_fn=<MseLossBackward0>)\n",
      "949 tensor(80542.0234, grad_fn=<MseLossBackward0>)\n",
      "950 tensor(80538.0547, grad_fn=<MseLossBackward0>)\n",
      "951 tensor(80534.0938, grad_fn=<MseLossBackward0>)\n",
      "952 tensor(80530.1250, grad_fn=<MseLossBackward0>)\n",
      "953 tensor(80526.1562, grad_fn=<MseLossBackward0>)\n",
      "954 tensor(80522.2031, grad_fn=<MseLossBackward0>)\n",
      "955 tensor(80518.2422, grad_fn=<MseLossBackward0>)\n",
      "956 tensor(80514.2812, grad_fn=<MseLossBackward0>)\n",
      "957 tensor(80510.3281, grad_fn=<MseLossBackward0>)\n",
      "958 tensor(80506.3672, grad_fn=<MseLossBackward0>)\n",
      "959 tensor(80502.4219, grad_fn=<MseLossBackward0>)\n",
      "960 tensor(80498.4688, grad_fn=<MseLossBackward0>)\n",
      "961 tensor(80494.5312, grad_fn=<MseLossBackward0>)\n",
      "962 tensor(80490.5781, grad_fn=<MseLossBackward0>)\n",
      "963 tensor(80486.6328, grad_fn=<MseLossBackward0>)\n",
      "964 tensor(80482.6953, grad_fn=<MseLossBackward0>)\n",
      "965 tensor(80478.7578, grad_fn=<MseLossBackward0>)\n",
      "966 tensor(80474.8203, grad_fn=<MseLossBackward0>)\n",
      "967 tensor(80470.8828, grad_fn=<MseLossBackward0>)\n",
      "968 tensor(80466.9453, grad_fn=<MseLossBackward0>)\n",
      "969 tensor(80463.0156, grad_fn=<MseLossBackward0>)\n",
      "970 tensor(80459.0859, grad_fn=<MseLossBackward0>)\n",
      "971 tensor(80455.1641, grad_fn=<MseLossBackward0>)\n",
      "972 tensor(80451.2344, grad_fn=<MseLossBackward0>)\n",
      "973 tensor(80447.3047, grad_fn=<MseLossBackward0>)\n",
      "974 tensor(80443.3906, grad_fn=<MseLossBackward0>)\n",
      "975 tensor(80439.4688, grad_fn=<MseLossBackward0>)\n",
      "976 tensor(80435.5391, grad_fn=<MseLossBackward0>)\n",
      "977 tensor(80431.6250, grad_fn=<MseLossBackward0>)\n",
      "978 tensor(80427.7188, grad_fn=<MseLossBackward0>)\n",
      "979 tensor(80423.8047, grad_fn=<MseLossBackward0>)\n",
      "980 tensor(80419.8906, grad_fn=<MseLossBackward0>)\n",
      "981 tensor(80415.9844, grad_fn=<MseLossBackward0>)\n",
      "982 tensor(80412.0781, grad_fn=<MseLossBackward0>)\n",
      "983 tensor(80408.1719, grad_fn=<MseLossBackward0>)\n",
      "984 tensor(80404.2734, grad_fn=<MseLossBackward0>)\n",
      "985 tensor(80400.3828, grad_fn=<MseLossBackward0>)\n",
      "986 tensor(80396.4688, grad_fn=<MseLossBackward0>)\n",
      "987 tensor(80392.5781, grad_fn=<MseLossBackward0>)\n",
      "988 tensor(80388.6797, grad_fn=<MseLossBackward0>)\n",
      "989 tensor(80384.7812, grad_fn=<MseLossBackward0>)\n",
      "990 tensor(80380.8906, grad_fn=<MseLossBackward0>)\n",
      "991 tensor(80377., grad_fn=<MseLossBackward0>)\n",
      "992 tensor(80373.1172, grad_fn=<MseLossBackward0>)\n",
      "993 tensor(80369.2344, grad_fn=<MseLossBackward0>)\n",
      "994 tensor(80365.3438, grad_fn=<MseLossBackward0>)\n",
      "995 tensor(80361.4609, grad_fn=<MseLossBackward0>)\n",
      "996 tensor(80357.5859, grad_fn=<MseLossBackward0>)\n",
      "997 tensor(80353.7031, grad_fn=<MseLossBackward0>)\n",
      "998 tensor(80349.8359, grad_fn=<MseLossBackward0>)\n",
      "999 tensor(80345.9609, grad_fn=<MseLossBackward0>)\n",
      "1000 tensor(80342.0859, grad_fn=<MseLossBackward0>)\n",
      "1001 tensor(80338.2109, grad_fn=<MseLossBackward0>)\n",
      "1002 tensor(80334.3438, grad_fn=<MseLossBackward0>)\n",
      "1003 tensor(80330.4844, grad_fn=<MseLossBackward0>)\n",
      "1004 tensor(80326.6172, grad_fn=<MseLossBackward0>)\n",
      "1005 tensor(80322.7500, grad_fn=<MseLossBackward0>)\n",
      "1006 tensor(80318.8906, grad_fn=<MseLossBackward0>)\n",
      "1007 tensor(80315.0312, grad_fn=<MseLossBackward0>)\n",
      "1008 tensor(80311.1797, grad_fn=<MseLossBackward0>)\n",
      "1009 tensor(80307.3203, grad_fn=<MseLossBackward0>)\n",
      "1010 tensor(80303.4688, grad_fn=<MseLossBackward0>)\n",
      "1011 tensor(80299.6172, grad_fn=<MseLossBackward0>)\n",
      "1012 tensor(80295.7734, grad_fn=<MseLossBackward0>)\n",
      "1013 tensor(80291.9297, grad_fn=<MseLossBackward0>)\n",
      "1014 tensor(80288.0781, grad_fn=<MseLossBackward0>)\n",
      "1015 tensor(80284.2422, grad_fn=<MseLossBackward0>)\n",
      "1016 tensor(80280.3984, grad_fn=<MseLossBackward0>)\n",
      "1017 tensor(80276.5547, grad_fn=<MseLossBackward0>)\n",
      "1018 tensor(80272.7188, grad_fn=<MseLossBackward0>)\n",
      "1019 tensor(80268.8828, grad_fn=<MseLossBackward0>)\n",
      "1020 tensor(80265.0547, grad_fn=<MseLossBackward0>)\n",
      "1021 tensor(80261.2188, grad_fn=<MseLossBackward0>)\n",
      "1022 tensor(80257.3828, grad_fn=<MseLossBackward0>)\n",
      "1023 tensor(80253.5625, grad_fn=<MseLossBackward0>)\n",
      "1024 tensor(80249.7344, grad_fn=<MseLossBackward0>)\n",
      "1025 tensor(80245.9062, grad_fn=<MseLossBackward0>)\n",
      "1026 tensor(80242.0859, grad_fn=<MseLossBackward0>)\n",
      "1027 tensor(80238.2656, grad_fn=<MseLossBackward0>)\n",
      "1028 tensor(80234.4531, grad_fn=<MseLossBackward0>)\n",
      "1029 tensor(80230.6406, grad_fn=<MseLossBackward0>)\n",
      "1030 tensor(80226.8281, grad_fn=<MseLossBackward0>)\n",
      "1031 tensor(80223.0156, grad_fn=<MseLossBackward0>)\n",
      "1032 tensor(80219.2031, grad_fn=<MseLossBackward0>)\n",
      "1033 tensor(80215.3906, grad_fn=<MseLossBackward0>)\n",
      "1034 tensor(80211.5859, grad_fn=<MseLossBackward0>)\n",
      "1035 tensor(80207.7734, grad_fn=<MseLossBackward0>)\n",
      "1036 tensor(80203.9766, grad_fn=<MseLossBackward0>)\n",
      "1037 tensor(80200.1797, grad_fn=<MseLossBackward0>)\n",
      "1038 tensor(80196.3750, grad_fn=<MseLossBackward0>)\n",
      "1039 tensor(80192.5859, grad_fn=<MseLossBackward0>)\n",
      "1040 tensor(80188.7891, grad_fn=<MseLossBackward0>)\n",
      "1041 tensor(80185., grad_fn=<MseLossBackward0>)\n",
      "1042 tensor(80181.1953, grad_fn=<MseLossBackward0>)\n",
      "1043 tensor(80177.4141, grad_fn=<MseLossBackward0>)\n",
      "1044 tensor(80173.6328, grad_fn=<MseLossBackward0>)\n",
      "1045 tensor(80169.8516, grad_fn=<MseLossBackward0>)\n",
      "1046 tensor(80166.0625, grad_fn=<MseLossBackward0>)\n",
      "1047 tensor(80162.2734, grad_fn=<MseLossBackward0>)\n",
      "1048 tensor(80158.5078, grad_fn=<MseLossBackward0>)\n",
      "1049 tensor(80154.7344, grad_fn=<MseLossBackward0>)\n",
      "1050 tensor(80150.9453, grad_fn=<MseLossBackward0>)\n",
      "1051 tensor(80147.1719, grad_fn=<MseLossBackward0>)\n",
      "1052 tensor(80143.4062, grad_fn=<MseLossBackward0>)\n",
      "1053 tensor(80139.6328, grad_fn=<MseLossBackward0>)\n",
      "1054 tensor(80135.8672, grad_fn=<MseLossBackward0>)\n",
      "1055 tensor(80132.1094, grad_fn=<MseLossBackward0>)\n",
      "1056 tensor(80128.3359, grad_fn=<MseLossBackward0>)\n",
      "1057 tensor(80124.5781, grad_fn=<MseLossBackward0>)\n",
      "1058 tensor(80120.8125, grad_fn=<MseLossBackward0>)\n",
      "1059 tensor(80117.0625, grad_fn=<MseLossBackward0>)\n",
      "1060 tensor(80113.3125, grad_fn=<MseLossBackward0>)\n",
      "1061 tensor(80109.5469, grad_fn=<MseLossBackward0>)\n",
      "1062 tensor(80105.7969, grad_fn=<MseLossBackward0>)\n",
      "1063 tensor(80102.0469, grad_fn=<MseLossBackward0>)\n",
      "1064 tensor(80098.3047, grad_fn=<MseLossBackward0>)\n",
      "1065 tensor(80094.5469, grad_fn=<MseLossBackward0>)\n",
      "1066 tensor(80090.8047, grad_fn=<MseLossBackward0>)\n",
      "1067 tensor(80087.0625, grad_fn=<MseLossBackward0>)\n",
      "1068 tensor(80083.3203, grad_fn=<MseLossBackward0>)\n",
      "1069 tensor(80079.5859, grad_fn=<MseLossBackward0>)\n",
      "1070 tensor(80075.8516, grad_fn=<MseLossBackward0>)\n",
      "1071 tensor(80072.1172, grad_fn=<MseLossBackward0>)\n",
      "1072 tensor(80068.3828, grad_fn=<MseLossBackward0>)\n",
      "1073 tensor(80064.6484, grad_fn=<MseLossBackward0>)\n",
      "1074 tensor(80060.9297, grad_fn=<MseLossBackward0>)\n",
      "1075 tensor(80057.1953, grad_fn=<MseLossBackward0>)\n",
      "1076 tensor(80053.4766, grad_fn=<MseLossBackward0>)\n",
      "1077 tensor(80049.7500, grad_fn=<MseLossBackward0>)\n",
      "1078 tensor(80046.0312, grad_fn=<MseLossBackward0>)\n",
      "1079 tensor(80042.3125, grad_fn=<MseLossBackward0>)\n",
      "1080 tensor(80038.5938, grad_fn=<MseLossBackward0>)\n",
      "1081 tensor(80034.8750, grad_fn=<MseLossBackward0>)\n",
      "1082 tensor(80031.1562, grad_fn=<MseLossBackward0>)\n",
      "1083 tensor(80027.4531, grad_fn=<MseLossBackward0>)\n",
      "1084 tensor(80023.7500, grad_fn=<MseLossBackward0>)\n",
      "1085 tensor(80020.0312, grad_fn=<MseLossBackward0>)\n",
      "1086 tensor(80016.3359, grad_fn=<MseLossBackward0>)\n",
      "1087 tensor(80012.6328, grad_fn=<MseLossBackward0>)\n",
      "1088 tensor(80008.9297, grad_fn=<MseLossBackward0>)\n",
      "1089 tensor(80005.2266, grad_fn=<MseLossBackward0>)\n",
      "1090 tensor(80001.5312, grad_fn=<MseLossBackward0>)\n",
      "1091 tensor(79997.8438, grad_fn=<MseLossBackward0>)\n",
      "1092 tensor(79994.1328, grad_fn=<MseLossBackward0>)\n",
      "1093 tensor(79990.4453, grad_fn=<MseLossBackward0>)\n",
      "1094 tensor(79986.7578, grad_fn=<MseLossBackward0>)\n",
      "1095 tensor(79983.0625, grad_fn=<MseLossBackward0>)\n",
      "1096 tensor(79979.3906, grad_fn=<MseLossBackward0>)\n",
      "1097 tensor(79975.6953, grad_fn=<MseLossBackward0>)\n",
      "1098 tensor(79972.0156, grad_fn=<MseLossBackward0>)\n",
      "1099 tensor(79968.3281, grad_fn=<MseLossBackward0>)\n",
      "1100 tensor(79964.6641, grad_fn=<MseLossBackward0>)\n",
      "1101 tensor(79960.9766, grad_fn=<MseLossBackward0>)\n",
      "1102 tensor(79957.3125, grad_fn=<MseLossBackward0>)\n",
      "1103 tensor(79953.6406, grad_fn=<MseLossBackward0>)\n",
      "1104 tensor(79949.9688, grad_fn=<MseLossBackward0>)\n",
      "1105 tensor(79946.2969, grad_fn=<MseLossBackward0>)\n",
      "1106 tensor(79942.6328, grad_fn=<MseLossBackward0>)\n",
      "1107 tensor(79938.9688, grad_fn=<MseLossBackward0>)\n",
      "1108 tensor(79935.3047, grad_fn=<MseLossBackward0>)\n",
      "1109 tensor(79931.6484, grad_fn=<MseLossBackward0>)\n",
      "1110 tensor(79927.9844, grad_fn=<MseLossBackward0>)\n",
      "1111 tensor(79924.3359, grad_fn=<MseLossBackward0>)\n",
      "1112 tensor(79920.6797, grad_fn=<MseLossBackward0>)\n",
      "1113 tensor(79917.0312, grad_fn=<MseLossBackward0>)\n",
      "1114 tensor(79913.3750, grad_fn=<MseLossBackward0>)\n",
      "1115 tensor(79909.7188, grad_fn=<MseLossBackward0>)\n",
      "1116 tensor(79906.0781, grad_fn=<MseLossBackward0>)\n",
      "1117 tensor(79902.4297, grad_fn=<MseLossBackward0>)\n",
      "1118 tensor(79898.7812, grad_fn=<MseLossBackward0>)\n",
      "1119 tensor(79895.1328, grad_fn=<MseLossBackward0>)\n",
      "1120 tensor(79891.5000, grad_fn=<MseLossBackward0>)\n",
      "1121 tensor(79887.8672, grad_fn=<MseLossBackward0>)\n",
      "1122 tensor(79884.2422, grad_fn=<MseLossBackward0>)\n",
      "1123 tensor(79880.5938, grad_fn=<MseLossBackward0>)\n",
      "1124 tensor(79876.9609, grad_fn=<MseLossBackward0>)\n",
      "1125 tensor(79873.3359, grad_fn=<MseLossBackward0>)\n",
      "1126 tensor(79869.7109, grad_fn=<MseLossBackward0>)\n",
      "1127 tensor(79866.0781, grad_fn=<MseLossBackward0>)\n",
      "1128 tensor(79862.4609, grad_fn=<MseLossBackward0>)\n",
      "1129 tensor(79858.8438, grad_fn=<MseLossBackward0>)\n",
      "1130 tensor(79855.2188, grad_fn=<MseLossBackward0>)\n",
      "1131 tensor(79851.6016, grad_fn=<MseLossBackward0>)\n",
      "1132 tensor(79847.9844, grad_fn=<MseLossBackward0>)\n",
      "1133 tensor(79844.3750, grad_fn=<MseLossBackward0>)\n",
      "1134 tensor(79840.7656, grad_fn=<MseLossBackward0>)\n",
      "1135 tensor(79837.1484, grad_fn=<MseLossBackward0>)\n",
      "1136 tensor(79833.5391, grad_fn=<MseLossBackward0>)\n",
      "1137 tensor(79829.9297, grad_fn=<MseLossBackward0>)\n",
      "1138 tensor(79826.3281, grad_fn=<MseLossBackward0>)\n",
      "1139 tensor(79822.7266, grad_fn=<MseLossBackward0>)\n",
      "1140 tensor(79819.1250, grad_fn=<MseLossBackward0>)\n",
      "1141 tensor(79815.5234, grad_fn=<MseLossBackward0>)\n",
      "1142 tensor(79811.9297, grad_fn=<MseLossBackward0>)\n",
      "1143 tensor(79808.3438, grad_fn=<MseLossBackward0>)\n",
      "1144 tensor(79804.7500, grad_fn=<MseLossBackward0>)\n",
      "1145 tensor(79801.1484, grad_fn=<MseLossBackward0>)\n",
      "1146 tensor(79797.5703, grad_fn=<MseLossBackward0>)\n",
      "1147 tensor(79793.9766, grad_fn=<MseLossBackward0>)\n",
      "1148 tensor(79790.3906, grad_fn=<MseLossBackward0>)\n",
      "1149 tensor(79786.8125, grad_fn=<MseLossBackward0>)\n",
      "1150 tensor(79783.2344, grad_fn=<MseLossBackward0>)\n",
      "1151 tensor(79779.6484, grad_fn=<MseLossBackward0>)\n",
      "1152 tensor(79776.0781, grad_fn=<MseLossBackward0>)\n",
      "1153 tensor(79772.5000, grad_fn=<MseLossBackward0>)\n",
      "1154 tensor(79768.9297, grad_fn=<MseLossBackward0>)\n",
      "1155 tensor(79765.3516, grad_fn=<MseLossBackward0>)\n",
      "1156 tensor(79761.7891, grad_fn=<MseLossBackward0>)\n",
      "1157 tensor(79758.2188, grad_fn=<MseLossBackward0>)\n",
      "1158 tensor(79754.6562, grad_fn=<MseLossBackward0>)\n",
      "1159 tensor(79751.0859, grad_fn=<MseLossBackward0>)\n",
      "1160 tensor(79747.5312, grad_fn=<MseLossBackward0>)\n",
      "1161 tensor(79743.9688, grad_fn=<MseLossBackward0>)\n",
      "1162 tensor(79740.4141, grad_fn=<MseLossBackward0>)\n",
      "1163 tensor(79736.8516, grad_fn=<MseLossBackward0>)\n",
      "1164 tensor(79733.2969, grad_fn=<MseLossBackward0>)\n",
      "1165 tensor(79729.7500, grad_fn=<MseLossBackward0>)\n",
      "1166 tensor(79726.2031, grad_fn=<MseLossBackward0>)\n",
      "1167 tensor(79722.6562, grad_fn=<MseLossBackward0>)\n",
      "1168 tensor(79719.1094, grad_fn=<MseLossBackward0>)\n",
      "1169 tensor(79715.5625, grad_fn=<MseLossBackward0>)\n",
      "1170 tensor(79712.0234, grad_fn=<MseLossBackward0>)\n",
      "1171 tensor(79708.4844, grad_fn=<MseLossBackward0>)\n",
      "1172 tensor(79704.9531, grad_fn=<MseLossBackward0>)\n",
      "1173 tensor(79701.4062, grad_fn=<MseLossBackward0>)\n",
      "1174 tensor(79697.8750, grad_fn=<MseLossBackward0>)\n",
      "1175 tensor(79694.3438, grad_fn=<MseLossBackward0>)\n",
      "1176 tensor(79690.8125, grad_fn=<MseLossBackward0>)\n",
      "1177 tensor(79687.2891, grad_fn=<MseLossBackward0>)\n",
      "1178 tensor(79683.7578, grad_fn=<MseLossBackward0>)\n",
      "1179 tensor(79680.2266, grad_fn=<MseLossBackward0>)\n",
      "1180 tensor(79676.7109, grad_fn=<MseLossBackward0>)\n",
      "1181 tensor(79673.1953, grad_fn=<MseLossBackward0>)\n",
      "1182 tensor(79669.6641, grad_fn=<MseLossBackward0>)\n",
      "1183 tensor(79666.1484, grad_fn=<MseLossBackward0>)\n",
      "1184 tensor(79662.6406, grad_fn=<MseLossBackward0>)\n",
      "1185 tensor(79659.1328, grad_fn=<MseLossBackward0>)\n",
      "1186 tensor(79655.6094, grad_fn=<MseLossBackward0>)\n",
      "1187 tensor(79652.1016, grad_fn=<MseLossBackward0>)\n",
      "1188 tensor(79648.6094, grad_fn=<MseLossBackward0>)\n",
      "1189 tensor(79645.1016, grad_fn=<MseLossBackward0>)\n",
      "1190 tensor(79641.5938, grad_fn=<MseLossBackward0>)\n",
      "1191 tensor(79638.0938, grad_fn=<MseLossBackward0>)\n",
      "1192 tensor(79634.6016, grad_fn=<MseLossBackward0>)\n",
      "1193 tensor(79631.0938, grad_fn=<MseLossBackward0>)\n",
      "1194 tensor(79627.6016, grad_fn=<MseLossBackward0>)\n",
      "1195 tensor(79624.1094, grad_fn=<MseLossBackward0>)\n",
      "1196 tensor(79620.6094, grad_fn=<MseLossBackward0>)\n",
      "1197 tensor(79617.1328, grad_fn=<MseLossBackward0>)\n",
      "1198 tensor(79613.6406, grad_fn=<MseLossBackward0>)\n",
      "1199 tensor(79610.1484, grad_fn=<MseLossBackward0>)\n",
      "1200 tensor(79606.6719, grad_fn=<MseLossBackward0>)\n",
      "1201 tensor(79603.1953, grad_fn=<MseLossBackward0>)\n",
      "1202 tensor(79599.7031, grad_fn=<MseLossBackward0>)\n",
      "1203 tensor(79596.2344, grad_fn=<MseLossBackward0>)\n",
      "1204 tensor(79592.7500, grad_fn=<MseLossBackward0>)\n",
      "1205 tensor(79589.2891, grad_fn=<MseLossBackward0>)\n",
      "1206 tensor(79585.8125, grad_fn=<MseLossBackward0>)\n",
      "1207 tensor(79582.3516, grad_fn=<MseLossBackward0>)\n",
      "1208 tensor(79578.8750, grad_fn=<MseLossBackward0>)\n",
      "1209 tensor(79575.4141, grad_fn=<MseLossBackward0>)\n",
      "1210 tensor(79571.9453, grad_fn=<MseLossBackward0>)\n",
      "1211 tensor(79568.4844, grad_fn=<MseLossBackward0>)\n",
      "1212 tensor(79565.0312, grad_fn=<MseLossBackward0>)\n",
      "1213 tensor(79561.5703, grad_fn=<MseLossBackward0>)\n",
      "1214 tensor(79558.1016, grad_fn=<MseLossBackward0>)\n",
      "1215 tensor(79554.6641, grad_fn=<MseLossBackward0>)\n",
      "1216 tensor(79551.2031, grad_fn=<MseLossBackward0>)\n",
      "1217 tensor(79547.7578, grad_fn=<MseLossBackward0>)\n",
      "1218 tensor(79544.3047, grad_fn=<MseLossBackward0>)\n",
      "1219 tensor(79540.8594, grad_fn=<MseLossBackward0>)\n",
      "1220 tensor(79537.4219, grad_fn=<MseLossBackward0>)\n",
      "1221 tensor(79533.9766, grad_fn=<MseLossBackward0>)\n",
      "1222 tensor(79530.5391, grad_fn=<MseLossBackward0>)\n",
      "1223 tensor(79527.0938, grad_fn=<MseLossBackward0>)\n",
      "1224 tensor(79523.6641, grad_fn=<MseLossBackward0>)\n",
      "1225 tensor(79520.2188, grad_fn=<MseLossBackward0>)\n",
      "1226 tensor(79516.7969, grad_fn=<MseLossBackward0>)\n",
      "1227 tensor(79513.3594, grad_fn=<MseLossBackward0>)\n",
      "1228 tensor(79509.9297, grad_fn=<MseLossBackward0>)\n",
      "1229 tensor(79506.5000, grad_fn=<MseLossBackward0>)\n",
      "1230 tensor(79503.0859, grad_fn=<MseLossBackward0>)\n",
      "1231 tensor(79499.6562, grad_fn=<MseLossBackward0>)\n",
      "1232 tensor(79496.2422, grad_fn=<MseLossBackward0>)\n",
      "1233 tensor(79492.8125, grad_fn=<MseLossBackward0>)\n",
      "1234 tensor(79489.3984, grad_fn=<MseLossBackward0>)\n",
      "1235 tensor(79485.9844, grad_fn=<MseLossBackward0>)\n",
      "1236 tensor(79482.5703, grad_fn=<MseLossBackward0>)\n",
      "1237 tensor(79479.1641, grad_fn=<MseLossBackward0>)\n",
      "1238 tensor(79475.7578, grad_fn=<MseLossBackward0>)\n",
      "1239 tensor(79472.3516, grad_fn=<MseLossBackward0>)\n",
      "1240 tensor(79468.9453, grad_fn=<MseLossBackward0>)\n",
      "1241 tensor(79465.5391, grad_fn=<MseLossBackward0>)\n",
      "1242 tensor(79462.1406, grad_fn=<MseLossBackward0>)\n",
      "1243 tensor(79458.7422, grad_fn=<MseLossBackward0>)\n",
      "1244 tensor(79455.3438, grad_fn=<MseLossBackward0>)\n",
      "1245 tensor(79451.9375, grad_fn=<MseLossBackward0>)\n",
      "1246 tensor(79448.5469, grad_fn=<MseLossBackward0>)\n",
      "1247 tensor(79445.1562, grad_fn=<MseLossBackward0>)\n",
      "1248 tensor(79441.7734, grad_fn=<MseLossBackward0>)\n",
      "1249 tensor(79438.3828, grad_fn=<MseLossBackward0>)\n",
      "1250 tensor(79434.9922, grad_fn=<MseLossBackward0>)\n",
      "1251 tensor(79431.6094, grad_fn=<MseLossBackward0>)\n",
      "1252 tensor(79428.2344, grad_fn=<MseLossBackward0>)\n",
      "1253 tensor(79424.8516, grad_fn=<MseLossBackward0>)\n",
      "1254 tensor(79421.4688, grad_fn=<MseLossBackward0>)\n",
      "1255 tensor(79418.1016, grad_fn=<MseLossBackward0>)\n",
      "1256 tensor(79414.7266, grad_fn=<MseLossBackward0>)\n",
      "1257 tensor(79411.3438, grad_fn=<MseLossBackward0>)\n",
      "1258 tensor(79407.9844, grad_fn=<MseLossBackward0>)\n",
      "1259 tensor(79404.6250, grad_fn=<MseLossBackward0>)\n",
      "1260 tensor(79401.2500, grad_fn=<MseLossBackward0>)\n",
      "1261 tensor(79397.8828, grad_fn=<MseLossBackward0>)\n",
      "1262 tensor(79394.5234, grad_fn=<MseLossBackward0>)\n",
      "1263 tensor(79391.1562, grad_fn=<MseLossBackward0>)\n",
      "1264 tensor(79387.8125, grad_fn=<MseLossBackward0>)\n",
      "1265 tensor(79384.4453, grad_fn=<MseLossBackward0>)\n",
      "1266 tensor(79381.0938, grad_fn=<MseLossBackward0>)\n",
      "1267 tensor(79377.7344, grad_fn=<MseLossBackward0>)\n",
      "1268 tensor(79374.3828, grad_fn=<MseLossBackward0>)\n",
      "1269 tensor(79371.0312, grad_fn=<MseLossBackward0>)\n",
      "1270 tensor(79367.6953, grad_fn=<MseLossBackward0>)\n",
      "1271 tensor(79364.3438, grad_fn=<MseLossBackward0>)\n",
      "1272 tensor(79361.0078, grad_fn=<MseLossBackward0>)\n",
      "1273 tensor(79357.6562, grad_fn=<MseLossBackward0>)\n",
      "1274 tensor(79354.3281, grad_fn=<MseLossBackward0>)\n",
      "1275 tensor(79350.9922, grad_fn=<MseLossBackward0>)\n",
      "1276 tensor(79347.6484, grad_fn=<MseLossBackward0>)\n",
      "1277 tensor(79344.3203, grad_fn=<MseLossBackward0>)\n",
      "1278 tensor(79340.9922, grad_fn=<MseLossBackward0>)\n",
      "1279 tensor(79337.6641, grad_fn=<MseLossBackward0>)\n",
      "1280 tensor(79334.3438, grad_fn=<MseLossBackward0>)\n",
      "1281 tensor(79331.0078, grad_fn=<MseLossBackward0>)\n",
      "1282 tensor(79327.6875, grad_fn=<MseLossBackward0>)\n",
      "1283 tensor(79324.3672, grad_fn=<MseLossBackward0>)\n",
      "1284 tensor(79321.0547, grad_fn=<MseLossBackward0>)\n",
      "1285 tensor(79317.7422, grad_fn=<MseLossBackward0>)\n",
      "1286 tensor(79314.4141, grad_fn=<MseLossBackward0>)\n",
      "1287 tensor(79311.1016, grad_fn=<MseLossBackward0>)\n",
      "1288 tensor(79307.7969, grad_fn=<MseLossBackward0>)\n",
      "1289 tensor(79304.4844, grad_fn=<MseLossBackward0>)\n",
      "1290 tensor(79301.1719, grad_fn=<MseLossBackward0>)\n",
      "1291 tensor(79297.8750, grad_fn=<MseLossBackward0>)\n",
      "1292 tensor(79294.5703, grad_fn=<MseLossBackward0>)\n",
      "1293 tensor(79291.2656, grad_fn=<MseLossBackward0>)\n",
      "1294 tensor(79287.9688, grad_fn=<MseLossBackward0>)\n",
      "1295 tensor(79284.6719, grad_fn=<MseLossBackward0>)\n",
      "1296 tensor(79281.3672, grad_fn=<MseLossBackward0>)\n",
      "1297 tensor(79278.0703, grad_fn=<MseLossBackward0>)\n",
      "1298 tensor(79274.7812, grad_fn=<MseLossBackward0>)\n",
      "1299 tensor(79271.4922, grad_fn=<MseLossBackward0>)\n",
      "1300 tensor(79268.2031, grad_fn=<MseLossBackward0>)\n",
      "1301 tensor(79264.9219, grad_fn=<MseLossBackward0>)\n",
      "1302 tensor(79261.6406, grad_fn=<MseLossBackward0>)\n",
      "1303 tensor(79258.3594, grad_fn=<MseLossBackward0>)\n",
      "1304 tensor(79255.0781, grad_fn=<MseLossBackward0>)\n",
      "1305 tensor(79251.7969, grad_fn=<MseLossBackward0>)\n",
      "1306 tensor(79248.5234, grad_fn=<MseLossBackward0>)\n",
      "1307 tensor(79245.2422, grad_fn=<MseLossBackward0>)\n",
      "1308 tensor(79241.9766, grad_fn=<MseLossBackward0>)\n",
      "1309 tensor(79238.7031, grad_fn=<MseLossBackward0>)\n",
      "1310 tensor(79235.4453, grad_fn=<MseLossBackward0>)\n",
      "1311 tensor(79232.1719, grad_fn=<MseLossBackward0>)\n",
      "1312 tensor(79228.9062, grad_fn=<MseLossBackward0>)\n",
      "1313 tensor(79225.6484, grad_fn=<MseLossBackward0>)\n",
      "1314 tensor(79222.3906, grad_fn=<MseLossBackward0>)\n",
      "1315 tensor(79219.1250, grad_fn=<MseLossBackward0>)\n",
      "1316 tensor(79215.8672, grad_fn=<MseLossBackward0>)\n",
      "1317 tensor(79212.6250, grad_fn=<MseLossBackward0>)\n",
      "1318 tensor(79209.3672, grad_fn=<MseLossBackward0>)\n",
      "1319 tensor(79206.1094, grad_fn=<MseLossBackward0>)\n",
      "1320 tensor(79202.8672, grad_fn=<MseLossBackward0>)\n",
      "1321 tensor(79199.6250, grad_fn=<MseLossBackward0>)\n",
      "1322 tensor(79196.3750, grad_fn=<MseLossBackward0>)\n",
      "1323 tensor(79193.1250, grad_fn=<MseLossBackward0>)\n",
      "1324 tensor(79189.8984, grad_fn=<MseLossBackward0>)\n",
      "1325 tensor(79186.6484, grad_fn=<MseLossBackward0>)\n",
      "1326 tensor(79183.4141, grad_fn=<MseLossBackward0>)\n",
      "1327 tensor(79180.1719, grad_fn=<MseLossBackward0>)\n",
      "1328 tensor(79176.9453, grad_fn=<MseLossBackward0>)\n",
      "1329 tensor(79173.7188, grad_fn=<MseLossBackward0>)\n",
      "1330 tensor(79170.4844, grad_fn=<MseLossBackward0>)\n",
      "1331 tensor(79167.2578, grad_fn=<MseLossBackward0>)\n",
      "1332 tensor(79164.0312, grad_fn=<MseLossBackward0>)\n",
      "1333 tensor(79160.8125, grad_fn=<MseLossBackward0>)\n",
      "1334 tensor(79157.5938, grad_fn=<MseLossBackward0>)\n",
      "1335 tensor(79154.3672, grad_fn=<MseLossBackward0>)\n",
      "1336 tensor(79151.1562, grad_fn=<MseLossBackward0>)\n",
      "1337 tensor(79147.9375, grad_fn=<MseLossBackward0>)\n",
      "1338 tensor(79144.7266, grad_fn=<MseLossBackward0>)\n",
      "1339 tensor(79141.5156, grad_fn=<MseLossBackward0>)\n",
      "1340 tensor(79138.3047, grad_fn=<MseLossBackward0>)\n",
      "1341 tensor(79135.0938, grad_fn=<MseLossBackward0>)\n",
      "1342 tensor(79131.8906, grad_fn=<MseLossBackward0>)\n",
      "1343 tensor(79128.6797, grad_fn=<MseLossBackward0>)\n",
      "1344 tensor(79125.4844, grad_fn=<MseLossBackward0>)\n",
      "1345 tensor(79122.2812, grad_fn=<MseLossBackward0>)\n",
      "1346 tensor(79119.0938, grad_fn=<MseLossBackward0>)\n",
      "1347 tensor(79115.8906, grad_fn=<MseLossBackward0>)\n",
      "1348 tensor(79112.7109, grad_fn=<MseLossBackward0>)\n",
      "1349 tensor(79109.5156, grad_fn=<MseLossBackward0>)\n",
      "1350 tensor(79106.3203, grad_fn=<MseLossBackward0>)\n",
      "1351 tensor(79103.1250, grad_fn=<MseLossBackward0>)\n",
      "1352 tensor(79099.9453, grad_fn=<MseLossBackward0>)\n",
      "1353 tensor(79096.7656, grad_fn=<MseLossBackward0>)\n",
      "1354 tensor(79093.5859, grad_fn=<MseLossBackward0>)\n",
      "1355 tensor(79090.3906, grad_fn=<MseLossBackward0>)\n",
      "1356 tensor(79087.2188, grad_fn=<MseLossBackward0>)\n",
      "1357 tensor(79084.0391, grad_fn=<MseLossBackward0>)\n",
      "1358 tensor(79080.8672, grad_fn=<MseLossBackward0>)\n",
      "1359 tensor(79077.7031, grad_fn=<MseLossBackward0>)\n",
      "1360 tensor(79074.5234, grad_fn=<MseLossBackward0>)\n",
      "1361 tensor(79071.3594, grad_fn=<MseLossBackward0>)\n",
      "1362 tensor(79068.1875, grad_fn=<MseLossBackward0>)\n",
      "1363 tensor(79065.0391, grad_fn=<MseLossBackward0>)\n",
      "1364 tensor(79061.8672, grad_fn=<MseLossBackward0>)\n",
      "1365 tensor(79058.7109, grad_fn=<MseLossBackward0>)\n",
      "1366 tensor(79055.5469, grad_fn=<MseLossBackward0>)\n",
      "1367 tensor(79052.3906, grad_fn=<MseLossBackward0>)\n",
      "1368 tensor(79049.2422, grad_fn=<MseLossBackward0>)\n",
      "1369 tensor(79046.0781, grad_fn=<MseLossBackward0>)\n",
      "1370 tensor(79042.9297, grad_fn=<MseLossBackward0>)\n",
      "1371 tensor(79039.7891, grad_fn=<MseLossBackward0>)\n",
      "1372 tensor(79036.6406, grad_fn=<MseLossBackward0>)\n",
      "1373 tensor(79033.5000, grad_fn=<MseLossBackward0>)\n",
      "1374 tensor(79030.3516, grad_fn=<MseLossBackward0>)\n",
      "1375 tensor(79027.2109, grad_fn=<MseLossBackward0>)\n",
      "1376 tensor(79024.0703, grad_fn=<MseLossBackward0>)\n",
      "1377 tensor(79020.9453, grad_fn=<MseLossBackward0>)\n",
      "1378 tensor(79017.7891, grad_fn=<MseLossBackward0>)\n",
      "1379 tensor(79014.6641, grad_fn=<MseLossBackward0>)\n",
      "1380 tensor(79011.5312, grad_fn=<MseLossBackward0>)\n",
      "1381 tensor(79008.4062, grad_fn=<MseLossBackward0>)\n",
      "1382 tensor(79005.2812, grad_fn=<MseLossBackward0>)\n",
      "1383 tensor(79002.1562, grad_fn=<MseLossBackward0>)\n",
      "1384 tensor(78999.0312, grad_fn=<MseLossBackward0>)\n",
      "1385 tensor(78995.9141, grad_fn=<MseLossBackward0>)\n",
      "1386 tensor(78992.7891, grad_fn=<MseLossBackward0>)\n",
      "1387 tensor(78989.6719, grad_fn=<MseLossBackward0>)\n",
      "1388 tensor(78986.5625, grad_fn=<MseLossBackward0>)\n",
      "1389 tensor(78983.4453, grad_fn=<MseLossBackward0>)\n",
      "1390 tensor(78980.3359, grad_fn=<MseLossBackward0>)\n",
      "1391 tensor(78977.2266, grad_fn=<MseLossBackward0>)\n",
      "1392 tensor(78974.1172, grad_fn=<MseLossBackward0>)\n",
      "1393 tensor(78971.0078, grad_fn=<MseLossBackward0>)\n",
      "1394 tensor(78967.9141, grad_fn=<MseLossBackward0>)\n",
      "1395 tensor(78964.8125, grad_fn=<MseLossBackward0>)\n",
      "1396 tensor(78961.7031, grad_fn=<MseLossBackward0>)\n",
      "1397 tensor(78958.6094, grad_fn=<MseLossBackward0>)\n",
      "1398 tensor(78955.5156, grad_fn=<MseLossBackward0>)\n",
      "1399 tensor(78952.4141, grad_fn=<MseLossBackward0>)\n",
      "1400 tensor(78949.3281, grad_fn=<MseLossBackward0>)\n",
      "1401 tensor(78946.2422, grad_fn=<MseLossBackward0>)\n",
      "1402 tensor(78943.1484, grad_fn=<MseLossBackward0>)\n",
      "1403 tensor(78940.0625, grad_fn=<MseLossBackward0>)\n",
      "1404 tensor(78936.9766, grad_fn=<MseLossBackward0>)\n",
      "1405 tensor(78933.8984, grad_fn=<MseLossBackward0>)\n",
      "1406 tensor(78930.8203, grad_fn=<MseLossBackward0>)\n",
      "1407 tensor(78927.7500, grad_fn=<MseLossBackward0>)\n",
      "1408 tensor(78924.6719, grad_fn=<MseLossBackward0>)\n",
      "1409 tensor(78921.5938, grad_fn=<MseLossBackward0>)\n",
      "1410 tensor(78918.5234, grad_fn=<MseLossBackward0>)\n",
      "1411 tensor(78915.4453, grad_fn=<MseLossBackward0>)\n",
      "1412 tensor(78912.3828, grad_fn=<MseLossBackward0>)\n",
      "1413 tensor(78909.3125, grad_fn=<MseLossBackward0>)\n",
      "1414 tensor(78906.2500, grad_fn=<MseLossBackward0>)\n",
      "1415 tensor(78903.1797, grad_fn=<MseLossBackward0>)\n",
      "1416 tensor(78900.1250, grad_fn=<MseLossBackward0>)\n",
      "1417 tensor(78897.0625, grad_fn=<MseLossBackward0>)\n",
      "1418 tensor(78894.0156, grad_fn=<MseLossBackward0>)\n",
      "1419 tensor(78890.9609, grad_fn=<MseLossBackward0>)\n",
      "1420 tensor(78887.9062, grad_fn=<MseLossBackward0>)\n",
      "1421 tensor(78884.8516, grad_fn=<MseLossBackward0>)\n",
      "1422 tensor(78881.8047, grad_fn=<MseLossBackward0>)\n",
      "1423 tensor(78878.7656, grad_fn=<MseLossBackward0>)\n",
      "1424 tensor(78875.7188, grad_fn=<MseLossBackward0>)\n",
      "1425 tensor(78872.6719, grad_fn=<MseLossBackward0>)\n",
      "1426 tensor(78869.6328, grad_fn=<MseLossBackward0>)\n",
      "1427 tensor(78866.5938, grad_fn=<MseLossBackward0>)\n",
      "1428 tensor(78863.5547, grad_fn=<MseLossBackward0>)\n",
      "1429 tensor(78860.5234, grad_fn=<MseLossBackward0>)\n",
      "1430 tensor(78857.4844, grad_fn=<MseLossBackward0>)\n",
      "1431 tensor(78854.4531, grad_fn=<MseLossBackward0>)\n",
      "1432 tensor(78851.4375, grad_fn=<MseLossBackward0>)\n",
      "1433 tensor(78848.4062, grad_fn=<MseLossBackward0>)\n",
      "1434 tensor(78845.3750, grad_fn=<MseLossBackward0>)\n",
      "1435 tensor(78842.3438, grad_fn=<MseLossBackward0>)\n",
      "1436 tensor(78839.3359, grad_fn=<MseLossBackward0>)\n",
      "1437 tensor(78836.3125, grad_fn=<MseLossBackward0>)\n",
      "1438 tensor(78833.2969, grad_fn=<MseLossBackward0>)\n",
      "1439 tensor(78830.2812, grad_fn=<MseLossBackward0>)\n",
      "1440 tensor(78827.2656, grad_fn=<MseLossBackward0>)\n",
      "1441 tensor(78824.2500, grad_fn=<MseLossBackward0>)\n",
      "1442 tensor(78821.2500, grad_fn=<MseLossBackward0>)\n",
      "1443 tensor(78818.2422, grad_fn=<MseLossBackward0>)\n",
      "1444 tensor(78815.2344, grad_fn=<MseLossBackward0>)\n",
      "1445 tensor(78812.2344, grad_fn=<MseLossBackward0>)\n",
      "1446 tensor(78809.2266, grad_fn=<MseLossBackward0>)\n",
      "1447 tensor(78806.2266, grad_fn=<MseLossBackward0>)\n",
      "1448 tensor(78803.2344, grad_fn=<MseLossBackward0>)\n",
      "1449 tensor(78800.2422, grad_fn=<MseLossBackward0>)\n",
      "1450 tensor(78797.2344, grad_fn=<MseLossBackward0>)\n",
      "1451 tensor(78794.2500, grad_fn=<MseLossBackward0>)\n",
      "1452 tensor(78791.2578, grad_fn=<MseLossBackward0>)\n",
      "1453 tensor(78788.2812, grad_fn=<MseLossBackward0>)\n",
      "1454 tensor(78785.2891, grad_fn=<MseLossBackward0>)\n",
      "1455 tensor(78782.2969, grad_fn=<MseLossBackward0>)\n",
      "1456 tensor(78779.3281, grad_fn=<MseLossBackward0>)\n",
      "1457 tensor(78776.3438, grad_fn=<MseLossBackward0>)\n",
      "1458 tensor(78773.3672, grad_fn=<MseLossBackward0>)\n",
      "1459 tensor(78770.3984, grad_fn=<MseLossBackward0>)\n",
      "1460 tensor(78767.4141, grad_fn=<MseLossBackward0>)\n",
      "1461 tensor(78764.4453, grad_fn=<MseLossBackward0>)\n",
      "1462 tensor(78761.4688, grad_fn=<MseLossBackward0>)\n",
      "1463 tensor(78758.5078, grad_fn=<MseLossBackward0>)\n",
      "1464 tensor(78755.5391, grad_fn=<MseLossBackward0>)\n",
      "1465 tensor(78752.5625, grad_fn=<MseLossBackward0>)\n",
      "1466 tensor(78749.6094, grad_fn=<MseLossBackward0>)\n",
      "1467 tensor(78746.6484, grad_fn=<MseLossBackward0>)\n",
      "1468 tensor(78743.6875, grad_fn=<MseLossBackward0>)\n",
      "1469 tensor(78740.7422, grad_fn=<MseLossBackward0>)\n",
      "1470 tensor(78737.7812, grad_fn=<MseLossBackward0>)\n",
      "1471 tensor(78734.8281, grad_fn=<MseLossBackward0>)\n",
      "1472 tensor(78731.8750, grad_fn=<MseLossBackward0>)\n",
      "1473 tensor(78728.9297, grad_fn=<MseLossBackward0>)\n",
      "1474 tensor(78725.9844, grad_fn=<MseLossBackward0>)\n",
      "1475 tensor(78723.0391, grad_fn=<MseLossBackward0>)\n",
      "1476 tensor(78720.0938, grad_fn=<MseLossBackward0>)\n",
      "1477 tensor(78717.1562, grad_fn=<MseLossBackward0>)\n",
      "1478 tensor(78714.2188, grad_fn=<MseLossBackward0>)\n",
      "1479 tensor(78711.2812, grad_fn=<MseLossBackward0>)\n",
      "1480 tensor(78708.3438, grad_fn=<MseLossBackward0>)\n",
      "1481 tensor(78705.4062, grad_fn=<MseLossBackward0>)\n",
      "1482 tensor(78702.4844, grad_fn=<MseLossBackward0>)\n",
      "1483 tensor(78699.5469, grad_fn=<MseLossBackward0>)\n",
      "1484 tensor(78696.6172, grad_fn=<MseLossBackward0>)\n",
      "1485 tensor(78693.7109, grad_fn=<MseLossBackward0>)\n",
      "1486 tensor(78690.7734, grad_fn=<MseLossBackward0>)\n",
      "1487 tensor(78687.8516, grad_fn=<MseLossBackward0>)\n",
      "1488 tensor(78684.9297, grad_fn=<MseLossBackward0>)\n",
      "1489 tensor(78682.0234, grad_fn=<MseLossBackward0>)\n",
      "1490 tensor(78679.1094, grad_fn=<MseLossBackward0>)\n",
      "1491 tensor(78676.1875, grad_fn=<MseLossBackward0>)\n",
      "1492 tensor(78673.2812, grad_fn=<MseLossBackward0>)\n",
      "1493 tensor(78670.3672, grad_fn=<MseLossBackward0>)\n",
      "1494 tensor(78667.4609, grad_fn=<MseLossBackward0>)\n",
      "1495 tensor(78664.5547, grad_fn=<MseLossBackward0>)\n",
      "1496 tensor(78661.6562, grad_fn=<MseLossBackward0>)\n",
      "1497 tensor(78658.7500, grad_fn=<MseLossBackward0>)\n",
      "1498 tensor(78655.8516, grad_fn=<MseLossBackward0>)\n",
      "1499 tensor(78652.9531, grad_fn=<MseLossBackward0>)\n",
      "1500 tensor(78650.0547, grad_fn=<MseLossBackward0>)\n",
      "1501 tensor(78647.1641, grad_fn=<MseLossBackward0>)\n",
      "1502 tensor(78644.2734, grad_fn=<MseLossBackward0>)\n",
      "1503 tensor(78641.3828, grad_fn=<MseLossBackward0>)\n",
      "1504 tensor(78638.4922, grad_fn=<MseLossBackward0>)\n",
      "1505 tensor(78635.6172, grad_fn=<MseLossBackward0>)\n",
      "1506 tensor(78632.7188, grad_fn=<MseLossBackward0>)\n",
      "1507 tensor(78629.8438, grad_fn=<MseLossBackward0>)\n",
      "1508 tensor(78626.9609, grad_fn=<MseLossBackward0>)\n",
      "1509 tensor(78624.0859, grad_fn=<MseLossBackward0>)\n",
      "1510 tensor(78621.2109, grad_fn=<MseLossBackward0>)\n",
      "1511 tensor(78618.3359, grad_fn=<MseLossBackward0>)\n",
      "1512 tensor(78615.4609, grad_fn=<MseLossBackward0>)\n",
      "1513 tensor(78612.5938, grad_fn=<MseLossBackward0>)\n",
      "1514 tensor(78609.7266, grad_fn=<MseLossBackward0>)\n",
      "1515 tensor(78606.8672, grad_fn=<MseLossBackward0>)\n",
      "1516 tensor(78604., grad_fn=<MseLossBackward0>)\n",
      "1517 tensor(78601.1328, grad_fn=<MseLossBackward0>)\n",
      "1518 tensor(78598.2812, grad_fn=<MseLossBackward0>)\n",
      "1519 tensor(78595.4141, grad_fn=<MseLossBackward0>)\n",
      "1520 tensor(78592.5547, grad_fn=<MseLossBackward0>)\n",
      "1521 tensor(78589.7188, grad_fn=<MseLossBackward0>)\n",
      "1522 tensor(78586.8516, grad_fn=<MseLossBackward0>)\n",
      "1523 tensor(78584., grad_fn=<MseLossBackward0>)\n",
      "1524 tensor(78581.1484, grad_fn=<MseLossBackward0>)\n",
      "1525 tensor(78578.3047, grad_fn=<MseLossBackward0>)\n",
      "1526 tensor(78575.4609, grad_fn=<MseLossBackward0>)\n",
      "1527 tensor(78572.6250, grad_fn=<MseLossBackward0>)\n",
      "1528 tensor(78569.7734, grad_fn=<MseLossBackward0>)\n",
      "1529 tensor(78566.9375, grad_fn=<MseLossBackward0>)\n",
      "1530 tensor(78564.1094, grad_fn=<MseLossBackward0>)\n",
      "1531 tensor(78561.2656, grad_fn=<MseLossBackward0>)\n",
      "1532 tensor(78558.4297, grad_fn=<MseLossBackward0>)\n",
      "1533 tensor(78555.6016, grad_fn=<MseLossBackward0>)\n",
      "1534 tensor(78552.7734, grad_fn=<MseLossBackward0>)\n",
      "1535 tensor(78549.9453, grad_fn=<MseLossBackward0>)\n",
      "1536 tensor(78547.1250, grad_fn=<MseLossBackward0>)\n",
      "1537 tensor(78544.3047, grad_fn=<MseLossBackward0>)\n",
      "1538 tensor(78541.4688, grad_fn=<MseLossBackward0>)\n",
      "1539 tensor(78538.6641, grad_fn=<MseLossBackward0>)\n",
      "1540 tensor(78535.8438, grad_fn=<MseLossBackward0>)\n",
      "1541 tensor(78533.0234, grad_fn=<MseLossBackward0>)\n",
      "1542 tensor(78530.2109, grad_fn=<MseLossBackward0>)\n",
      "1543 tensor(78527.3984, grad_fn=<MseLossBackward0>)\n",
      "1544 tensor(78524.5938, grad_fn=<MseLossBackward0>)\n",
      "1545 tensor(78521.7891, grad_fn=<MseLossBackward0>)\n",
      "1546 tensor(78518.9766, grad_fn=<MseLossBackward0>)\n",
      "1547 tensor(78516.1797, grad_fn=<MseLossBackward0>)\n",
      "1548 tensor(78513.3750, grad_fn=<MseLossBackward0>)\n",
      "1549 tensor(78510.5781, grad_fn=<MseLossBackward0>)\n",
      "1550 tensor(78507.7734, grad_fn=<MseLossBackward0>)\n",
      "1551 tensor(78504.9766, grad_fn=<MseLossBackward0>)\n",
      "1552 tensor(78502.1875, grad_fn=<MseLossBackward0>)\n",
      "1553 tensor(78499.3984, grad_fn=<MseLossBackward0>)\n",
      "1554 tensor(78496.6016, grad_fn=<MseLossBackward0>)\n",
      "1555 tensor(78493.8125, grad_fn=<MseLossBackward0>)\n",
      "1556 tensor(78491.0312, grad_fn=<MseLossBackward0>)\n",
      "1557 tensor(78488.2422, grad_fn=<MseLossBackward0>)\n",
      "1558 tensor(78485.4609, grad_fn=<MseLossBackward0>)\n",
      "1559 tensor(78482.6875, grad_fn=<MseLossBackward0>)\n",
      "1560 tensor(78479.9062, grad_fn=<MseLossBackward0>)\n",
      "1561 tensor(78477.1250, grad_fn=<MseLossBackward0>)\n",
      "1562 tensor(78474.3594, grad_fn=<MseLossBackward0>)\n",
      "1563 tensor(78471.5859, grad_fn=<MseLossBackward0>)\n",
      "1564 tensor(78468.8125, grad_fn=<MseLossBackward0>)\n",
      "1565 tensor(78466.0391, grad_fn=<MseLossBackward0>)\n",
      "1566 tensor(78463.2812, grad_fn=<MseLossBackward0>)\n",
      "1567 tensor(78460.5156, grad_fn=<MseLossBackward0>)\n",
      "1568 tensor(78457.7578, grad_fn=<MseLossBackward0>)\n",
      "1569 tensor(78454.9922, grad_fn=<MseLossBackward0>)\n",
      "1570 tensor(78452.2344, grad_fn=<MseLossBackward0>)\n",
      "1571 tensor(78449.4688, grad_fn=<MseLossBackward0>)\n",
      "1572 tensor(78446.7188, grad_fn=<MseLossBackward0>)\n",
      "1573 tensor(78443.9688, grad_fn=<MseLossBackward0>)\n",
      "1574 tensor(78441.2188, grad_fn=<MseLossBackward0>)\n",
      "1575 tensor(78438.4766, grad_fn=<MseLossBackward0>)\n",
      "1576 tensor(78435.7266, grad_fn=<MseLossBackward0>)\n",
      "1577 tensor(78432.9766, grad_fn=<MseLossBackward0>)\n",
      "1578 tensor(78430.2344, grad_fn=<MseLossBackward0>)\n",
      "1579 tensor(78427.5000, grad_fn=<MseLossBackward0>)\n",
      "1580 tensor(78424.7578, grad_fn=<MseLossBackward0>)\n",
      "1581 tensor(78422.0078, grad_fn=<MseLossBackward0>)\n",
      "1582 tensor(78419.2812, grad_fn=<MseLossBackward0>)\n",
      "1583 tensor(78416.5469, grad_fn=<MseLossBackward0>)\n",
      "1584 tensor(78413.8203, grad_fn=<MseLossBackward0>)\n",
      "1585 tensor(78411.0859, grad_fn=<MseLossBackward0>)\n",
      "1586 tensor(78408.3672, grad_fn=<MseLossBackward0>)\n",
      "1587 tensor(78405.6406, grad_fn=<MseLossBackward0>)\n",
      "1588 tensor(78402.9141, grad_fn=<MseLossBackward0>)\n",
      "1589 tensor(78400.1875, grad_fn=<MseLossBackward0>)\n",
      "1590 tensor(78397.4766, grad_fn=<MseLossBackward0>)\n",
      "1591 tensor(78394.7578, grad_fn=<MseLossBackward0>)\n",
      "1592 tensor(78392.0391, grad_fn=<MseLossBackward0>)\n",
      "1593 tensor(78389.3203, grad_fn=<MseLossBackward0>)\n",
      "1594 tensor(78386.6172, grad_fn=<MseLossBackward0>)\n",
      "1595 tensor(78383.9062, grad_fn=<MseLossBackward0>)\n",
      "1596 tensor(78381.1953, grad_fn=<MseLossBackward0>)\n",
      "1597 tensor(78378.4922, grad_fn=<MseLossBackward0>)\n",
      "1598 tensor(78375.7969, grad_fn=<MseLossBackward0>)\n",
      "1599 tensor(78373.0859, grad_fn=<MseLossBackward0>)\n",
      "1600 tensor(78370.3984, grad_fn=<MseLossBackward0>)\n",
      "1601 tensor(78367.6797, grad_fn=<MseLossBackward0>)\n",
      "1602 tensor(78365., grad_fn=<MseLossBackward0>)\n",
      "1603 tensor(78362.2969, grad_fn=<MseLossBackward0>)\n",
      "1604 tensor(78359.6016, grad_fn=<MseLossBackward0>)\n",
      "1605 tensor(78356.9141, grad_fn=<MseLossBackward0>)\n",
      "1606 tensor(78354.2266, grad_fn=<MseLossBackward0>)\n",
      "1607 tensor(78351.5312, grad_fn=<MseLossBackward0>)\n",
      "1608 tensor(78348.8516, grad_fn=<MseLossBackward0>)\n",
      "1609 tensor(78346.1797, grad_fn=<MseLossBackward0>)\n",
      "1610 tensor(78343.5000, grad_fn=<MseLossBackward0>)\n",
      "1611 tensor(78340.8203, grad_fn=<MseLossBackward0>)\n",
      "1612 tensor(78338.1406, grad_fn=<MseLossBackward0>)\n",
      "1613 tensor(78335.4688, grad_fn=<MseLossBackward0>)\n",
      "1614 tensor(78332.7891, grad_fn=<MseLossBackward0>)\n",
      "1615 tensor(78330.1250, grad_fn=<MseLossBackward0>)\n",
      "1616 tensor(78327.4531, grad_fn=<MseLossBackward0>)\n",
      "1617 tensor(78324.7891, grad_fn=<MseLossBackward0>)\n",
      "1618 tensor(78322.1172, grad_fn=<MseLossBackward0>)\n",
      "1619 tensor(78319.4609, grad_fn=<MseLossBackward0>)\n",
      "1620 tensor(78316.8047, grad_fn=<MseLossBackward0>)\n",
      "1621 tensor(78314.1406, grad_fn=<MseLossBackward0>)\n",
      "1622 tensor(78311.4844, grad_fn=<MseLossBackward0>)\n",
      "1623 tensor(78308.8281, grad_fn=<MseLossBackward0>)\n",
      "1624 tensor(78306.1797, grad_fn=<MseLossBackward0>)\n",
      "1625 tensor(78303.5312, grad_fn=<MseLossBackward0>)\n",
      "1626 tensor(78300.8750, grad_fn=<MseLossBackward0>)\n",
      "1627 tensor(78298.2188, grad_fn=<MseLossBackward0>)\n",
      "1628 tensor(78295.5781, grad_fn=<MseLossBackward0>)\n",
      "1629 tensor(78292.9375, grad_fn=<MseLossBackward0>)\n",
      "1630 tensor(78290.2969, grad_fn=<MseLossBackward0>)\n",
      "1631 tensor(78287.6562, grad_fn=<MseLossBackward0>)\n",
      "1632 tensor(78285.0156, grad_fn=<MseLossBackward0>)\n",
      "1633 tensor(78282.3828, grad_fn=<MseLossBackward0>)\n",
      "1634 tensor(78279.7500, grad_fn=<MseLossBackward0>)\n",
      "1635 tensor(78277.1172, grad_fn=<MseLossBackward0>)\n",
      "1636 tensor(78274.4844, grad_fn=<MseLossBackward0>)\n",
      "1637 tensor(78271.8672, grad_fn=<MseLossBackward0>)\n",
      "1638 tensor(78269.2344, grad_fn=<MseLossBackward0>)\n",
      "1639 tensor(78266.6172, grad_fn=<MseLossBackward0>)\n",
      "1640 tensor(78263.9844, grad_fn=<MseLossBackward0>)\n",
      "1641 tensor(78261.3750, grad_fn=<MseLossBackward0>)\n",
      "1642 tensor(78258.7578, grad_fn=<MseLossBackward0>)\n",
      "1643 tensor(78256.1406, grad_fn=<MseLossBackward0>)\n",
      "1644 tensor(78253.5156, grad_fn=<MseLossBackward0>)\n",
      "1645 tensor(78250.9141, grad_fn=<MseLossBackward0>)\n",
      "1646 tensor(78248.3047, grad_fn=<MseLossBackward0>)\n",
      "1647 tensor(78245.6953, grad_fn=<MseLossBackward0>)\n",
      "1648 tensor(78243.0938, grad_fn=<MseLossBackward0>)\n",
      "1649 tensor(78240.4844, grad_fn=<MseLossBackward0>)\n",
      "1650 tensor(78237.8828, grad_fn=<MseLossBackward0>)\n",
      "1651 tensor(78235.2812, grad_fn=<MseLossBackward0>)\n",
      "1652 tensor(78232.6875, grad_fn=<MseLossBackward0>)\n",
      "1653 tensor(78230.0859, grad_fn=<MseLossBackward0>)\n",
      "1654 tensor(78227.4844, grad_fn=<MseLossBackward0>)\n",
      "1655 tensor(78224.8906, grad_fn=<MseLossBackward0>)\n",
      "1656 tensor(78222.3047, grad_fn=<MseLossBackward0>)\n",
      "1657 tensor(78219.7188, grad_fn=<MseLossBackward0>)\n",
      "1658 tensor(78217.1328, grad_fn=<MseLossBackward0>)\n",
      "1659 tensor(78214.5469, grad_fn=<MseLossBackward0>)\n",
      "1660 tensor(78211.9609, grad_fn=<MseLossBackward0>)\n",
      "1661 tensor(78209.3828, grad_fn=<MseLossBackward0>)\n",
      "1662 tensor(78206.8047, grad_fn=<MseLossBackward0>)\n",
      "1663 tensor(78204.2266, grad_fn=<MseLossBackward0>)\n",
      "1664 tensor(78201.6484, grad_fn=<MseLossBackward0>)\n",
      "1665 tensor(78199.0781, grad_fn=<MseLossBackward0>)\n",
      "1666 tensor(78196.5156, grad_fn=<MseLossBackward0>)\n",
      "1667 tensor(78193.9375, grad_fn=<MseLossBackward0>)\n",
      "1668 tensor(78191.3672, grad_fn=<MseLossBackward0>)\n",
      "1669 tensor(78188.8047, grad_fn=<MseLossBackward0>)\n",
      "1670 tensor(78186.2422, grad_fn=<MseLossBackward0>)\n",
      "1671 tensor(78183.6875, grad_fn=<MseLossBackward0>)\n",
      "1672 tensor(78181.1250, grad_fn=<MseLossBackward0>)\n",
      "1673 tensor(78178.5625, grad_fn=<MseLossBackward0>)\n",
      "1674 tensor(78176.0078, grad_fn=<MseLossBackward0>)\n",
      "1675 tensor(78173.4609, grad_fn=<MseLossBackward0>)\n",
      "1676 tensor(78170.9062, grad_fn=<MseLossBackward0>)\n",
      "1677 tensor(78168.3516, grad_fn=<MseLossBackward0>)\n",
      "1678 tensor(78165.8047, grad_fn=<MseLossBackward0>)\n",
      "1679 tensor(78163.2578, grad_fn=<MseLossBackward0>)\n",
      "1680 tensor(78160.7188, grad_fn=<MseLossBackward0>)\n",
      "1681 tensor(78158.1797, grad_fn=<MseLossBackward0>)\n",
      "1682 tensor(78155.6406, grad_fn=<MseLossBackward0>)\n",
      "1683 tensor(78153.0938, grad_fn=<MseLossBackward0>)\n",
      "1684 tensor(78150.5547, grad_fn=<MseLossBackward0>)\n",
      "1685 tensor(78148.0234, grad_fn=<MseLossBackward0>)\n",
      "1686 tensor(78145.4922, grad_fn=<MseLossBackward0>)\n",
      "1687 tensor(78142.9609, grad_fn=<MseLossBackward0>)\n",
      "1688 tensor(78140.4297, grad_fn=<MseLossBackward0>)\n",
      "1689 tensor(78137.9062, grad_fn=<MseLossBackward0>)\n",
      "1690 tensor(78135.3828, grad_fn=<MseLossBackward0>)\n",
      "1691 tensor(78132.8594, grad_fn=<MseLossBackward0>)\n",
      "1692 tensor(78130.3359, grad_fn=<MseLossBackward0>)\n",
      "1693 tensor(78127.8125, grad_fn=<MseLossBackward0>)\n",
      "1694 tensor(78125.3047, grad_fn=<MseLossBackward0>)\n",
      "1695 tensor(78122.7891, grad_fn=<MseLossBackward0>)\n",
      "1696 tensor(78120.2812, grad_fn=<MseLossBackward0>)\n",
      "1697 tensor(78117.7656, grad_fn=<MseLossBackward0>)\n",
      "1698 tensor(78115.2578, grad_fn=<MseLossBackward0>)\n",
      "1699 tensor(78112.7500, grad_fn=<MseLossBackward0>)\n",
      "1700 tensor(78110.2422, grad_fn=<MseLossBackward0>)\n",
      "1701 tensor(78107.7422, grad_fn=<MseLossBackward0>)\n",
      "1702 tensor(78105.2422, grad_fn=<MseLossBackward0>)\n",
      "1703 tensor(78102.7422, grad_fn=<MseLossBackward0>)\n",
      "1704 tensor(78100.2500, grad_fn=<MseLossBackward0>)\n",
      "1705 tensor(78097.7422, grad_fn=<MseLossBackward0>)\n",
      "1706 tensor(78095.2578, grad_fn=<MseLossBackward0>)\n",
      "1707 tensor(78092.7656, grad_fn=<MseLossBackward0>)\n",
      "1708 tensor(78090.2656, grad_fn=<MseLossBackward0>)\n",
      "1709 tensor(78087.7891, grad_fn=<MseLossBackward0>)\n",
      "1710 tensor(78085.2969, grad_fn=<MseLossBackward0>)\n",
      "1711 tensor(78082.8125, grad_fn=<MseLossBackward0>)\n",
      "1712 tensor(78080.3359, grad_fn=<MseLossBackward0>)\n",
      "1713 tensor(78077.8594, grad_fn=<MseLossBackward0>)\n",
      "1714 tensor(78075.3672, grad_fn=<MseLossBackward0>)\n",
      "1715 tensor(78072.8984, grad_fn=<MseLossBackward0>)\n",
      "1716 tensor(78070.4141, grad_fn=<MseLossBackward0>)\n",
      "1717 tensor(78067.9531, grad_fn=<MseLossBackward0>)\n",
      "1718 tensor(78065.4766, grad_fn=<MseLossBackward0>)\n",
      "1719 tensor(78063.0156, grad_fn=<MseLossBackward0>)\n",
      "1720 tensor(78060.5391, grad_fn=<MseLossBackward0>)\n",
      "1721 tensor(78058.0781, grad_fn=<MseLossBackward0>)\n",
      "1722 tensor(78055.6250, grad_fn=<MseLossBackward0>)\n",
      "1723 tensor(78053.1562, grad_fn=<MseLossBackward0>)\n",
      "1724 tensor(78050.6953, grad_fn=<MseLossBackward0>)\n",
      "1725 tensor(78048.2500, grad_fn=<MseLossBackward0>)\n",
      "1726 tensor(78045.7969, grad_fn=<MseLossBackward0>)\n",
      "1727 tensor(78043.3438, grad_fn=<MseLossBackward0>)\n",
      "1728 tensor(78040.8828, grad_fn=<MseLossBackward0>)\n",
      "1729 tensor(78038.4375, grad_fn=<MseLossBackward0>)\n",
      "1730 tensor(78035.9922, grad_fn=<MseLossBackward0>)\n",
      "1731 tensor(78033.5547, grad_fn=<MseLossBackward0>)\n",
      "1732 tensor(78031.0938, grad_fn=<MseLossBackward0>)\n",
      "1733 tensor(78028.6641, grad_fn=<MseLossBackward0>)\n",
      "1734 tensor(78026.2188, grad_fn=<MseLossBackward0>)\n",
      "1735 tensor(78023.7812, grad_fn=<MseLossBackward0>)\n",
      "1736 tensor(78021.3438, grad_fn=<MseLossBackward0>)\n",
      "1737 tensor(78018.9141, grad_fn=<MseLossBackward0>)\n",
      "1738 tensor(78016.4844, grad_fn=<MseLossBackward0>)\n",
      "1739 tensor(78014.0547, grad_fn=<MseLossBackward0>)\n",
      "1740 tensor(78011.6250, grad_fn=<MseLossBackward0>)\n",
      "1741 tensor(78009.1953, grad_fn=<MseLossBackward0>)\n",
      "1742 tensor(78006.7734, grad_fn=<MseLossBackward0>)\n",
      "1743 tensor(78004.3516, grad_fn=<MseLossBackward0>)\n",
      "1744 tensor(78001.9297, grad_fn=<MseLossBackward0>)\n",
      "1745 tensor(77999.5078, grad_fn=<MseLossBackward0>)\n",
      "1746 tensor(77997.1016, grad_fn=<MseLossBackward0>)\n",
      "1747 tensor(77994.6875, grad_fn=<MseLossBackward0>)\n",
      "1748 tensor(77992.2734, grad_fn=<MseLossBackward0>)\n",
      "1749 tensor(77989.8672, grad_fn=<MseLossBackward0>)\n",
      "1750 tensor(77987.4609, grad_fn=<MseLossBackward0>)\n",
      "1751 tensor(77985.0547, grad_fn=<MseLossBackward0>)\n",
      "1752 tensor(77982.6484, grad_fn=<MseLossBackward0>)\n",
      "1753 tensor(77980.2500, grad_fn=<MseLossBackward0>)\n",
      "1754 tensor(77977.8516, grad_fn=<MseLossBackward0>)\n",
      "1755 tensor(77975.4375, grad_fn=<MseLossBackward0>)\n",
      "1756 tensor(77973.0469, grad_fn=<MseLossBackward0>)\n",
      "1757 tensor(77970.6562, grad_fn=<MseLossBackward0>)\n",
      "1758 tensor(77968.2578, grad_fn=<MseLossBackward0>)\n",
      "1759 tensor(77965.8750, grad_fn=<MseLossBackward0>)\n",
      "1760 tensor(77963.4766, grad_fn=<MseLossBackward0>)\n",
      "1761 tensor(77961.0938, grad_fn=<MseLossBackward0>)\n",
      "1762 tensor(77958.7109, grad_fn=<MseLossBackward0>)\n",
      "1763 tensor(77956.3203, grad_fn=<MseLossBackward0>)\n",
      "1764 tensor(77953.9375, grad_fn=<MseLossBackward0>)\n",
      "1765 tensor(77951.5625, grad_fn=<MseLossBackward0>)\n",
      "1766 tensor(77949.1875, grad_fn=<MseLossBackward0>)\n",
      "1767 tensor(77946.8125, grad_fn=<MseLossBackward0>)\n",
      "1768 tensor(77944.4375, grad_fn=<MseLossBackward0>)\n",
      "1769 tensor(77942.0625, grad_fn=<MseLossBackward0>)\n",
      "1770 tensor(77939.6875, grad_fn=<MseLossBackward0>)\n",
      "1771 tensor(77937.3359, grad_fn=<MseLossBackward0>)\n",
      "1772 tensor(77934.9609, grad_fn=<MseLossBackward0>)\n",
      "1773 tensor(77932.6016, grad_fn=<MseLossBackward0>)\n",
      "1774 tensor(77930.2344, grad_fn=<MseLossBackward0>)\n",
      "1775 tensor(77927.8750, grad_fn=<MseLossBackward0>)\n",
      "1776 tensor(77925.5156, grad_fn=<MseLossBackward0>)\n",
      "1777 tensor(77923.1641, grad_fn=<MseLossBackward0>)\n",
      "1778 tensor(77920.7969, grad_fn=<MseLossBackward0>)\n",
      "1779 tensor(77918.4609, grad_fn=<MseLossBackward0>)\n",
      "1780 tensor(77916.1016, grad_fn=<MseLossBackward0>)\n",
      "1781 tensor(77913.7578, grad_fn=<MseLossBackward0>)\n",
      "1782 tensor(77911.4062, grad_fn=<MseLossBackward0>)\n",
      "1783 tensor(77909.0703, grad_fn=<MseLossBackward0>)\n",
      "1784 tensor(77906.7188, grad_fn=<MseLossBackward0>)\n",
      "1785 tensor(77904.3750, grad_fn=<MseLossBackward0>)\n",
      "1786 tensor(77902.0391, grad_fn=<MseLossBackward0>)\n",
      "1787 tensor(77899.7031, grad_fn=<MseLossBackward0>)\n",
      "1788 tensor(77897.3750, grad_fn=<MseLossBackward0>)\n",
      "1789 tensor(77895.0391, grad_fn=<MseLossBackward0>)\n",
      "1790 tensor(77892.7031, grad_fn=<MseLossBackward0>)\n",
      "1791 tensor(77890.3750, grad_fn=<MseLossBackward0>)\n",
      "1792 tensor(77888.0547, grad_fn=<MseLossBackward0>)\n",
      "1793 tensor(77885.7266, grad_fn=<MseLossBackward0>)\n",
      "1794 tensor(77883.3984, grad_fn=<MseLossBackward0>)\n",
      "1795 tensor(77881.0781, grad_fn=<MseLossBackward0>)\n",
      "1796 tensor(77878.7578, grad_fn=<MseLossBackward0>)\n",
      "1797 tensor(77876.4375, grad_fn=<MseLossBackward0>)\n",
      "1798 tensor(77874.1172, grad_fn=<MseLossBackward0>)\n",
      "1799 tensor(77871.8047, grad_fn=<MseLossBackward0>)\n",
      "1800 tensor(77869.5000, grad_fn=<MseLossBackward0>)\n",
      "1801 tensor(77867.1875, grad_fn=<MseLossBackward0>)\n",
      "1802 tensor(77864.8828, grad_fn=<MseLossBackward0>)\n",
      "1803 tensor(77862.5703, grad_fn=<MseLossBackward0>)\n",
      "1804 tensor(77860.2656, grad_fn=<MseLossBackward0>)\n",
      "1805 tensor(77857.9688, grad_fn=<MseLossBackward0>)\n",
      "1806 tensor(77855.6719, grad_fn=<MseLossBackward0>)\n",
      "1807 tensor(77853.3672, grad_fn=<MseLossBackward0>)\n",
      "1808 tensor(77851.0703, grad_fn=<MseLossBackward0>)\n",
      "1809 tensor(77848.7734, grad_fn=<MseLossBackward0>)\n",
      "1810 tensor(77846.4844, grad_fn=<MseLossBackward0>)\n",
      "1811 tensor(77844.1875, grad_fn=<MseLossBackward0>)\n",
      "1812 tensor(77841.8984, grad_fn=<MseLossBackward0>)\n",
      "1813 tensor(77839.6094, grad_fn=<MseLossBackward0>)\n",
      "1814 tensor(77837.3359, grad_fn=<MseLossBackward0>)\n",
      "1815 tensor(77835.0391, grad_fn=<MseLossBackward0>)\n",
      "1816 tensor(77832.7656, grad_fn=<MseLossBackward0>)\n",
      "1817 tensor(77830.4922, grad_fn=<MseLossBackward0>)\n",
      "1818 tensor(77828.2031, grad_fn=<MseLossBackward0>)\n",
      "1819 tensor(77825.9297, grad_fn=<MseLossBackward0>)\n",
      "1820 tensor(77823.6562, grad_fn=<MseLossBackward0>)\n",
      "1821 tensor(77821.3906, grad_fn=<MseLossBackward0>)\n",
      "1822 tensor(77819.1172, grad_fn=<MseLossBackward0>)\n",
      "1823 tensor(77816.8516, grad_fn=<MseLossBackward0>)\n",
      "1824 tensor(77814.5938, grad_fn=<MseLossBackward0>)\n",
      "1825 tensor(77812.3125, grad_fn=<MseLossBackward0>)\n",
      "1826 tensor(77810.0547, grad_fn=<MseLossBackward0>)\n",
      "1827 tensor(77807.7969, grad_fn=<MseLossBackward0>)\n",
      "1828 tensor(77805.5391, grad_fn=<MseLossBackward0>)\n",
      "1829 tensor(77803.2891, grad_fn=<MseLossBackward0>)\n",
      "1830 tensor(77801.0312, grad_fn=<MseLossBackward0>)\n",
      "1831 tensor(77798.7812, grad_fn=<MseLossBackward0>)\n",
      "1832 tensor(77796.5234, grad_fn=<MseLossBackward0>)\n",
      "1833 tensor(77794.2812, grad_fn=<MseLossBackward0>)\n",
      "1834 tensor(77792.0234, grad_fn=<MseLossBackward0>)\n",
      "1835 tensor(77789.7812, grad_fn=<MseLossBackward0>)\n",
      "1836 tensor(77787.5391, grad_fn=<MseLossBackward0>)\n",
      "1837 tensor(77785.3047, grad_fn=<MseLossBackward0>)\n",
      "1838 tensor(77783.0625, grad_fn=<MseLossBackward0>)\n",
      "1839 tensor(77780.8203, grad_fn=<MseLossBackward0>)\n",
      "1840 tensor(77778.5938, grad_fn=<MseLossBackward0>)\n",
      "1841 tensor(77776.3516, grad_fn=<MseLossBackward0>)\n",
      "1842 tensor(77774.1250, grad_fn=<MseLossBackward0>)\n",
      "1843 tensor(77771.8984, grad_fn=<MseLossBackward0>)\n",
      "1844 tensor(77769.6641, grad_fn=<MseLossBackward0>)\n",
      "1845 tensor(77767.4297, grad_fn=<MseLossBackward0>)\n",
      "1846 tensor(77765.2109, grad_fn=<MseLossBackward0>)\n",
      "1847 tensor(77762.9922, grad_fn=<MseLossBackward0>)\n",
      "1848 tensor(77760.7734, grad_fn=<MseLossBackward0>)\n",
      "1849 tensor(77758.5547, grad_fn=<MseLossBackward0>)\n",
      "1850 tensor(77756.3359, grad_fn=<MseLossBackward0>)\n",
      "1851 tensor(77754.1250, grad_fn=<MseLossBackward0>)\n",
      "1852 tensor(77751.9141, grad_fn=<MseLossBackward0>)\n",
      "1853 tensor(77749.6953, grad_fn=<MseLossBackward0>)\n",
      "1854 tensor(77747.4922, grad_fn=<MseLossBackward0>)\n",
      "1855 tensor(77745.2891, grad_fn=<MseLossBackward0>)\n",
      "1856 tensor(77743.0781, grad_fn=<MseLossBackward0>)\n",
      "1857 tensor(77740.8750, grad_fn=<MseLossBackward0>)\n",
      "1858 tensor(77738.6719, grad_fn=<MseLossBackward0>)\n",
      "1859 tensor(77736.4688, grad_fn=<MseLossBackward0>)\n",
      "1860 tensor(77734.2656, grad_fn=<MseLossBackward0>)\n",
      "1861 tensor(77732.0859, grad_fn=<MseLossBackward0>)\n",
      "1862 tensor(77729.8906, grad_fn=<MseLossBackward0>)\n",
      "1863 tensor(77727.6953, grad_fn=<MseLossBackward0>)\n",
      "1864 tensor(77725.5078, grad_fn=<MseLossBackward0>)\n",
      "1865 tensor(77723.3203, grad_fn=<MseLossBackward0>)\n",
      "1866 tensor(77721.1406, grad_fn=<MseLossBackward0>)\n",
      "1867 tensor(77718.9531, grad_fn=<MseLossBackward0>)\n",
      "1868 tensor(77716.7734, grad_fn=<MseLossBackward0>)\n",
      "1869 tensor(77714.5859, grad_fn=<MseLossBackward0>)\n",
      "1870 tensor(77712.4141, grad_fn=<MseLossBackward0>)\n",
      "1871 tensor(77710.2344, grad_fn=<MseLossBackward0>)\n",
      "1872 tensor(77708.0625, grad_fn=<MseLossBackward0>)\n",
      "1873 tensor(77705.8906, grad_fn=<MseLossBackward0>)\n",
      "1874 tensor(77703.7188, grad_fn=<MseLossBackward0>)\n",
      "1875 tensor(77701.5469, grad_fn=<MseLossBackward0>)\n",
      "1876 tensor(77699.3750, grad_fn=<MseLossBackward0>)\n",
      "1877 tensor(77697.2109, grad_fn=<MseLossBackward0>)\n",
      "1878 tensor(77695.0547, grad_fn=<MseLossBackward0>)\n",
      "1879 tensor(77692.8828, grad_fn=<MseLossBackward0>)\n",
      "1880 tensor(77690.7266, grad_fn=<MseLossBackward0>)\n",
      "1881 tensor(77688.5781, grad_fn=<MseLossBackward0>)\n",
      "1882 tensor(77686.4141, grad_fn=<MseLossBackward0>)\n",
      "1883 tensor(77684.2578, grad_fn=<MseLossBackward0>)\n",
      "1884 tensor(77682.1094, grad_fn=<MseLossBackward0>)\n",
      "1885 tensor(77679.9609, grad_fn=<MseLossBackward0>)\n",
      "1886 tensor(77677.8125, grad_fn=<MseLossBackward0>)\n",
      "1887 tensor(77675.6641, grad_fn=<MseLossBackward0>)\n",
      "1888 tensor(77673.5234, grad_fn=<MseLossBackward0>)\n",
      "1889 tensor(77671.3750, grad_fn=<MseLossBackward0>)\n",
      "1890 tensor(77669.2422, grad_fn=<MseLossBackward0>)\n",
      "1891 tensor(77667.1094, grad_fn=<MseLossBackward0>)\n",
      "1892 tensor(77664.9609, grad_fn=<MseLossBackward0>)\n",
      "1893 tensor(77662.8281, grad_fn=<MseLossBackward0>)\n",
      "1894 tensor(77660.7031, grad_fn=<MseLossBackward0>)\n",
      "1895 tensor(77658.5703, grad_fn=<MseLossBackward0>)\n",
      "1896 tensor(77656.4297, grad_fn=<MseLossBackward0>)\n",
      "1897 tensor(77654.3125, grad_fn=<MseLossBackward0>)\n",
      "1898 tensor(77652.1875, grad_fn=<MseLossBackward0>)\n",
      "1899 tensor(77650.0625, grad_fn=<MseLossBackward0>)\n",
      "1900 tensor(77647.9453, grad_fn=<MseLossBackward0>)\n",
      "1901 tensor(77645.8203, grad_fn=<MseLossBackward0>)\n",
      "1902 tensor(77643.7031, grad_fn=<MseLossBackward0>)\n",
      "1903 tensor(77641.5938, grad_fn=<MseLossBackward0>)\n",
      "1904 tensor(77639.4766, grad_fn=<MseLossBackward0>)\n",
      "1905 tensor(77637.3594, grad_fn=<MseLossBackward0>)\n",
      "1906 tensor(77635.2578, grad_fn=<MseLossBackward0>)\n",
      "1907 tensor(77633.1484, grad_fn=<MseLossBackward0>)\n",
      "1908 tensor(77631.0469, grad_fn=<MseLossBackward0>)\n",
      "1909 tensor(77628.9375, grad_fn=<MseLossBackward0>)\n",
      "1910 tensor(77626.8359, grad_fn=<MseLossBackward0>)\n",
      "1911 tensor(77624.7266, grad_fn=<MseLossBackward0>)\n",
      "1912 tensor(77622.6250, grad_fn=<MseLossBackward0>)\n",
      "1913 tensor(77620.5391, grad_fn=<MseLossBackward0>)\n",
      "1914 tensor(77618.4453, grad_fn=<MseLossBackward0>)\n",
      "1915 tensor(77616.3516, grad_fn=<MseLossBackward0>)\n",
      "1916 tensor(77614.2578, grad_fn=<MseLossBackward0>)\n",
      "1917 tensor(77612.1719, grad_fn=<MseLossBackward0>)\n",
      "1918 tensor(77610.0859, grad_fn=<MseLossBackward0>)\n",
      "1919 tensor(77608., grad_fn=<MseLossBackward0>)\n",
      "1920 tensor(77605.9141, grad_fn=<MseLossBackward0>)\n",
      "1921 tensor(77603.8281, grad_fn=<MseLossBackward0>)\n",
      "1922 tensor(77601.7578, grad_fn=<MseLossBackward0>)\n",
      "1923 tensor(77599.6719, grad_fn=<MseLossBackward0>)\n",
      "1924 tensor(77597.5859, grad_fn=<MseLossBackward0>)\n",
      "1925 tensor(77595.5234, grad_fn=<MseLossBackward0>)\n",
      "1926 tensor(77593.4531, grad_fn=<MseLossBackward0>)\n",
      "1927 tensor(77591.3750, grad_fn=<MseLossBackward0>)\n",
      "1928 tensor(77589.3125, grad_fn=<MseLossBackward0>)\n",
      "1929 tensor(77587.2422, grad_fn=<MseLossBackward0>)\n",
      "1930 tensor(77585.1719, grad_fn=<MseLossBackward0>)\n",
      "1931 tensor(77583.1094, grad_fn=<MseLossBackward0>)\n",
      "1932 tensor(77581.0469, grad_fn=<MseLossBackward0>)\n",
      "1933 tensor(77578.9844, grad_fn=<MseLossBackward0>)\n",
      "1934 tensor(77576.9453, grad_fn=<MseLossBackward0>)\n",
      "1935 tensor(77574.8828, grad_fn=<MseLossBackward0>)\n",
      "1936 tensor(77572.8281, grad_fn=<MseLossBackward0>)\n",
      "1937 tensor(77570.7812, grad_fn=<MseLossBackward0>)\n",
      "1938 tensor(77568.7266, grad_fn=<MseLossBackward0>)\n",
      "1939 tensor(77566.6797, grad_fn=<MseLossBackward0>)\n",
      "1940 tensor(77564.6328, grad_fn=<MseLossBackward0>)\n",
      "1941 tensor(77562.5859, grad_fn=<MseLossBackward0>)\n",
      "1942 tensor(77560.5469, grad_fn=<MseLossBackward0>)\n",
      "1943 tensor(77558.5078, grad_fn=<MseLossBackward0>)\n",
      "1944 tensor(77556.4688, grad_fn=<MseLossBackward0>)\n",
      "1945 tensor(77554.4297, grad_fn=<MseLossBackward0>)\n",
      "1946 tensor(77552.3906, grad_fn=<MseLossBackward0>)\n",
      "1947 tensor(77550.3672, grad_fn=<MseLossBackward0>)\n",
      "1948 tensor(77548.3281, grad_fn=<MseLossBackward0>)\n",
      "1949 tensor(77546.3047, grad_fn=<MseLossBackward0>)\n",
      "1950 tensor(77544.2734, grad_fn=<MseLossBackward0>)\n",
      "1951 tensor(77542.2500, grad_fn=<MseLossBackward0>)\n",
      "1952 tensor(77540.2188, grad_fn=<MseLossBackward0>)\n",
      "1953 tensor(77538.2031, grad_fn=<MseLossBackward0>)\n",
      "1954 tensor(77536.1875, grad_fn=<MseLossBackward0>)\n",
      "1955 tensor(77534.1562, grad_fn=<MseLossBackward0>)\n",
      "1956 tensor(77532.1562, grad_fn=<MseLossBackward0>)\n",
      "1957 tensor(77530.1328, grad_fn=<MseLossBackward0>)\n",
      "1958 tensor(77528.1172, grad_fn=<MseLossBackward0>)\n",
      "1959 tensor(77526.1094, grad_fn=<MseLossBackward0>)\n",
      "1960 tensor(77524.1016, grad_fn=<MseLossBackward0>)\n",
      "1961 tensor(77522.0938, grad_fn=<MseLossBackward0>)\n",
      "1962 tensor(77520.0938, grad_fn=<MseLossBackward0>)\n",
      "1963 tensor(77518.0938, grad_fn=<MseLossBackward0>)\n",
      "1964 tensor(77516.0859, grad_fn=<MseLossBackward0>)\n",
      "1965 tensor(77514.0859, grad_fn=<MseLossBackward0>)\n",
      "1966 tensor(77512.0859, grad_fn=<MseLossBackward0>)\n",
      "1967 tensor(77510.0938, grad_fn=<MseLossBackward0>)\n",
      "1968 tensor(77508.1094, grad_fn=<MseLossBackward0>)\n",
      "1969 tensor(77506.1172, grad_fn=<MseLossBackward0>)\n",
      "1970 tensor(77504.1250, grad_fn=<MseLossBackward0>)\n",
      "1971 tensor(77502.1250, grad_fn=<MseLossBackward0>)\n",
      "1972 tensor(77500.1484, grad_fn=<MseLossBackward0>)\n",
      "1973 tensor(77498.1641, grad_fn=<MseLossBackward0>)\n",
      "1974 tensor(77496.1797, grad_fn=<MseLossBackward0>)\n",
      "1975 tensor(77494.1953, grad_fn=<MseLossBackward0>)\n",
      "1976 tensor(77492.2188, grad_fn=<MseLossBackward0>)\n",
      "1977 tensor(77490.2422, grad_fn=<MseLossBackward0>)\n",
      "1978 tensor(77488.2656, grad_fn=<MseLossBackward0>)\n",
      "1979 tensor(77486.2891, grad_fn=<MseLossBackward0>)\n",
      "1980 tensor(77484.3281, grad_fn=<MseLossBackward0>)\n",
      "1981 tensor(77482.3516, grad_fn=<MseLossBackward0>)\n",
      "1982 tensor(77480.3906, grad_fn=<MseLossBackward0>)\n",
      "1983 tensor(77478.4219, grad_fn=<MseLossBackward0>)\n",
      "1984 tensor(77476.4609, grad_fn=<MseLossBackward0>)\n",
      "1985 tensor(77474.4922, grad_fn=<MseLossBackward0>)\n",
      "1986 tensor(77472.5312, grad_fn=<MseLossBackward0>)\n",
      "1987 tensor(77470.5781, grad_fn=<MseLossBackward0>)\n",
      "1988 tensor(77468.6094, grad_fn=<MseLossBackward0>)\n",
      "1989 tensor(77466.6641, grad_fn=<MseLossBackward0>)\n",
      "1990 tensor(77464.7109, grad_fn=<MseLossBackward0>)\n",
      "1991 tensor(77462.7656, grad_fn=<MseLossBackward0>)\n",
      "1992 tensor(77460.8125, grad_fn=<MseLossBackward0>)\n",
      "1993 tensor(77458.8594, grad_fn=<MseLossBackward0>)\n",
      "1994 tensor(77456.9219, grad_fn=<MseLossBackward0>)\n",
      "1995 tensor(77454.9766, grad_fn=<MseLossBackward0>)\n",
      "1996 tensor(77453.0391, grad_fn=<MseLossBackward0>)\n",
      "1997 tensor(77451.0938, grad_fn=<MseLossBackward0>)\n",
      "1998 tensor(77449.1562, grad_fn=<MseLossBackward0>)\n",
      "1999 tensor(77447.2344, grad_fn=<MseLossBackward0>)\n",
      "2000 tensor(77445.2891, grad_fn=<MseLossBackward0>)\n",
      "2001 tensor(77443.3516, grad_fn=<MseLossBackward0>)\n",
      "2002 tensor(77441.4219, grad_fn=<MseLossBackward0>)\n",
      "2003 tensor(77439.5000, grad_fn=<MseLossBackward0>)\n",
      "2004 tensor(77437.5625, grad_fn=<MseLossBackward0>)\n",
      "2005 tensor(77435.6562, grad_fn=<MseLossBackward0>)\n",
      "2006 tensor(77433.7188, grad_fn=<MseLossBackward0>)\n",
      "2007 tensor(77431.8047, grad_fn=<MseLossBackward0>)\n",
      "2008 tensor(77429.8750, grad_fn=<MseLossBackward0>)\n",
      "2009 tensor(77427.9688, grad_fn=<MseLossBackward0>)\n",
      "2010 tensor(77426.0391, grad_fn=<MseLossBackward0>)\n",
      "2011 tensor(77424.1328, grad_fn=<MseLossBackward0>)\n",
      "2012 tensor(77422.2188, grad_fn=<MseLossBackward0>)\n",
      "2013 tensor(77420.3125, grad_fn=<MseLossBackward0>)\n",
      "2014 tensor(77418.3984, grad_fn=<MseLossBackward0>)\n",
      "2015 tensor(77416.5000, grad_fn=<MseLossBackward0>)\n",
      "2016 tensor(77414.5859, grad_fn=<MseLossBackward0>)\n",
      "2017 tensor(77412.6875, grad_fn=<MseLossBackward0>)\n",
      "2018 tensor(77410.7969, grad_fn=<MseLossBackward0>)\n",
      "2019 tensor(77408.8828, grad_fn=<MseLossBackward0>)\n",
      "2020 tensor(77406.9922, grad_fn=<MseLossBackward0>)\n",
      "2021 tensor(77405.1016, grad_fn=<MseLossBackward0>)\n",
      "2022 tensor(77403.1953, grad_fn=<MseLossBackward0>)\n",
      "2023 tensor(77401.3047, grad_fn=<MseLossBackward0>)\n",
      "2024 tensor(77399.4219, grad_fn=<MseLossBackward0>)\n",
      "2025 tensor(77397.5391, grad_fn=<MseLossBackward0>)\n",
      "2026 tensor(77395.6484, grad_fn=<MseLossBackward0>)\n",
      "2027 tensor(77393.7578, grad_fn=<MseLossBackward0>)\n",
      "2028 tensor(77391.8750, grad_fn=<MseLossBackward0>)\n",
      "2029 tensor(77390., grad_fn=<MseLossBackward0>)\n",
      "2030 tensor(77388.1250, grad_fn=<MseLossBackward0>)\n",
      "2031 tensor(77386.2500, grad_fn=<MseLossBackward0>)\n",
      "2032 tensor(77384.3672, grad_fn=<MseLossBackward0>)\n",
      "2033 tensor(77382.5000, grad_fn=<MseLossBackward0>)\n",
      "2034 tensor(77380.6172, grad_fn=<MseLossBackward0>)\n",
      "2035 tensor(77378.7500, grad_fn=<MseLossBackward0>)\n",
      "2036 tensor(77376.8828, grad_fn=<MseLossBackward0>)\n",
      "2037 tensor(77375.0156, grad_fn=<MseLossBackward0>)\n",
      "2038 tensor(77373.1641, grad_fn=<MseLossBackward0>)\n",
      "2039 tensor(77371.2969, grad_fn=<MseLossBackward0>)\n",
      "2040 tensor(77369.4297, grad_fn=<MseLossBackward0>)\n",
      "2041 tensor(77367.5703, grad_fn=<MseLossBackward0>)\n",
      "2042 tensor(77365.7109, grad_fn=<MseLossBackward0>)\n",
      "2043 tensor(77363.8594, grad_fn=<MseLossBackward0>)\n",
      "2044 tensor(77362., grad_fn=<MseLossBackward0>)\n",
      "2045 tensor(77360.1484, grad_fn=<MseLossBackward0>)\n",
      "2046 tensor(77358.3047, grad_fn=<MseLossBackward0>)\n",
      "2047 tensor(77356.4531, grad_fn=<MseLossBackward0>)\n",
      "2048 tensor(77354.6172, grad_fn=<MseLossBackward0>)\n",
      "2049 tensor(77352.7734, grad_fn=<MseLossBackward0>)\n",
      "2050 tensor(77350.9219, grad_fn=<MseLossBackward0>)\n",
      "2051 tensor(77349.0859, grad_fn=<MseLossBackward0>)\n",
      "2052 tensor(77347.2500, grad_fn=<MseLossBackward0>)\n",
      "2053 tensor(77345.4141, grad_fn=<MseLossBackward0>)\n",
      "2054 tensor(77343.5781, grad_fn=<MseLossBackward0>)\n",
      "2055 tensor(77341.7422, grad_fn=<MseLossBackward0>)\n",
      "2056 tensor(77339.9062, grad_fn=<MseLossBackward0>)\n",
      "2057 tensor(77338.0781, grad_fn=<MseLossBackward0>)\n",
      "2058 tensor(77336.2500, grad_fn=<MseLossBackward0>)\n",
      "2059 tensor(77334.4297, grad_fn=<MseLossBackward0>)\n",
      "2060 tensor(77332.6016, grad_fn=<MseLossBackward0>)\n",
      "2061 tensor(77330.7734, grad_fn=<MseLossBackward0>)\n",
      "2062 tensor(77328.9609, grad_fn=<MseLossBackward0>)\n",
      "2063 tensor(77327.1406, grad_fn=<MseLossBackward0>)\n",
      "2064 tensor(77325.3281, grad_fn=<MseLossBackward0>)\n",
      "2065 tensor(77323.5156, grad_fn=<MseLossBackward0>)\n",
      "2066 tensor(77321.7031, grad_fn=<MseLossBackward0>)\n",
      "2067 tensor(77319.8906, grad_fn=<MseLossBackward0>)\n",
      "2068 tensor(77318.0781, grad_fn=<MseLossBackward0>)\n",
      "2069 tensor(77316.2578, grad_fn=<MseLossBackward0>)\n",
      "2070 tensor(77314.4688, grad_fn=<MseLossBackward0>)\n",
      "2071 tensor(77312.6641, grad_fn=<MseLossBackward0>)\n",
      "2072 tensor(77310.8516, grad_fn=<MseLossBackward0>)\n",
      "2073 tensor(77309.0547, grad_fn=<MseLossBackward0>)\n",
      "2074 tensor(77307.2578, grad_fn=<MseLossBackward0>)\n",
      "2075 tensor(77305.4688, grad_fn=<MseLossBackward0>)\n",
      "2076 tensor(77303.6719, grad_fn=<MseLossBackward0>)\n",
      "2077 tensor(77301.8750, grad_fn=<MseLossBackward0>)\n",
      "2078 tensor(77300.0859, grad_fn=<MseLossBackward0>)\n",
      "2079 tensor(77298.2891, grad_fn=<MseLossBackward0>)\n",
      "2080 tensor(77296.5078, grad_fn=<MseLossBackward0>)\n",
      "2081 tensor(77294.7109, grad_fn=<MseLossBackward0>)\n",
      "2082 tensor(77292.9375, grad_fn=<MseLossBackward0>)\n",
      "2083 tensor(77291.1562, grad_fn=<MseLossBackward0>)\n",
      "2084 tensor(77289.3750, grad_fn=<MseLossBackward0>)\n",
      "2085 tensor(77287.5938, grad_fn=<MseLossBackward0>)\n",
      "2086 tensor(77285.8203, grad_fn=<MseLossBackward0>)\n",
      "2087 tensor(77284.0469, grad_fn=<MseLossBackward0>)\n",
      "2088 tensor(77282.2656, grad_fn=<MseLossBackward0>)\n",
      "2089 tensor(77280.4922, grad_fn=<MseLossBackward0>)\n",
      "2090 tensor(77278.7266, grad_fn=<MseLossBackward0>)\n",
      "2091 tensor(77276.9609, grad_fn=<MseLossBackward0>)\n",
      "2092 tensor(77275.1953, grad_fn=<MseLossBackward0>)\n",
      "2093 tensor(77273.4297, grad_fn=<MseLossBackward0>)\n",
      "2094 tensor(77271.6641, grad_fn=<MseLossBackward0>)\n",
      "2095 tensor(77269.9141, grad_fn=<MseLossBackward0>)\n",
      "2096 tensor(77268.1484, grad_fn=<MseLossBackward0>)\n",
      "2097 tensor(77266.3984, grad_fn=<MseLossBackward0>)\n",
      "2098 tensor(77264.6328, grad_fn=<MseLossBackward0>)\n",
      "2099 tensor(77262.8828, grad_fn=<MseLossBackward0>)\n",
      "2100 tensor(77261.1328, grad_fn=<MseLossBackward0>)\n",
      "2101 tensor(77259.3906, grad_fn=<MseLossBackward0>)\n",
      "2102 tensor(77257.6328, grad_fn=<MseLossBackward0>)\n",
      "2103 tensor(77255.8984, grad_fn=<MseLossBackward0>)\n",
      "2104 tensor(77254.1406, grad_fn=<MseLossBackward0>)\n",
      "2105 tensor(77252.4062, grad_fn=<MseLossBackward0>)\n",
      "2106 tensor(77250.6641, grad_fn=<MseLossBackward0>)\n",
      "2107 tensor(77248.9297, grad_fn=<MseLossBackward0>)\n",
      "2108 tensor(77247.1875, grad_fn=<MseLossBackward0>)\n",
      "2109 tensor(77245.4531, grad_fn=<MseLossBackward0>)\n",
      "2110 tensor(77243.7188, grad_fn=<MseLossBackward0>)\n",
      "2111 tensor(77241.9922, grad_fn=<MseLossBackward0>)\n",
      "2112 tensor(77240.2578, grad_fn=<MseLossBackward0>)\n",
      "2113 tensor(77238.5234, grad_fn=<MseLossBackward0>)\n",
      "2114 tensor(77236.7969, grad_fn=<MseLossBackward0>)\n",
      "2115 tensor(77235.0781, grad_fn=<MseLossBackward0>)\n",
      "2116 tensor(77233.3516, grad_fn=<MseLossBackward0>)\n",
      "2117 tensor(77231.6406, grad_fn=<MseLossBackward0>)\n",
      "2118 tensor(77229.9219, grad_fn=<MseLossBackward0>)\n",
      "2119 tensor(77228.1953, grad_fn=<MseLossBackward0>)\n",
      "2120 tensor(77226.4844, grad_fn=<MseLossBackward0>)\n",
      "2121 tensor(77224.7656, grad_fn=<MseLossBackward0>)\n",
      "2122 tensor(77223.0547, grad_fn=<MseLossBackward0>)\n",
      "2123 tensor(77221.3438, grad_fn=<MseLossBackward0>)\n",
      "2124 tensor(77219.6328, grad_fn=<MseLossBackward0>)\n",
      "2125 tensor(77217.9375, grad_fn=<MseLossBackward0>)\n",
      "2126 tensor(77216.2188, grad_fn=<MseLossBackward0>)\n",
      "2127 tensor(77214.5312, grad_fn=<MseLossBackward0>)\n",
      "2128 tensor(77212.8281, grad_fn=<MseLossBackward0>)\n",
      "2129 tensor(77211.1250, grad_fn=<MseLossBackward0>)\n",
      "2130 tensor(77209.4219, grad_fn=<MseLossBackward0>)\n",
      "2131 tensor(77207.7344, grad_fn=<MseLossBackward0>)\n",
      "2132 tensor(77206.0312, grad_fn=<MseLossBackward0>)\n",
      "2133 tensor(77204.3438, grad_fn=<MseLossBackward0>)\n",
      "2134 tensor(77202.6562, grad_fn=<MseLossBackward0>)\n",
      "2135 tensor(77200.9609, grad_fn=<MseLossBackward0>)\n",
      "2136 tensor(77199.2734, grad_fn=<MseLossBackward0>)\n",
      "2137 tensor(77197.5938, grad_fn=<MseLossBackward0>)\n",
      "2138 tensor(77195.9141, grad_fn=<MseLossBackward0>)\n",
      "2139 tensor(77194.2266, grad_fn=<MseLossBackward0>)\n",
      "2140 tensor(77192.5469, grad_fn=<MseLossBackward0>)\n",
      "2141 tensor(77190.8672, grad_fn=<MseLossBackward0>)\n",
      "2142 tensor(77189.2031, grad_fn=<MseLossBackward0>)\n",
      "2143 tensor(77187.5156, grad_fn=<MseLossBackward0>)\n",
      "2144 tensor(77185.8359, grad_fn=<MseLossBackward0>)\n",
      "2145 tensor(77184.1719, grad_fn=<MseLossBackward0>)\n",
      "2146 tensor(77182.5078, grad_fn=<MseLossBackward0>)\n",
      "2147 tensor(77180.8359, grad_fn=<MseLossBackward0>)\n",
      "2148 tensor(77179.1719, grad_fn=<MseLossBackward0>)\n",
      "2149 tensor(77177.5078, grad_fn=<MseLossBackward0>)\n",
      "2150 tensor(77175.8438, grad_fn=<MseLossBackward0>)\n",
      "2151 tensor(77174.1875, grad_fn=<MseLossBackward0>)\n",
      "2152 tensor(77172.5234, grad_fn=<MseLossBackward0>)\n",
      "2153 tensor(77170.8750, grad_fn=<MseLossBackward0>)\n",
      "2154 tensor(77169.2188, grad_fn=<MseLossBackward0>)\n",
      "2155 tensor(77167.5625, grad_fn=<MseLossBackward0>)\n",
      "2156 tensor(77165.9219, grad_fn=<MseLossBackward0>)\n",
      "2157 tensor(77164.2656, grad_fn=<MseLossBackward0>)\n",
      "2158 tensor(77162.6094, grad_fn=<MseLossBackward0>)\n",
      "2159 tensor(77160.9688, grad_fn=<MseLossBackward0>)\n",
      "2160 tensor(77159.3281, grad_fn=<MseLossBackward0>)\n",
      "2161 tensor(77157.6797, grad_fn=<MseLossBackward0>)\n",
      "2162 tensor(77156.0469, grad_fn=<MseLossBackward0>)\n",
      "2163 tensor(77154.4062, grad_fn=<MseLossBackward0>)\n",
      "2164 tensor(77152.7656, grad_fn=<MseLossBackward0>)\n",
      "2165 tensor(77151.1250, grad_fn=<MseLossBackward0>)\n",
      "2166 tensor(77149.5000, grad_fn=<MseLossBackward0>)\n",
      "2167 tensor(77147.8594, grad_fn=<MseLossBackward0>)\n",
      "2168 tensor(77146.2266, grad_fn=<MseLossBackward0>)\n",
      "2169 tensor(77144.6016, grad_fn=<MseLossBackward0>)\n",
      "2170 tensor(77142.9844, grad_fn=<MseLossBackward0>)\n",
      "2171 tensor(77141.3516, grad_fn=<MseLossBackward0>)\n",
      "2172 tensor(77139.7188, grad_fn=<MseLossBackward0>)\n",
      "2173 tensor(77138.1094, grad_fn=<MseLossBackward0>)\n",
      "2174 tensor(77136.4844, grad_fn=<MseLossBackward0>)\n",
      "2175 tensor(77134.8750, grad_fn=<MseLossBackward0>)\n",
      "2176 tensor(77133.2500, grad_fn=<MseLossBackward0>)\n",
      "2177 tensor(77131.6406, grad_fn=<MseLossBackward0>)\n",
      "2178 tensor(77130.0234, grad_fn=<MseLossBackward0>)\n",
      "2179 tensor(77128.4062, grad_fn=<MseLossBackward0>)\n",
      "2180 tensor(77126.8047, grad_fn=<MseLossBackward0>)\n",
      "2181 tensor(77125.2031, grad_fn=<MseLossBackward0>)\n",
      "2182 tensor(77123.5938, grad_fn=<MseLossBackward0>)\n",
      "2183 tensor(77121.9922, grad_fn=<MseLossBackward0>)\n",
      "2184 tensor(77120.3828, grad_fn=<MseLossBackward0>)\n",
      "2185 tensor(77118.7812, grad_fn=<MseLossBackward0>)\n",
      "2186 tensor(77117.1875, grad_fn=<MseLossBackward0>)\n",
      "2187 tensor(77115.5859, grad_fn=<MseLossBackward0>)\n",
      "2188 tensor(77113.9922, grad_fn=<MseLossBackward0>)\n",
      "2189 tensor(77112.3984, grad_fn=<MseLossBackward0>)\n",
      "2190 tensor(77110.8125, grad_fn=<MseLossBackward0>)\n",
      "2191 tensor(77109.2109, grad_fn=<MseLossBackward0>)\n",
      "2192 tensor(77107.6406, grad_fn=<MseLossBackward0>)\n",
      "2193 tensor(77106.0469, grad_fn=<MseLossBackward0>)\n",
      "2194 tensor(77104.4688, grad_fn=<MseLossBackward0>)\n",
      "2195 tensor(77102.8750, grad_fn=<MseLossBackward0>)\n",
      "2196 tensor(77101.3047, grad_fn=<MseLossBackward0>)\n",
      "2197 tensor(77099.7188, grad_fn=<MseLossBackward0>)\n",
      "2198 tensor(77098.1328, grad_fn=<MseLossBackward0>)\n",
      "2199 tensor(77096.5625, grad_fn=<MseLossBackward0>)\n",
      "2200 tensor(77094.9922, grad_fn=<MseLossBackward0>)\n",
      "2201 tensor(77093.4141, grad_fn=<MseLossBackward0>)\n",
      "2202 tensor(77091.8438, grad_fn=<MseLossBackward0>)\n",
      "2203 tensor(77090.2812, grad_fn=<MseLossBackward0>)\n",
      "2204 tensor(77088.7109, grad_fn=<MseLossBackward0>)\n",
      "2205 tensor(77087.1406, grad_fn=<MseLossBackward0>)\n",
      "2206 tensor(77085.5859, grad_fn=<MseLossBackward0>)\n",
      "2207 tensor(77084.0234, grad_fn=<MseLossBackward0>)\n",
      "2208 tensor(77082.4609, grad_fn=<MseLossBackward0>)\n",
      "2209 tensor(77080.8984, grad_fn=<MseLossBackward0>)\n",
      "2210 tensor(77079.3438, grad_fn=<MseLossBackward0>)\n",
      "2211 tensor(77077.7812, grad_fn=<MseLossBackward0>)\n",
      "2212 tensor(77076.2422, grad_fn=<MseLossBackward0>)\n",
      "2213 tensor(77074.6875, grad_fn=<MseLossBackward0>)\n",
      "2214 tensor(77073.1406, grad_fn=<MseLossBackward0>)\n",
      "2215 tensor(77071.5781, grad_fn=<MseLossBackward0>)\n",
      "2216 tensor(77070.0391, grad_fn=<MseLossBackward0>)\n",
      "2217 tensor(77068.4922, grad_fn=<MseLossBackward0>)\n",
      "2218 tensor(77066.9531, grad_fn=<MseLossBackward0>)\n",
      "2219 tensor(77065.4062, grad_fn=<MseLossBackward0>)\n",
      "2220 tensor(77063.8750, grad_fn=<MseLossBackward0>)\n",
      "2221 tensor(77062.3281, grad_fn=<MseLossBackward0>)\n",
      "2222 tensor(77060.7969, grad_fn=<MseLossBackward0>)\n",
      "2223 tensor(77059.2656, grad_fn=<MseLossBackward0>)\n",
      "2224 tensor(77057.7188, grad_fn=<MseLossBackward0>)\n",
      "2225 tensor(77056.2031, grad_fn=<MseLossBackward0>)\n",
      "2226 tensor(77054.6797, grad_fn=<MseLossBackward0>)\n",
      "2227 tensor(77053.1406, grad_fn=<MseLossBackward0>)\n",
      "2228 tensor(77051.6172, grad_fn=<MseLossBackward0>)\n",
      "2229 tensor(77050.0938, grad_fn=<MseLossBackward0>)\n",
      "2230 tensor(77048.5781, grad_fn=<MseLossBackward0>)\n",
      "2231 tensor(77047.0469, grad_fn=<MseLossBackward0>)\n",
      "2232 tensor(77045.5234, grad_fn=<MseLossBackward0>)\n",
      "2233 tensor(77044.0078, grad_fn=<MseLossBackward0>)\n",
      "2234 tensor(77042.5000, grad_fn=<MseLossBackward0>)\n",
      "2235 tensor(77040.9922, grad_fn=<MseLossBackward0>)\n",
      "2236 tensor(77039.4766, grad_fn=<MseLossBackward0>)\n",
      "2237 tensor(77037.9688, grad_fn=<MseLossBackward0>)\n",
      "2238 tensor(77036.4453, grad_fn=<MseLossBackward0>)\n",
      "2239 tensor(77034.9453, grad_fn=<MseLossBackward0>)\n",
      "2240 tensor(77033.4375, grad_fn=<MseLossBackward0>)\n",
      "2241 tensor(77031.9453, grad_fn=<MseLossBackward0>)\n",
      "2242 tensor(77030.4297, grad_fn=<MseLossBackward0>)\n",
      "2243 tensor(77028.9375, grad_fn=<MseLossBackward0>)\n",
      "2244 tensor(77027.4375, grad_fn=<MseLossBackward0>)\n",
      "2245 tensor(77025.9375, grad_fn=<MseLossBackward0>)\n",
      "2246 tensor(77024.4375, grad_fn=<MseLossBackward0>)\n",
      "2247 tensor(77022.9531, grad_fn=<MseLossBackward0>)\n",
      "2248 tensor(77021.4688, grad_fn=<MseLossBackward0>)\n",
      "2249 tensor(77019.9609, grad_fn=<MseLossBackward0>)\n",
      "2250 tensor(77018.4844, grad_fn=<MseLossBackward0>)\n",
      "2251 tensor(77017., grad_fn=<MseLossBackward0>)\n",
      "2252 tensor(77015.5156, grad_fn=<MseLossBackward0>)\n",
      "2253 tensor(77014.0234, grad_fn=<MseLossBackward0>)\n",
      "2254 tensor(77012.5547, grad_fn=<MseLossBackward0>)\n",
      "2255 tensor(77011.0703, grad_fn=<MseLossBackward0>)\n",
      "2256 tensor(77009.5938, grad_fn=<MseLossBackward0>)\n",
      "2257 tensor(77008.1172, grad_fn=<MseLossBackward0>)\n",
      "2258 tensor(77006.6562, grad_fn=<MseLossBackward0>)\n",
      "2259 tensor(77005.1641, grad_fn=<MseLossBackward0>)\n",
      "2260 tensor(77003.6953, grad_fn=<MseLossBackward0>)\n",
      "2261 tensor(77002.2344, grad_fn=<MseLossBackward0>)\n",
      "2262 tensor(77000.7656, grad_fn=<MseLossBackward0>)\n",
      "2263 tensor(76999.2969, grad_fn=<MseLossBackward0>)\n",
      "2264 tensor(76997.8359, grad_fn=<MseLossBackward0>)\n",
      "2265 tensor(76996.3672, grad_fn=<MseLossBackward0>)\n",
      "2266 tensor(76994.9062, grad_fn=<MseLossBackward0>)\n",
      "2267 tensor(76993.4453, grad_fn=<MseLossBackward0>)\n",
      "2268 tensor(76991.9922, grad_fn=<MseLossBackward0>)\n",
      "2269 tensor(76990.5391, grad_fn=<MseLossBackward0>)\n",
      "2270 tensor(76989.0859, grad_fn=<MseLossBackward0>)\n",
      "2271 tensor(76987.6328, grad_fn=<MseLossBackward0>)\n",
      "2272 tensor(76986.1797, grad_fn=<MseLossBackward0>)\n",
      "2273 tensor(76984.7266, grad_fn=<MseLossBackward0>)\n",
      "2274 tensor(76983.2734, grad_fn=<MseLossBackward0>)\n",
      "2275 tensor(76981.8438, grad_fn=<MseLossBackward0>)\n",
      "2276 tensor(76980.3984, grad_fn=<MseLossBackward0>)\n",
      "2277 tensor(76978.9531, grad_fn=<MseLossBackward0>)\n",
      "2278 tensor(76977.5078, grad_fn=<MseLossBackward0>)\n",
      "2279 tensor(76976.0781, grad_fn=<MseLossBackward0>)\n",
      "2280 tensor(76974.6250, grad_fn=<MseLossBackward0>)\n",
      "2281 tensor(76973.2031, grad_fn=<MseLossBackward0>)\n",
      "2282 tensor(76971.7734, grad_fn=<MseLossBackward0>)\n",
      "2283 tensor(76970.3281, grad_fn=<MseLossBackward0>)\n",
      "2284 tensor(76968.8984, grad_fn=<MseLossBackward0>)\n",
      "2285 tensor(76967.4688, grad_fn=<MseLossBackward0>)\n",
      "2286 tensor(76966.0547, grad_fn=<MseLossBackward0>)\n",
      "2287 tensor(76964.6172, grad_fn=<MseLossBackward0>)\n",
      "2288 tensor(76963.1875, grad_fn=<MseLossBackward0>)\n",
      "2289 tensor(76961.7734, grad_fn=<MseLossBackward0>)\n",
      "2290 tensor(76960.3516, grad_fn=<MseLossBackward0>)\n",
      "2291 tensor(76958.9375, grad_fn=<MseLossBackward0>)\n",
      "2292 tensor(76957.5156, grad_fn=<MseLossBackward0>)\n",
      "2293 tensor(76956.1094, grad_fn=<MseLossBackward0>)\n",
      "2294 tensor(76954.6875, grad_fn=<MseLossBackward0>)\n",
      "2295 tensor(76953.2812, grad_fn=<MseLossBackward0>)\n",
      "2296 tensor(76951.8750, grad_fn=<MseLossBackward0>)\n",
      "2297 tensor(76950.4609, grad_fn=<MseLossBackward0>)\n",
      "2298 tensor(76949.0469, grad_fn=<MseLossBackward0>)\n",
      "2299 tensor(76947.6484, grad_fn=<MseLossBackward0>)\n",
      "2300 tensor(76946.2422, grad_fn=<MseLossBackward0>)\n",
      "2301 tensor(76944.8516, grad_fn=<MseLossBackward0>)\n",
      "2302 tensor(76943.4453, grad_fn=<MseLossBackward0>)\n",
      "2303 tensor(76942.0391, grad_fn=<MseLossBackward0>)\n",
      "2304 tensor(76940.6484, grad_fn=<MseLossBackward0>)\n",
      "2305 tensor(76939.2500, grad_fn=<MseLossBackward0>)\n",
      "2306 tensor(76937.8594, grad_fn=<MseLossBackward0>)\n",
      "2307 tensor(76936.4609, grad_fn=<MseLossBackward0>)\n",
      "2308 tensor(76935.0781, grad_fn=<MseLossBackward0>)\n",
      "2309 tensor(76933.6875, grad_fn=<MseLossBackward0>)\n",
      "2310 tensor(76932.2969, grad_fn=<MseLossBackward0>)\n",
      "2311 tensor(76930.9141, grad_fn=<MseLossBackward0>)\n",
      "2312 tensor(76929.5312, grad_fn=<MseLossBackward0>)\n",
      "2313 tensor(76928.1484, grad_fn=<MseLossBackward0>)\n",
      "2314 tensor(76926.7656, grad_fn=<MseLossBackward0>)\n",
      "2315 tensor(76925.3906, grad_fn=<MseLossBackward0>)\n",
      "2316 tensor(76924., grad_fn=<MseLossBackward0>)\n",
      "2317 tensor(76922.6406, grad_fn=<MseLossBackward0>)\n",
      "2318 tensor(76921.2578, grad_fn=<MseLossBackward0>)\n",
      "2319 tensor(76919.8906, grad_fn=<MseLossBackward0>)\n",
      "2320 tensor(76918.5156, grad_fn=<MseLossBackward0>)\n",
      "2321 tensor(76917.1484, grad_fn=<MseLossBackward0>)\n",
      "2322 tensor(76915.7891, grad_fn=<MseLossBackward0>)\n",
      "2323 tensor(76914.4219, grad_fn=<MseLossBackward0>)\n",
      "2324 tensor(76913.0547, grad_fn=<MseLossBackward0>)\n",
      "2325 tensor(76911.6953, grad_fn=<MseLossBackward0>)\n",
      "2326 tensor(76910.3438, grad_fn=<MseLossBackward0>)\n",
      "2327 tensor(76908.9688, grad_fn=<MseLossBackward0>)\n",
      "2328 tensor(76907.6250, grad_fn=<MseLossBackward0>)\n",
      "2329 tensor(76906.2656, grad_fn=<MseLossBackward0>)\n",
      "2330 tensor(76904.9062, grad_fn=<MseLossBackward0>)\n",
      "2331 tensor(76903.5625, grad_fn=<MseLossBackward0>)\n",
      "2332 tensor(76902.2031, grad_fn=<MseLossBackward0>)\n",
      "2333 tensor(76900.8594, grad_fn=<MseLossBackward0>)\n",
      "2334 tensor(76899.5156, grad_fn=<MseLossBackward0>)\n",
      "2335 tensor(76898.1641, grad_fn=<MseLossBackward0>)\n",
      "2336 tensor(76896.8203, grad_fn=<MseLossBackward0>)\n",
      "2337 tensor(76895.4766, grad_fn=<MseLossBackward0>)\n",
      "2338 tensor(76894.1328, grad_fn=<MseLossBackward0>)\n",
      "2339 tensor(76892.7969, grad_fn=<MseLossBackward0>)\n",
      "2340 tensor(76891.4609, grad_fn=<MseLossBackward0>)\n",
      "2341 tensor(76890.1250, grad_fn=<MseLossBackward0>)\n",
      "2342 tensor(76888.7891, grad_fn=<MseLossBackward0>)\n",
      "2343 tensor(76887.4609, grad_fn=<MseLossBackward0>)\n",
      "2344 tensor(76886.1250, grad_fn=<MseLossBackward0>)\n",
      "2345 tensor(76884.8047, grad_fn=<MseLossBackward0>)\n",
      "2346 tensor(76883.4766, grad_fn=<MseLossBackward0>)\n",
      "2347 tensor(76882.1484, grad_fn=<MseLossBackward0>)\n",
      "2348 tensor(76880.8125, grad_fn=<MseLossBackward0>)\n",
      "2349 tensor(76879.5000, grad_fn=<MseLossBackward0>)\n",
      "2350 tensor(76878.1719, grad_fn=<MseLossBackward0>)\n",
      "2351 tensor(76876.8594, grad_fn=<MseLossBackward0>)\n",
      "2352 tensor(76875.5391, grad_fn=<MseLossBackward0>)\n",
      "2353 tensor(76874.2188, grad_fn=<MseLossBackward0>)\n",
      "2354 tensor(76872.9141, grad_fn=<MseLossBackward0>)\n",
      "2355 tensor(76871.5938, grad_fn=<MseLossBackward0>)\n",
      "2356 tensor(76870.2891, grad_fn=<MseLossBackward0>)\n",
      "2357 tensor(76868.9766, grad_fn=<MseLossBackward0>)\n",
      "2358 tensor(76867.6719, grad_fn=<MseLossBackward0>)\n",
      "2359 tensor(76866.3594, grad_fn=<MseLossBackward0>)\n",
      "2360 tensor(76865.0625, grad_fn=<MseLossBackward0>)\n",
      "2361 tensor(76863.7500, grad_fn=<MseLossBackward0>)\n",
      "2362 tensor(76862.4453, grad_fn=<MseLossBackward0>)\n",
      "2363 tensor(76861.1484, grad_fn=<MseLossBackward0>)\n",
      "2364 tensor(76859.8516, grad_fn=<MseLossBackward0>)\n",
      "2365 tensor(76858.5625, grad_fn=<MseLossBackward0>)\n",
      "2366 tensor(76857.2500, grad_fn=<MseLossBackward0>)\n",
      "2367 tensor(76855.9688, grad_fn=<MseLossBackward0>)\n",
      "2368 tensor(76854.6719, grad_fn=<MseLossBackward0>)\n",
      "2369 tensor(76853.3750, grad_fn=<MseLossBackward0>)\n",
      "2370 tensor(76852.0859, grad_fn=<MseLossBackward0>)\n",
      "2371 tensor(76850.8047, grad_fn=<MseLossBackward0>)\n",
      "2372 tensor(76849.5234, grad_fn=<MseLossBackward0>)\n",
      "2373 tensor(76848.2422, grad_fn=<MseLossBackward0>)\n",
      "2374 tensor(76846.9531, grad_fn=<MseLossBackward0>)\n",
      "2375 tensor(76845.6797, grad_fn=<MseLossBackward0>)\n",
      "2376 tensor(76844.3984, grad_fn=<MseLossBackward0>)\n",
      "2377 tensor(76843.1094, grad_fn=<MseLossBackward0>)\n",
      "2378 tensor(76841.8359, grad_fn=<MseLossBackward0>)\n",
      "2379 tensor(76840.5703, grad_fn=<MseLossBackward0>)\n",
      "2380 tensor(76839.2969, grad_fn=<MseLossBackward0>)\n",
      "2381 tensor(76838.0312, grad_fn=<MseLossBackward0>)\n",
      "2382 tensor(76836.7578, grad_fn=<MseLossBackward0>)\n",
      "2383 tensor(76835.4922, grad_fn=<MseLossBackward0>)\n",
      "2384 tensor(76834.2188, grad_fn=<MseLossBackward0>)\n",
      "2385 tensor(76832.9531, grad_fn=<MseLossBackward0>)\n",
      "2386 tensor(76831.6953, grad_fn=<MseLossBackward0>)\n",
      "2387 tensor(76830.4297, grad_fn=<MseLossBackward0>)\n",
      "2388 tensor(76829.1719, grad_fn=<MseLossBackward0>)\n",
      "2389 tensor(76827.9141, grad_fn=<MseLossBackward0>)\n",
      "2390 tensor(76826.6484, grad_fn=<MseLossBackward0>)\n",
      "2391 tensor(76825.4062, grad_fn=<MseLossBackward0>)\n",
      "2392 tensor(76824.1406, grad_fn=<MseLossBackward0>)\n",
      "2393 tensor(76822.8906, grad_fn=<MseLossBackward0>)\n",
      "2394 tensor(76821.6484, grad_fn=<MseLossBackward0>)\n",
      "2395 tensor(76820.3984, grad_fn=<MseLossBackward0>)\n",
      "2396 tensor(76819.1562, grad_fn=<MseLossBackward0>)\n",
      "2397 tensor(76817.9062, grad_fn=<MseLossBackward0>)\n",
      "2398 tensor(76816.6562, grad_fn=<MseLossBackward0>)\n",
      "2399 tensor(76815.4219, grad_fn=<MseLossBackward0>)\n",
      "2400 tensor(76814.1797, grad_fn=<MseLossBackward0>)\n",
      "2401 tensor(76812.9375, grad_fn=<MseLossBackward0>)\n",
      "2402 tensor(76811.7031, grad_fn=<MseLossBackward0>)\n",
      "2403 tensor(76810.4688, grad_fn=<MseLossBackward0>)\n",
      "2404 tensor(76809.2344, grad_fn=<MseLossBackward0>)\n",
      "2405 tensor(76807.9922, grad_fn=<MseLossBackward0>)\n",
      "2406 tensor(76806.7656, grad_fn=<MseLossBackward0>)\n",
      "2407 tensor(76805.5391, grad_fn=<MseLossBackward0>)\n",
      "2408 tensor(76804.3047, grad_fn=<MseLossBackward0>)\n",
      "2409 tensor(76803.0781, grad_fn=<MseLossBackward0>)\n",
      "2410 tensor(76801.8516, grad_fn=<MseLossBackward0>)\n",
      "2411 tensor(76800.6406, grad_fn=<MseLossBackward0>)\n",
      "2412 tensor(76799.4062, grad_fn=<MseLossBackward0>)\n",
      "2413 tensor(76798.1875, grad_fn=<MseLossBackward0>)\n",
      "2414 tensor(76796.9766, grad_fn=<MseLossBackward0>)\n",
      "2415 tensor(76795.7578, grad_fn=<MseLossBackward0>)\n",
      "2416 tensor(76794.5469, grad_fn=<MseLossBackward0>)\n",
      "2417 tensor(76793.3281, grad_fn=<MseLossBackward0>)\n",
      "2418 tensor(76792.1094, grad_fn=<MseLossBackward0>)\n",
      "2419 tensor(76790.8984, grad_fn=<MseLossBackward0>)\n",
      "2420 tensor(76789.6953, grad_fn=<MseLossBackward0>)\n",
      "2421 tensor(76788.4922, grad_fn=<MseLossBackward0>)\n",
      "2422 tensor(76787.2812, grad_fn=<MseLossBackward0>)\n",
      "2423 tensor(76786.0703, grad_fn=<MseLossBackward0>)\n",
      "2424 tensor(76784.8672, grad_fn=<MseLossBackward0>)\n",
      "2425 tensor(76783.6641, grad_fn=<MseLossBackward0>)\n",
      "2426 tensor(76782.4688, grad_fn=<MseLossBackward0>)\n",
      "2427 tensor(76781.2734, grad_fn=<MseLossBackward0>)\n",
      "2428 tensor(76780.0703, grad_fn=<MseLossBackward0>)\n",
      "2429 tensor(76778.8750, grad_fn=<MseLossBackward0>)\n",
      "2430 tensor(76777.6797, grad_fn=<MseLossBackward0>)\n",
      "2431 tensor(76776.5000, grad_fn=<MseLossBackward0>)\n",
      "2432 tensor(76775.3047, grad_fn=<MseLossBackward0>)\n",
      "2433 tensor(76774.1250, grad_fn=<MseLossBackward0>)\n",
      "2434 tensor(76772.9297, grad_fn=<MseLossBackward0>)\n",
      "2435 tensor(76771.7422, grad_fn=<MseLossBackward0>)\n",
      "2436 tensor(76770.5469, grad_fn=<MseLossBackward0>)\n",
      "2437 tensor(76769.3750, grad_fn=<MseLossBackward0>)\n",
      "2438 tensor(76768.2031, grad_fn=<MseLossBackward0>)\n",
      "2439 tensor(76767.0078, grad_fn=<MseLossBackward0>)\n",
      "2440 tensor(76765.8359, grad_fn=<MseLossBackward0>)\n",
      "2441 tensor(76764.6562, grad_fn=<MseLossBackward0>)\n",
      "2442 tensor(76763.4922, grad_fn=<MseLossBackward0>)\n",
      "2443 tensor(76762.3047, grad_fn=<MseLossBackward0>)\n",
      "2444 tensor(76761.1484, grad_fn=<MseLossBackward0>)\n",
      "2445 tensor(76759.9688, grad_fn=<MseLossBackward0>)\n",
      "2446 tensor(76758.7969, grad_fn=<MseLossBackward0>)\n",
      "2447 tensor(76757.6328, grad_fn=<MseLossBackward0>)\n",
      "2448 tensor(76756.4688, grad_fn=<MseLossBackward0>)\n",
      "2449 tensor(76755.2969, grad_fn=<MseLossBackward0>)\n",
      "2450 tensor(76754.1406, grad_fn=<MseLossBackward0>)\n",
      "2451 tensor(76752.9766, grad_fn=<MseLossBackward0>)\n",
      "2452 tensor(76751.8203, grad_fn=<MseLossBackward0>)\n",
      "2453 tensor(76750.6641, grad_fn=<MseLossBackward0>)\n",
      "2454 tensor(76749.5078, grad_fn=<MseLossBackward0>)\n",
      "2455 tensor(76748.3516, grad_fn=<MseLossBackward0>)\n",
      "2456 tensor(76747.1953, grad_fn=<MseLossBackward0>)\n",
      "2457 tensor(76746.0469, grad_fn=<MseLossBackward0>)\n",
      "2458 tensor(76744.8984, grad_fn=<MseLossBackward0>)\n",
      "2459 tensor(76743.7422, grad_fn=<MseLossBackward0>)\n",
      "2460 tensor(76742.6016, grad_fn=<MseLossBackward0>)\n",
      "2461 tensor(76741.4453, grad_fn=<MseLossBackward0>)\n",
      "2462 tensor(76740.3125, grad_fn=<MseLossBackward0>)\n",
      "2463 tensor(76739.1641, grad_fn=<MseLossBackward0>)\n",
      "2464 tensor(76738.0312, grad_fn=<MseLossBackward0>)\n",
      "2465 tensor(76736.8828, grad_fn=<MseLossBackward0>)\n",
      "2466 tensor(76735.7422, grad_fn=<MseLossBackward0>)\n",
      "2467 tensor(76734.6094, grad_fn=<MseLossBackward0>)\n",
      "2468 tensor(76733.4766, grad_fn=<MseLossBackward0>)\n",
      "2469 tensor(76732.3359, grad_fn=<MseLossBackward0>)\n",
      "2470 tensor(76731.2109, grad_fn=<MseLossBackward0>)\n",
      "2471 tensor(76730.0781, grad_fn=<MseLossBackward0>)\n",
      "2472 tensor(76728.9453, grad_fn=<MseLossBackward0>)\n",
      "2473 tensor(76727.8203, grad_fn=<MseLossBackward0>)\n",
      "2474 tensor(76726.7031, grad_fn=<MseLossBackward0>)\n",
      "2475 tensor(76725.5781, grad_fn=<MseLossBackward0>)\n",
      "2476 tensor(76724.4453, grad_fn=<MseLossBackward0>)\n",
      "2477 tensor(76723.3281, grad_fn=<MseLossBackward0>)\n",
      "2478 tensor(76722.2188, grad_fn=<MseLossBackward0>)\n",
      "2479 tensor(76721.1016, grad_fn=<MseLossBackward0>)\n",
      "2480 tensor(76719.9766, grad_fn=<MseLossBackward0>)\n",
      "2481 tensor(76718.8594, grad_fn=<MseLossBackward0>)\n",
      "2482 tensor(76717.7422, grad_fn=<MseLossBackward0>)\n",
      "2483 tensor(76716.6328, grad_fn=<MseLossBackward0>)\n",
      "2484 tensor(76715.5234, grad_fn=<MseLossBackward0>)\n",
      "2485 tensor(76714.4141, grad_fn=<MseLossBackward0>)\n",
      "2486 tensor(76713.3125, grad_fn=<MseLossBackward0>)\n",
      "2487 tensor(76712.2031, grad_fn=<MseLossBackward0>)\n",
      "2488 tensor(76711.0938, grad_fn=<MseLossBackward0>)\n",
      "2489 tensor(76710., grad_fn=<MseLossBackward0>)\n",
      "2490 tensor(76708.8906, grad_fn=<MseLossBackward0>)\n",
      "2491 tensor(76707.7969, grad_fn=<MseLossBackward0>)\n",
      "2492 tensor(76706.6875, grad_fn=<MseLossBackward0>)\n",
      "2493 tensor(76705.5938, grad_fn=<MseLossBackward0>)\n",
      "2494 tensor(76704.5000, grad_fn=<MseLossBackward0>)\n",
      "2495 tensor(76703.4062, grad_fn=<MseLossBackward0>)\n",
      "2496 tensor(76702.3125, grad_fn=<MseLossBackward0>)\n",
      "2497 tensor(76701.2266, grad_fn=<MseLossBackward0>)\n",
      "2498 tensor(76700.1406, grad_fn=<MseLossBackward0>)\n",
      "2499 tensor(76699.0469, grad_fn=<MseLossBackward0>)\n",
      "2500 tensor(76697.9531, grad_fn=<MseLossBackward0>)\n",
      "2501 tensor(76696.8672, grad_fn=<MseLossBackward0>)\n",
      "2502 tensor(76695.7812, grad_fn=<MseLossBackward0>)\n",
      "2503 tensor(76694.7031, grad_fn=<MseLossBackward0>)\n",
      "2504 tensor(76693.6172, grad_fn=<MseLossBackward0>)\n",
      "2505 tensor(76692.5391, grad_fn=<MseLossBackward0>)\n",
      "2506 tensor(76691.4688, grad_fn=<MseLossBackward0>)\n",
      "2507 tensor(76690.3906, grad_fn=<MseLossBackward0>)\n",
      "2508 tensor(76689.3125, grad_fn=<MseLossBackward0>)\n",
      "2509 tensor(76688.2422, grad_fn=<MseLossBackward0>)\n",
      "2510 tensor(76687.1719, grad_fn=<MseLossBackward0>)\n",
      "2511 tensor(76686.1094, grad_fn=<MseLossBackward0>)\n",
      "2512 tensor(76685.0234, grad_fn=<MseLossBackward0>)\n",
      "2513 tensor(76683.9688, grad_fn=<MseLossBackward0>)\n",
      "2514 tensor(76682.9062, grad_fn=<MseLossBackward0>)\n",
      "2515 tensor(76681.8281, grad_fn=<MseLossBackward0>)\n",
      "2516 tensor(76680.7734, grad_fn=<MseLossBackward0>)\n",
      "2517 tensor(76679.7109, grad_fn=<MseLossBackward0>)\n",
      "2518 tensor(76678.6406, grad_fn=<MseLossBackward0>)\n",
      "2519 tensor(76677.5859, grad_fn=<MseLossBackward0>)\n",
      "2520 tensor(76676.5391, grad_fn=<MseLossBackward0>)\n",
      "2521 tensor(76675.4766, grad_fn=<MseLossBackward0>)\n",
      "2522 tensor(76674.4219, grad_fn=<MseLossBackward0>)\n",
      "2523 tensor(76673.3672, grad_fn=<MseLossBackward0>)\n",
      "2524 tensor(76672.3203, grad_fn=<MseLossBackward0>)\n",
      "2525 tensor(76671.2734, grad_fn=<MseLossBackward0>)\n",
      "2526 tensor(76670.2188, grad_fn=<MseLossBackward0>)\n",
      "2527 tensor(76669.1719, grad_fn=<MseLossBackward0>)\n",
      "2528 tensor(76668.1328, grad_fn=<MseLossBackward0>)\n",
      "2529 tensor(76667.0859, grad_fn=<MseLossBackward0>)\n",
      "2530 tensor(76666.0391, grad_fn=<MseLossBackward0>)\n",
      "2531 tensor(76665., grad_fn=<MseLossBackward0>)\n",
      "2532 tensor(76663.9688, grad_fn=<MseLossBackward0>)\n",
      "2533 tensor(76662.9297, grad_fn=<MseLossBackward0>)\n",
      "2534 tensor(76661.8906, grad_fn=<MseLossBackward0>)\n",
      "2535 tensor(76660.8594, grad_fn=<MseLossBackward0>)\n",
      "2536 tensor(76659.8203, grad_fn=<MseLossBackward0>)\n",
      "2537 tensor(76658.7812, grad_fn=<MseLossBackward0>)\n",
      "2538 tensor(76657.7578, grad_fn=<MseLossBackward0>)\n",
      "2539 tensor(76656.7266, grad_fn=<MseLossBackward0>)\n",
      "2540 tensor(76655.6953, grad_fn=<MseLossBackward0>)\n",
      "2541 tensor(76654.6719, grad_fn=<MseLossBackward0>)\n",
      "2542 tensor(76653.6484, grad_fn=<MseLossBackward0>)\n",
      "2543 tensor(76652.6250, grad_fn=<MseLossBackward0>)\n",
      "2544 tensor(76651.6094, grad_fn=<MseLossBackward0>)\n",
      "2545 tensor(76650.5859, grad_fn=<MseLossBackward0>)\n",
      "2546 tensor(76649.5625, grad_fn=<MseLossBackward0>)\n",
      "2547 tensor(76648.5469, grad_fn=<MseLossBackward0>)\n",
      "2548 tensor(76647.5312, grad_fn=<MseLossBackward0>)\n",
      "2549 tensor(76646.5156, grad_fn=<MseLossBackward0>)\n",
      "2550 tensor(76645.5000, grad_fn=<MseLossBackward0>)\n",
      "2551 tensor(76644.4922, grad_fn=<MseLossBackward0>)\n",
      "2552 tensor(76643.4844, grad_fn=<MseLossBackward0>)\n",
      "2553 tensor(76642.4688, grad_fn=<MseLossBackward0>)\n",
      "2554 tensor(76641.4609, grad_fn=<MseLossBackward0>)\n",
      "2555 tensor(76640.4609, grad_fn=<MseLossBackward0>)\n",
      "2556 tensor(76639.4531, grad_fn=<MseLossBackward0>)\n",
      "2557 tensor(76638.4531, grad_fn=<MseLossBackward0>)\n",
      "2558 tensor(76637.4453, grad_fn=<MseLossBackward0>)\n",
      "2559 tensor(76636.4531, grad_fn=<MseLossBackward0>)\n",
      "2560 tensor(76635.4453, grad_fn=<MseLossBackward0>)\n",
      "2561 tensor(76634.4375, grad_fn=<MseLossBackward0>)\n",
      "2562 tensor(76633.4453, grad_fn=<MseLossBackward0>)\n",
      "2563 tensor(76632.4531, grad_fn=<MseLossBackward0>)\n",
      "2564 tensor(76631.4609, grad_fn=<MseLossBackward0>)\n",
      "2565 tensor(76630.4688, grad_fn=<MseLossBackward0>)\n",
      "2566 tensor(76629.4766, grad_fn=<MseLossBackward0>)\n",
      "2567 tensor(76628.5000, grad_fn=<MseLossBackward0>)\n",
      "2568 tensor(76627.5078, grad_fn=<MseLossBackward0>)\n",
      "2569 tensor(76626.5156, grad_fn=<MseLossBackward0>)\n",
      "2570 tensor(76625.5234, grad_fn=<MseLossBackward0>)\n",
      "2571 tensor(76624.5469, grad_fn=<MseLossBackward0>)\n",
      "2572 tensor(76623.5703, grad_fn=<MseLossBackward0>)\n",
      "2573 tensor(76622.5938, grad_fn=<MseLossBackward0>)\n",
      "2574 tensor(76621.6094, grad_fn=<MseLossBackward0>)\n",
      "2575 tensor(76620.6328, grad_fn=<MseLossBackward0>)\n",
      "2576 tensor(76619.6562, grad_fn=<MseLossBackward0>)\n",
      "2577 tensor(76618.6875, grad_fn=<MseLossBackward0>)\n",
      "2578 tensor(76617.7109, grad_fn=<MseLossBackward0>)\n",
      "2579 tensor(76616.7344, grad_fn=<MseLossBackward0>)\n",
      "2580 tensor(76615.7656, grad_fn=<MseLossBackward0>)\n",
      "2581 tensor(76614.8047, grad_fn=<MseLossBackward0>)\n",
      "2582 tensor(76613.8281, grad_fn=<MseLossBackward0>)\n",
      "2583 tensor(76612.8672, grad_fn=<MseLossBackward0>)\n",
      "2584 tensor(76611.8984, grad_fn=<MseLossBackward0>)\n",
      "2585 tensor(76610.9219, grad_fn=<MseLossBackward0>)\n",
      "2586 tensor(76609.9688, grad_fn=<MseLossBackward0>)\n",
      "2587 tensor(76609.0156, grad_fn=<MseLossBackward0>)\n",
      "2588 tensor(76608.0547, grad_fn=<MseLossBackward0>)\n",
      "2589 tensor(76607.0859, grad_fn=<MseLossBackward0>)\n",
      "2590 tensor(76606.1406, grad_fn=<MseLossBackward0>)\n",
      "2591 tensor(76605.1797, grad_fn=<MseLossBackward0>)\n",
      "2592 tensor(76604.2266, grad_fn=<MseLossBackward0>)\n",
      "2593 tensor(76603.2734, grad_fn=<MseLossBackward0>)\n",
      "2594 tensor(76602.3281, grad_fn=<MseLossBackward0>)\n",
      "2595 tensor(76601.3828, grad_fn=<MseLossBackward0>)\n",
      "2596 tensor(76600.4297, grad_fn=<MseLossBackward0>)\n",
      "2597 tensor(76599.4844, grad_fn=<MseLossBackward0>)\n",
      "2598 tensor(76598.5391, grad_fn=<MseLossBackward0>)\n",
      "2599 tensor(76597.6094, grad_fn=<MseLossBackward0>)\n",
      "2600 tensor(76596.6406, grad_fn=<MseLossBackward0>)\n",
      "2601 tensor(76595.7031, grad_fn=<MseLossBackward0>)\n",
      "2602 tensor(76594.7734, grad_fn=<MseLossBackward0>)\n",
      "2603 tensor(76593.8281, grad_fn=<MseLossBackward0>)\n",
      "2604 tensor(76592.8984, grad_fn=<MseLossBackward0>)\n",
      "2605 tensor(76591.9609, grad_fn=<MseLossBackward0>)\n",
      "2606 tensor(76591.0312, grad_fn=<MseLossBackward0>)\n",
      "2607 tensor(76590.0938, grad_fn=<MseLossBackward0>)\n",
      "2608 tensor(76589.1641, grad_fn=<MseLossBackward0>)\n",
      "2609 tensor(76588.2266, grad_fn=<MseLossBackward0>)\n",
      "2610 tensor(76587.2969, grad_fn=<MseLossBackward0>)\n",
      "2611 tensor(76586.3672, grad_fn=<MseLossBackward0>)\n",
      "2612 tensor(76585.4375, grad_fn=<MseLossBackward0>)\n",
      "2613 tensor(76584.5312, grad_fn=<MseLossBackward0>)\n",
      "2614 tensor(76583.6016, grad_fn=<MseLossBackward0>)\n",
      "2615 tensor(76582.6797, grad_fn=<MseLossBackward0>)\n",
      "2616 tensor(76581.7578, grad_fn=<MseLossBackward0>)\n",
      "2617 tensor(76580.8359, grad_fn=<MseLossBackward0>)\n",
      "2618 tensor(76579.9219, grad_fn=<MseLossBackward0>)\n",
      "2619 tensor(76579.0078, grad_fn=<MseLossBackward0>)\n",
      "2620 tensor(76578.0859, grad_fn=<MseLossBackward0>)\n",
      "2621 tensor(76577.1719, grad_fn=<MseLossBackward0>)\n",
      "2622 tensor(76576.2656, grad_fn=<MseLossBackward0>)\n",
      "2623 tensor(76575.3438, grad_fn=<MseLossBackward0>)\n",
      "2624 tensor(76574.4453, grad_fn=<MseLossBackward0>)\n",
      "2625 tensor(76573.5391, grad_fn=<MseLossBackward0>)\n",
      "2626 tensor(76572.6250, grad_fn=<MseLossBackward0>)\n",
      "2627 tensor(76571.7266, grad_fn=<MseLossBackward0>)\n",
      "2628 tensor(76570.8125, grad_fn=<MseLossBackward0>)\n",
      "2629 tensor(76569.9141, grad_fn=<MseLossBackward0>)\n",
      "2630 tensor(76569.0156, grad_fn=<MseLossBackward0>)\n",
      "2631 tensor(76568.1172, grad_fn=<MseLossBackward0>)\n",
      "2632 tensor(76567.2188, grad_fn=<MseLossBackward0>)\n",
      "2633 tensor(76566.3203, grad_fn=<MseLossBackward0>)\n",
      "2634 tensor(76565.4219, grad_fn=<MseLossBackward0>)\n",
      "2635 tensor(76564.5234, grad_fn=<MseLossBackward0>)\n",
      "2636 tensor(76563.6328, grad_fn=<MseLossBackward0>)\n",
      "2637 tensor(76562.7422, grad_fn=<MseLossBackward0>)\n",
      "2638 tensor(76561.8516, grad_fn=<MseLossBackward0>)\n",
      "2639 tensor(76560.9609, grad_fn=<MseLossBackward0>)\n",
      "2640 tensor(76560.0781, grad_fn=<MseLossBackward0>)\n",
      "2641 tensor(76559.1953, grad_fn=<MseLossBackward0>)\n",
      "2642 tensor(76558.3047, grad_fn=<MseLossBackward0>)\n",
      "2643 tensor(76557.4219, grad_fn=<MseLossBackward0>)\n",
      "2644 tensor(76556.5469, grad_fn=<MseLossBackward0>)\n",
      "2645 tensor(76555.6641, grad_fn=<MseLossBackward0>)\n",
      "2646 tensor(76554.7812, grad_fn=<MseLossBackward0>)\n",
      "2647 tensor(76553.8984, grad_fn=<MseLossBackward0>)\n",
      "2648 tensor(76553.0312, grad_fn=<MseLossBackward0>)\n",
      "2649 tensor(76552.1484, grad_fn=<MseLossBackward0>)\n",
      "2650 tensor(76551.2734, grad_fn=<MseLossBackward0>)\n",
      "2651 tensor(76550.4062, grad_fn=<MseLossBackward0>)\n",
      "2652 tensor(76549.5312, grad_fn=<MseLossBackward0>)\n",
      "2653 tensor(76548.6562, grad_fn=<MseLossBackward0>)\n",
      "2654 tensor(76547.7891, grad_fn=<MseLossBackward0>)\n",
      "2655 tensor(76546.9141, grad_fn=<MseLossBackward0>)\n",
      "2656 tensor(76546.0469, grad_fn=<MseLossBackward0>)\n",
      "2657 tensor(76545.1953, grad_fn=<MseLossBackward0>)\n",
      "2658 tensor(76544.3203, grad_fn=<MseLossBackward0>)\n",
      "2659 tensor(76543.4688, grad_fn=<MseLossBackward0>)\n",
      "2660 tensor(76542.6172, grad_fn=<MseLossBackward0>)\n",
      "2661 tensor(76541.7422, grad_fn=<MseLossBackward0>)\n",
      "2662 tensor(76540.8828, grad_fn=<MseLossBackward0>)\n",
      "2663 tensor(76540.0234, grad_fn=<MseLossBackward0>)\n",
      "2664 tensor(76539.1719, grad_fn=<MseLossBackward0>)\n",
      "2665 tensor(76538.3125, grad_fn=<MseLossBackward0>)\n",
      "2666 tensor(76537.4688, grad_fn=<MseLossBackward0>)\n",
      "2667 tensor(76536.6094, grad_fn=<MseLossBackward0>)\n",
      "2668 tensor(76535.7656, grad_fn=<MseLossBackward0>)\n",
      "2669 tensor(76534.9141, grad_fn=<MseLossBackward0>)\n",
      "2670 tensor(76534.0625, grad_fn=<MseLossBackward0>)\n",
      "2671 tensor(76533.2188, grad_fn=<MseLossBackward0>)\n",
      "2672 tensor(76532.3828, grad_fn=<MseLossBackward0>)\n",
      "2673 tensor(76531.5391, grad_fn=<MseLossBackward0>)\n",
      "2674 tensor(76530.6875, grad_fn=<MseLossBackward0>)\n",
      "2675 tensor(76529.8516, grad_fn=<MseLossBackward0>)\n",
      "2676 tensor(76529.0078, grad_fn=<MseLossBackward0>)\n",
      "2677 tensor(76528.1719, grad_fn=<MseLossBackward0>)\n",
      "2678 tensor(76527.3281, grad_fn=<MseLossBackward0>)\n",
      "2679 tensor(76526.4922, grad_fn=<MseLossBackward0>)\n",
      "2680 tensor(76525.6562, grad_fn=<MseLossBackward0>)\n",
      "2681 tensor(76524.8203, grad_fn=<MseLossBackward0>)\n",
      "2682 tensor(76523.9844, grad_fn=<MseLossBackward0>)\n",
      "2683 tensor(76523.1641, grad_fn=<MseLossBackward0>)\n",
      "2684 tensor(76522.3281, grad_fn=<MseLossBackward0>)\n",
      "2685 tensor(76521.5078, grad_fn=<MseLossBackward0>)\n",
      "2686 tensor(76520.6719, grad_fn=<MseLossBackward0>)\n",
      "2687 tensor(76519.8516, grad_fn=<MseLossBackward0>)\n",
      "2688 tensor(76519.0234, grad_fn=<MseLossBackward0>)\n",
      "2689 tensor(76518.1953, grad_fn=<MseLossBackward0>)\n",
      "2690 tensor(76517.3828, grad_fn=<MseLossBackward0>)\n",
      "2691 tensor(76516.5625, grad_fn=<MseLossBackward0>)\n",
      "2692 tensor(76515.7422, grad_fn=<MseLossBackward0>)\n",
      "2693 tensor(76514.9297, grad_fn=<MseLossBackward0>)\n",
      "2694 tensor(76514.1016, grad_fn=<MseLossBackward0>)\n",
      "2695 tensor(76513.2969, grad_fn=<MseLossBackward0>)\n",
      "2696 tensor(76512.4844, grad_fn=<MseLossBackward0>)\n",
      "2697 tensor(76511.6641, grad_fn=<MseLossBackward0>)\n",
      "2698 tensor(76510.8516, grad_fn=<MseLossBackward0>)\n",
      "2699 tensor(76510.0391, grad_fn=<MseLossBackward0>)\n",
      "2700 tensor(76509.2422, grad_fn=<MseLossBackward0>)\n",
      "2701 tensor(76508.4297, grad_fn=<MseLossBackward0>)\n",
      "2702 tensor(76507.6250, grad_fn=<MseLossBackward0>)\n",
      "2703 tensor(76506.8203, grad_fn=<MseLossBackward0>)\n",
      "2704 tensor(76506.0156, grad_fn=<MseLossBackward0>)\n",
      "2705 tensor(76505.2031, grad_fn=<MseLossBackward0>)\n",
      "2706 tensor(76504.4062, grad_fn=<MseLossBackward0>)\n",
      "2707 tensor(76503.6094, grad_fn=<MseLossBackward0>)\n",
      "2708 tensor(76502.8047, grad_fn=<MseLossBackward0>)\n",
      "2709 tensor(76502.0078, grad_fn=<MseLossBackward0>)\n",
      "2710 tensor(76501.2188, grad_fn=<MseLossBackward0>)\n",
      "2711 tensor(76500.4219, grad_fn=<MseLossBackward0>)\n",
      "2712 tensor(76499.6250, grad_fn=<MseLossBackward0>)\n",
      "2713 tensor(76498.8281, grad_fn=<MseLossBackward0>)\n",
      "2714 tensor(76498.0391, grad_fn=<MseLossBackward0>)\n",
      "2715 tensor(76497.2578, grad_fn=<MseLossBackward0>)\n",
      "2716 tensor(76496.4609, grad_fn=<MseLossBackward0>)\n",
      "2717 tensor(76495.6797, grad_fn=<MseLossBackward0>)\n",
      "2718 tensor(76494.8906, grad_fn=<MseLossBackward0>)\n",
      "2719 tensor(76494.1094, grad_fn=<MseLossBackward0>)\n",
      "2720 tensor(76493.3281, grad_fn=<MseLossBackward0>)\n",
      "2721 tensor(76492.5391, grad_fn=<MseLossBackward0>)\n",
      "2722 tensor(76491.7578, grad_fn=<MseLossBackward0>)\n",
      "2723 tensor(76490.9766, grad_fn=<MseLossBackward0>)\n",
      "2724 tensor(76490.2031, grad_fn=<MseLossBackward0>)\n",
      "2725 tensor(76489.4219, grad_fn=<MseLossBackward0>)\n",
      "2726 tensor(76488.6406, grad_fn=<MseLossBackward0>)\n",
      "2727 tensor(76487.8750, grad_fn=<MseLossBackward0>)\n",
      "2728 tensor(76487.1016, grad_fn=<MseLossBackward0>)\n",
      "2729 tensor(76486.3203, grad_fn=<MseLossBackward0>)\n",
      "2730 tensor(76485.5547, grad_fn=<MseLossBackward0>)\n",
      "2731 tensor(76484.7891, grad_fn=<MseLossBackward0>)\n",
      "2732 tensor(76484.0156, grad_fn=<MseLossBackward0>)\n",
      "2733 tensor(76483.2422, grad_fn=<MseLossBackward0>)\n",
      "2734 tensor(76482.4844, grad_fn=<MseLossBackward0>)\n",
      "2735 tensor(76481.7266, grad_fn=<MseLossBackward0>)\n",
      "2736 tensor(76480.9609, grad_fn=<MseLossBackward0>)\n",
      "2737 tensor(76480.1953, grad_fn=<MseLossBackward0>)\n",
      "2738 tensor(76479.4375, grad_fn=<MseLossBackward0>)\n",
      "2739 tensor(76478.6641, grad_fn=<MseLossBackward0>)\n",
      "2740 tensor(76477.9062, grad_fn=<MseLossBackward0>)\n",
      "2741 tensor(76477.1641, grad_fn=<MseLossBackward0>)\n",
      "2742 tensor(76476.3906, grad_fn=<MseLossBackward0>)\n",
      "2743 tensor(76475.6484, grad_fn=<MseLossBackward0>)\n",
      "2744 tensor(76474.8984, grad_fn=<MseLossBackward0>)\n",
      "2745 tensor(76474.1406, grad_fn=<MseLossBackward0>)\n",
      "2746 tensor(76473.3828, grad_fn=<MseLossBackward0>)\n",
      "2747 tensor(76472.6406, grad_fn=<MseLossBackward0>)\n",
      "2748 tensor(76471.8906, grad_fn=<MseLossBackward0>)\n",
      "2749 tensor(76471.1406, grad_fn=<MseLossBackward0>)\n",
      "2750 tensor(76470.3906, grad_fn=<MseLossBackward0>)\n",
      "2751 tensor(76469.6484, grad_fn=<MseLossBackward0>)\n",
      "2752 tensor(76468.9062, grad_fn=<MseLossBackward0>)\n",
      "2753 tensor(76468.1641, grad_fn=<MseLossBackward0>)\n",
      "2754 tensor(76467.4297, grad_fn=<MseLossBackward0>)\n",
      "2755 tensor(76466.6875, grad_fn=<MseLossBackward0>)\n",
      "2756 tensor(76465.9375, grad_fn=<MseLossBackward0>)\n",
      "2757 tensor(76465.2031, grad_fn=<MseLossBackward0>)\n",
      "2758 tensor(76464.4688, grad_fn=<MseLossBackward0>)\n",
      "2759 tensor(76463.7344, grad_fn=<MseLossBackward0>)\n",
      "2760 tensor(76463., grad_fn=<MseLossBackward0>)\n",
      "2761 tensor(76462.2656, grad_fn=<MseLossBackward0>)\n",
      "2762 tensor(76461.5391, grad_fn=<MseLossBackward0>)\n",
      "2763 tensor(76460.8125, grad_fn=<MseLossBackward0>)\n",
      "2764 tensor(76460.0781, grad_fn=<MseLossBackward0>)\n",
      "2765 tensor(76459.3516, grad_fn=<MseLossBackward0>)\n",
      "2766 tensor(76458.6172, grad_fn=<MseLossBackward0>)\n",
      "2767 tensor(76457.8906, grad_fn=<MseLossBackward0>)\n",
      "2768 tensor(76457.1719, grad_fn=<MseLossBackward0>)\n",
      "2769 tensor(76456.4531, grad_fn=<MseLossBackward0>)\n",
      "2770 tensor(76455.7188, grad_fn=<MseLossBackward0>)\n",
      "2771 tensor(76455.0078, grad_fn=<MseLossBackward0>)\n",
      "2772 tensor(76454.2812, grad_fn=<MseLossBackward0>)\n",
      "2773 tensor(76453.5703, grad_fn=<MseLossBackward0>)\n",
      "2774 tensor(76452.8438, grad_fn=<MseLossBackward0>)\n",
      "2775 tensor(76452.1328, grad_fn=<MseLossBackward0>)\n",
      "2776 tensor(76451.4141, grad_fn=<MseLossBackward0>)\n",
      "2777 tensor(76450.7031, grad_fn=<MseLossBackward0>)\n",
      "2778 tensor(76449.9844, grad_fn=<MseLossBackward0>)\n",
      "2779 tensor(76449.2812, grad_fn=<MseLossBackward0>)\n",
      "2780 tensor(76448.5625, grad_fn=<MseLossBackward0>)\n",
      "2781 tensor(76447.8672, grad_fn=<MseLossBackward0>)\n",
      "2782 tensor(76447.1562, grad_fn=<MseLossBackward0>)\n",
      "2783 tensor(76446.4531, grad_fn=<MseLossBackward0>)\n",
      "2784 tensor(76445.7344, grad_fn=<MseLossBackward0>)\n",
      "2785 tensor(76445.0391, grad_fn=<MseLossBackward0>)\n",
      "2786 tensor(76444.3359, grad_fn=<MseLossBackward0>)\n",
      "2787 tensor(76443.6328, grad_fn=<MseLossBackward0>)\n",
      "2788 tensor(76442.9297, grad_fn=<MseLossBackward0>)\n",
      "2789 tensor(76442.2266, grad_fn=<MseLossBackward0>)\n",
      "2790 tensor(76441.5312, grad_fn=<MseLossBackward0>)\n",
      "2791 tensor(76440.8359, grad_fn=<MseLossBackward0>)\n",
      "2792 tensor(76440.1406, grad_fn=<MseLossBackward0>)\n",
      "2793 tensor(76439.4375, grad_fn=<MseLossBackward0>)\n",
      "2794 tensor(76438.7578, grad_fn=<MseLossBackward0>)\n",
      "2795 tensor(76438.0625, grad_fn=<MseLossBackward0>)\n",
      "2796 tensor(76437.3672, grad_fn=<MseLossBackward0>)\n",
      "2797 tensor(76436.6797, grad_fn=<MseLossBackward0>)\n",
      "2798 tensor(76435.9922, grad_fn=<MseLossBackward0>)\n",
      "2799 tensor(76435.2969, grad_fn=<MseLossBackward0>)\n",
      "2800 tensor(76434.6094, grad_fn=<MseLossBackward0>)\n",
      "2801 tensor(76433.9297, grad_fn=<MseLossBackward0>)\n",
      "2802 tensor(76433.2500, grad_fn=<MseLossBackward0>)\n",
      "2803 tensor(76432.5625, grad_fn=<MseLossBackward0>)\n",
      "2804 tensor(76431.8828, grad_fn=<MseLossBackward0>)\n",
      "2805 tensor(76431.2031, grad_fn=<MseLossBackward0>)\n",
      "2806 tensor(76430.5234, grad_fn=<MseLossBackward0>)\n",
      "2807 tensor(76429.8438, grad_fn=<MseLossBackward0>)\n",
      "2808 tensor(76429.1641, grad_fn=<MseLossBackward0>)\n",
      "2809 tensor(76428.4844, grad_fn=<MseLossBackward0>)\n",
      "2810 tensor(76427.8047, grad_fn=<MseLossBackward0>)\n",
      "2811 tensor(76427.1406, grad_fn=<MseLossBackward0>)\n",
      "2812 tensor(76426.4688, grad_fn=<MseLossBackward0>)\n",
      "2813 tensor(76425.7891, grad_fn=<MseLossBackward0>)\n",
      "2814 tensor(76425.1250, grad_fn=<MseLossBackward0>)\n",
      "2815 tensor(76424.4531, grad_fn=<MseLossBackward0>)\n",
      "2816 tensor(76423.7891, grad_fn=<MseLossBackward0>)\n",
      "2817 tensor(76423.1172, grad_fn=<MseLossBackward0>)\n",
      "2818 tensor(76422.4531, grad_fn=<MseLossBackward0>)\n",
      "2819 tensor(76421.7812, grad_fn=<MseLossBackward0>)\n",
      "2820 tensor(76421.1172, grad_fn=<MseLossBackward0>)\n",
      "2821 tensor(76420.4609, grad_fn=<MseLossBackward0>)\n",
      "2822 tensor(76419.7969, grad_fn=<MseLossBackward0>)\n",
      "2823 tensor(76419.1406, grad_fn=<MseLossBackward0>)\n",
      "2824 tensor(76418.4844, grad_fn=<MseLossBackward0>)\n",
      "2825 tensor(76417.8203, grad_fn=<MseLossBackward0>)\n",
      "2826 tensor(76417.1719, grad_fn=<MseLossBackward0>)\n",
      "2827 tensor(76416.5156, grad_fn=<MseLossBackward0>)\n",
      "2828 tensor(76415.8516, grad_fn=<MseLossBackward0>)\n",
      "2829 tensor(76415.2109, grad_fn=<MseLossBackward0>)\n",
      "2830 tensor(76414.5547, grad_fn=<MseLossBackward0>)\n",
      "2831 tensor(76413.8984, grad_fn=<MseLossBackward0>)\n",
      "2832 tensor(76413.2500, grad_fn=<MseLossBackward0>)\n",
      "2833 tensor(76412.6016, grad_fn=<MseLossBackward0>)\n",
      "2834 tensor(76411.9609, grad_fn=<MseLossBackward0>)\n",
      "2835 tensor(76411.3047, grad_fn=<MseLossBackward0>)\n",
      "2836 tensor(76410.6719, grad_fn=<MseLossBackward0>)\n",
      "2837 tensor(76410.0156, grad_fn=<MseLossBackward0>)\n",
      "2838 tensor(76409.3750, grad_fn=<MseLossBackward0>)\n",
      "2839 tensor(76408.7266, grad_fn=<MseLossBackward0>)\n",
      "2840 tensor(76408.0938, grad_fn=<MseLossBackward0>)\n",
      "2841 tensor(76407.4531, grad_fn=<MseLossBackward0>)\n",
      "2842 tensor(76406.8281, grad_fn=<MseLossBackward0>)\n",
      "2843 tensor(76406.1797, grad_fn=<MseLossBackward0>)\n",
      "2844 tensor(76405.5391, grad_fn=<MseLossBackward0>)\n",
      "2845 tensor(76404.9062, grad_fn=<MseLossBackward0>)\n",
      "2846 tensor(76404.2734, grad_fn=<MseLossBackward0>)\n",
      "2847 tensor(76403.6406, grad_fn=<MseLossBackward0>)\n",
      "2848 tensor(76403., grad_fn=<MseLossBackward0>)\n",
      "2849 tensor(76402.3750, grad_fn=<MseLossBackward0>)\n",
      "2850 tensor(76401.7500, grad_fn=<MseLossBackward0>)\n",
      "2851 tensor(76401.1250, grad_fn=<MseLossBackward0>)\n",
      "2852 tensor(76400.4922, grad_fn=<MseLossBackward0>)\n",
      "2853 tensor(76399.8672, grad_fn=<MseLossBackward0>)\n",
      "2854 tensor(76399.2422, grad_fn=<MseLossBackward0>)\n",
      "2855 tensor(76398.6094, grad_fn=<MseLossBackward0>)\n",
      "2856 tensor(76397.9922, grad_fn=<MseLossBackward0>)\n",
      "2857 tensor(76397.3750, grad_fn=<MseLossBackward0>)\n",
      "2858 tensor(76396.7422, grad_fn=<MseLossBackward0>)\n",
      "2859 tensor(76396.1250, grad_fn=<MseLossBackward0>)\n",
      "2860 tensor(76395.5078, grad_fn=<MseLossBackward0>)\n",
      "2861 tensor(76394.8906, grad_fn=<MseLossBackward0>)\n",
      "2862 tensor(76394.2734, grad_fn=<MseLossBackward0>)\n",
      "2863 tensor(76393.6641, grad_fn=<MseLossBackward0>)\n",
      "2864 tensor(76393.0469, grad_fn=<MseLossBackward0>)\n",
      "2865 tensor(76392.4297, grad_fn=<MseLossBackward0>)\n",
      "2866 tensor(76391.8125, grad_fn=<MseLossBackward0>)\n",
      "2867 tensor(76391.2031, grad_fn=<MseLossBackward0>)\n",
      "2868 tensor(76390.5859, grad_fn=<MseLossBackward0>)\n",
      "2869 tensor(76389.9922, grad_fn=<MseLossBackward0>)\n",
      "2870 tensor(76389.3828, grad_fn=<MseLossBackward0>)\n",
      "2871 tensor(76388.7734, grad_fn=<MseLossBackward0>)\n",
      "2872 tensor(76388.1719, grad_fn=<MseLossBackward0>)\n",
      "2873 tensor(76387.5547, grad_fn=<MseLossBackward0>)\n",
      "2874 tensor(76386.9531, grad_fn=<MseLossBackward0>)\n",
      "2875 tensor(76386.3594, grad_fn=<MseLossBackward0>)\n",
      "2876 tensor(76385.7500, grad_fn=<MseLossBackward0>)\n",
      "2877 tensor(76385.1562, grad_fn=<MseLossBackward0>)\n",
      "2878 tensor(76384.5547, grad_fn=<MseLossBackward0>)\n",
      "2879 tensor(76383.9531, grad_fn=<MseLossBackward0>)\n",
      "2880 tensor(76383.3594, grad_fn=<MseLossBackward0>)\n",
      "2881 tensor(76382.7734, grad_fn=<MseLossBackward0>)\n",
      "2882 tensor(76382.1641, grad_fn=<MseLossBackward0>)\n",
      "2883 tensor(76381.5781, grad_fn=<MseLossBackward0>)\n",
      "2884 tensor(76380.9922, grad_fn=<MseLossBackward0>)\n",
      "2885 tensor(76380.3828, grad_fn=<MseLossBackward0>)\n",
      "2886 tensor(76379.8047, grad_fn=<MseLossBackward0>)\n",
      "2887 tensor(76379.2031, grad_fn=<MseLossBackward0>)\n",
      "2888 tensor(76378.6250, grad_fn=<MseLossBackward0>)\n",
      "2889 tensor(76378.0312, grad_fn=<MseLossBackward0>)\n",
      "2890 tensor(76377.4453, grad_fn=<MseLossBackward0>)\n",
      "2891 tensor(76376.8672, grad_fn=<MseLossBackward0>)\n",
      "2892 tensor(76376.2734, grad_fn=<MseLossBackward0>)\n",
      "2893 tensor(76375.6953, grad_fn=<MseLossBackward0>)\n",
      "2894 tensor(76375.1094, grad_fn=<MseLossBackward0>)\n",
      "2895 tensor(76374.5312, grad_fn=<MseLossBackward0>)\n",
      "2896 tensor(76373.9453, grad_fn=<MseLossBackward0>)\n",
      "2897 tensor(76373.3750, grad_fn=<MseLossBackward0>)\n",
      "2898 tensor(76372.7891, grad_fn=<MseLossBackward0>)\n",
      "2899 tensor(76372.2188, grad_fn=<MseLossBackward0>)\n",
      "2900 tensor(76371.6328, grad_fn=<MseLossBackward0>)\n",
      "2901 tensor(76371.0547, grad_fn=<MseLossBackward0>)\n",
      "2902 tensor(76370.5000, grad_fn=<MseLossBackward0>)\n",
      "2903 tensor(76369.9297, grad_fn=<MseLossBackward0>)\n",
      "2904 tensor(76369.3438, grad_fn=<MseLossBackward0>)\n",
      "2905 tensor(76368.7734, grad_fn=<MseLossBackward0>)\n",
      "2906 tensor(76368.2031, grad_fn=<MseLossBackward0>)\n",
      "2907 tensor(76367.6406, grad_fn=<MseLossBackward0>)\n",
      "2908 tensor(76367.0781, grad_fn=<MseLossBackward0>)\n",
      "2909 tensor(76366.5078, grad_fn=<MseLossBackward0>)\n",
      "2910 tensor(76365.9375, grad_fn=<MseLossBackward0>)\n",
      "2911 tensor(76365.3750, grad_fn=<MseLossBackward0>)\n",
      "2912 tensor(76364.8047, grad_fn=<MseLossBackward0>)\n",
      "2913 tensor(76364.2500, grad_fn=<MseLossBackward0>)\n",
      "2914 tensor(76363.6875, grad_fn=<MseLossBackward0>)\n",
      "2915 tensor(76363.1328, grad_fn=<MseLossBackward0>)\n",
      "2916 tensor(76362.5625, grad_fn=<MseLossBackward0>)\n",
      "2917 tensor(76362.0156, grad_fn=<MseLossBackward0>)\n",
      "2918 tensor(76361.4453, grad_fn=<MseLossBackward0>)\n",
      "2919 tensor(76360.8984, grad_fn=<MseLossBackward0>)\n",
      "2920 tensor(76360.3359, grad_fn=<MseLossBackward0>)\n",
      "2921 tensor(76359.7891, grad_fn=<MseLossBackward0>)\n",
      "2922 tensor(76359.2266, grad_fn=<MseLossBackward0>)\n",
      "2923 tensor(76358.6797, grad_fn=<MseLossBackward0>)\n",
      "2924 tensor(76358.1328, grad_fn=<MseLossBackward0>)\n",
      "2925 tensor(76357.5781, grad_fn=<MseLossBackward0>)\n",
      "2926 tensor(76357.0312, grad_fn=<MseLossBackward0>)\n",
      "2927 tensor(76356.4844, grad_fn=<MseLossBackward0>)\n",
      "2928 tensor(76355.9375, grad_fn=<MseLossBackward0>)\n",
      "2929 tensor(76355.3906, grad_fn=<MseLossBackward0>)\n",
      "2930 tensor(76354.8438, grad_fn=<MseLossBackward0>)\n",
      "2931 tensor(76354.2969, grad_fn=<MseLossBackward0>)\n",
      "2932 tensor(76353.7578, grad_fn=<MseLossBackward0>)\n",
      "2933 tensor(76353.2109, grad_fn=<MseLossBackward0>)\n",
      "2934 tensor(76352.6797, grad_fn=<MseLossBackward0>)\n",
      "2935 tensor(76352.1406, grad_fn=<MseLossBackward0>)\n",
      "2936 tensor(76351.6016, grad_fn=<MseLossBackward0>)\n",
      "2937 tensor(76351.0625, grad_fn=<MseLossBackward0>)\n",
      "2938 tensor(76350.5156, grad_fn=<MseLossBackward0>)\n",
      "2939 tensor(76349.9766, grad_fn=<MseLossBackward0>)\n",
      "2940 tensor(76349.4453, grad_fn=<MseLossBackward0>)\n",
      "2941 tensor(76348.9141, grad_fn=<MseLossBackward0>)\n",
      "2942 tensor(76348.3750, grad_fn=<MseLossBackward0>)\n",
      "2943 tensor(76347.8594, grad_fn=<MseLossBackward0>)\n",
      "2944 tensor(76347.3281, grad_fn=<MseLossBackward0>)\n",
      "2945 tensor(76346.7891, grad_fn=<MseLossBackward0>)\n",
      "2946 tensor(76346.2578, grad_fn=<MseLossBackward0>)\n",
      "2947 tensor(76345.7266, grad_fn=<MseLossBackward0>)\n",
      "2948 tensor(76345.2031, grad_fn=<MseLossBackward0>)\n",
      "2949 tensor(76344.6875, grad_fn=<MseLossBackward0>)\n",
      "2950 tensor(76344.1484, grad_fn=<MseLossBackward0>)\n",
      "2951 tensor(76343.6328, grad_fn=<MseLossBackward0>)\n",
      "2952 tensor(76343.1016, grad_fn=<MseLossBackward0>)\n",
      "2953 tensor(76342.5859, grad_fn=<MseLossBackward0>)\n",
      "2954 tensor(76342.0625, grad_fn=<MseLossBackward0>)\n",
      "2955 tensor(76341.5469, grad_fn=<MseLossBackward0>)\n",
      "2956 tensor(76341.0234, grad_fn=<MseLossBackward0>)\n",
      "2957 tensor(76340.5078, grad_fn=<MseLossBackward0>)\n",
      "2958 tensor(76339.9844, grad_fn=<MseLossBackward0>)\n",
      "2959 tensor(76339.4688, grad_fn=<MseLossBackward0>)\n",
      "2960 tensor(76338.9531, grad_fn=<MseLossBackward0>)\n",
      "2961 tensor(76338.4453, grad_fn=<MseLossBackward0>)\n",
      "2962 tensor(76337.9297, grad_fn=<MseLossBackward0>)\n",
      "2963 tensor(76337.4141, grad_fn=<MseLossBackward0>)\n",
      "2964 tensor(76336.9062, grad_fn=<MseLossBackward0>)\n",
      "2965 tensor(76336.3906, grad_fn=<MseLossBackward0>)\n",
      "2966 tensor(76335.8828, grad_fn=<MseLossBackward0>)\n",
      "2967 tensor(76335.3750, grad_fn=<MseLossBackward0>)\n",
      "2968 tensor(76334.8750, grad_fn=<MseLossBackward0>)\n",
      "2969 tensor(76334.3672, grad_fn=<MseLossBackward0>)\n",
      "2970 tensor(76333.8516, grad_fn=<MseLossBackward0>)\n",
      "2971 tensor(76333.3516, grad_fn=<MseLossBackward0>)\n",
      "2972 tensor(76332.8438, grad_fn=<MseLossBackward0>)\n",
      "2973 tensor(76332.3438, grad_fn=<MseLossBackward0>)\n",
      "2974 tensor(76331.8516, grad_fn=<MseLossBackward0>)\n",
      "2975 tensor(76331.3438, grad_fn=<MseLossBackward0>)\n",
      "2976 tensor(76330.8438, grad_fn=<MseLossBackward0>)\n",
      "2977 tensor(76330.3438, grad_fn=<MseLossBackward0>)\n",
      "2978 tensor(76329.8516, grad_fn=<MseLossBackward0>)\n",
      "2979 tensor(76329.3516, grad_fn=<MseLossBackward0>)\n",
      "2980 tensor(76328.8594, grad_fn=<MseLossBackward0>)\n",
      "2981 tensor(76328.3594, grad_fn=<MseLossBackward0>)\n",
      "2982 tensor(76327.8672, grad_fn=<MseLossBackward0>)\n",
      "2983 tensor(76327.3750, grad_fn=<MseLossBackward0>)\n",
      "2984 tensor(76326.8828, grad_fn=<MseLossBackward0>)\n",
      "2985 tensor(76326.3906, grad_fn=<MseLossBackward0>)\n",
      "2986 tensor(76325.8984, grad_fn=<MseLossBackward0>)\n",
      "2987 tensor(76325.4141, grad_fn=<MseLossBackward0>)\n",
      "2988 tensor(76324.9375, grad_fn=<MseLossBackward0>)\n",
      "2989 tensor(76324.4375, grad_fn=<MseLossBackward0>)\n",
      "2990 tensor(76323.9531, grad_fn=<MseLossBackward0>)\n",
      "2991 tensor(76323.4609, grad_fn=<MseLossBackward0>)\n",
      "2992 tensor(76322.9766, grad_fn=<MseLossBackward0>)\n",
      "2993 tensor(76322.4922, grad_fn=<MseLossBackward0>)\n",
      "2994 tensor(76322.0156, grad_fn=<MseLossBackward0>)\n",
      "2995 tensor(76321.5391, grad_fn=<MseLossBackward0>)\n",
      "2996 tensor(76321.0469, grad_fn=<MseLossBackward0>)\n",
      "2997 tensor(76320.5625, grad_fn=<MseLossBackward0>)\n",
      "2998 tensor(76320.0938, grad_fn=<MseLossBackward0>)\n",
      "2999 tensor(76319.6094, grad_fn=<MseLossBackward0>)\n",
      "3000 tensor(76319.1328, grad_fn=<MseLossBackward0>)\n",
      "3001 tensor(76318.6562, grad_fn=<MseLossBackward0>)\n",
      "3002 tensor(76318.1875, grad_fn=<MseLossBackward0>)\n",
      "3003 tensor(76317.7109, grad_fn=<MseLossBackward0>)\n",
      "3004 tensor(76317.2344, grad_fn=<MseLossBackward0>)\n",
      "3005 tensor(76316.7656, grad_fn=<MseLossBackward0>)\n",
      "3006 tensor(76316.2891, grad_fn=<MseLossBackward0>)\n",
      "3007 tensor(76315.8281, grad_fn=<MseLossBackward0>)\n",
      "3008 tensor(76315.3438, grad_fn=<MseLossBackward0>)\n",
      "3009 tensor(76314.8828, grad_fn=<MseLossBackward0>)\n",
      "3010 tensor(76314.4141, grad_fn=<MseLossBackward0>)\n",
      "3011 tensor(76313.9531, grad_fn=<MseLossBackward0>)\n",
      "3012 tensor(76313.4688, grad_fn=<MseLossBackward0>)\n",
      "3013 tensor(76313.0156, grad_fn=<MseLossBackward0>)\n",
      "3014 tensor(76312.5469, grad_fn=<MseLossBackward0>)\n",
      "3015 tensor(76312.0859, grad_fn=<MseLossBackward0>)\n",
      "3016 tensor(76311.6250, grad_fn=<MseLossBackward0>)\n",
      "3017 tensor(76311.1641, grad_fn=<MseLossBackward0>)\n",
      "3018 tensor(76310.6953, grad_fn=<MseLossBackward0>)\n",
      "3019 tensor(76310.2422, grad_fn=<MseLossBackward0>)\n",
      "3020 tensor(76309.7891, grad_fn=<MseLossBackward0>)\n",
      "3021 tensor(76309.3281, grad_fn=<MseLossBackward0>)\n",
      "3022 tensor(76308.8750, grad_fn=<MseLossBackward0>)\n",
      "3023 tensor(76308.4141, grad_fn=<MseLossBackward0>)\n",
      "3024 tensor(76307.9531, grad_fn=<MseLossBackward0>)\n",
      "3025 tensor(76307.5000, grad_fn=<MseLossBackward0>)\n",
      "3026 tensor(76307.0469, grad_fn=<MseLossBackward0>)\n",
      "3027 tensor(76306.6016, grad_fn=<MseLossBackward0>)\n",
      "3028 tensor(76306.1484, grad_fn=<MseLossBackward0>)\n",
      "3029 tensor(76305.6953, grad_fn=<MseLossBackward0>)\n",
      "3030 tensor(76305.2422, grad_fn=<MseLossBackward0>)\n",
      "3031 tensor(76304.7891, grad_fn=<MseLossBackward0>)\n",
      "3032 tensor(76304.3516, grad_fn=<MseLossBackward0>)\n",
      "3033 tensor(76303.8906, grad_fn=<MseLossBackward0>)\n",
      "3034 tensor(76303.4609, grad_fn=<MseLossBackward0>)\n",
      "3035 tensor(76303.0078, grad_fn=<MseLossBackward0>)\n",
      "3036 tensor(76302.5547, grad_fn=<MseLossBackward0>)\n",
      "3037 tensor(76302.1172, grad_fn=<MseLossBackward0>)\n",
      "3038 tensor(76301.6797, grad_fn=<MseLossBackward0>)\n",
      "3039 tensor(76301.2344, grad_fn=<MseLossBackward0>)\n",
      "3040 tensor(76300.7891, grad_fn=<MseLossBackward0>)\n",
      "3041 tensor(76300.3516, grad_fn=<MseLossBackward0>)\n",
      "3042 tensor(76299.9141, grad_fn=<MseLossBackward0>)\n",
      "3043 tensor(76299.4766, grad_fn=<MseLossBackward0>)\n",
      "3044 tensor(76299.0391, grad_fn=<MseLossBackward0>)\n",
      "3045 tensor(76298.6016, grad_fn=<MseLossBackward0>)\n",
      "3046 tensor(76298.1641, grad_fn=<MseLossBackward0>)\n",
      "3047 tensor(76297.7266, grad_fn=<MseLossBackward0>)\n",
      "3048 tensor(76297.2969, grad_fn=<MseLossBackward0>)\n",
      "3049 tensor(76296.8672, grad_fn=<MseLossBackward0>)\n",
      "3050 tensor(76296.4297, grad_fn=<MseLossBackward0>)\n",
      "3051 tensor(76296.0078, grad_fn=<MseLossBackward0>)\n",
      "3052 tensor(76295.5703, grad_fn=<MseLossBackward0>)\n",
      "3053 tensor(76295.1484, grad_fn=<MseLossBackward0>)\n",
      "3054 tensor(76294.7188, grad_fn=<MseLossBackward0>)\n",
      "3055 tensor(76294.2891, grad_fn=<MseLossBackward0>)\n",
      "3056 tensor(76293.8594, grad_fn=<MseLossBackward0>)\n",
      "3057 tensor(76293.4297, grad_fn=<MseLossBackward0>)\n",
      "3058 tensor(76293.0078, grad_fn=<MseLossBackward0>)\n",
      "3059 tensor(76292.5781, grad_fn=<MseLossBackward0>)\n",
      "3060 tensor(76292.1562, grad_fn=<MseLossBackward0>)\n",
      "3061 tensor(76291.7344, grad_fn=<MseLossBackward0>)\n",
      "3062 tensor(76291.3125, grad_fn=<MseLossBackward0>)\n",
      "3063 tensor(76290.9062, grad_fn=<MseLossBackward0>)\n",
      "3064 tensor(76290.4766, grad_fn=<MseLossBackward0>)\n",
      "3065 tensor(76290.0547, grad_fn=<MseLossBackward0>)\n",
      "3066 tensor(76289.6406, grad_fn=<MseLossBackward0>)\n",
      "3067 tensor(76289.2188, grad_fn=<MseLossBackward0>)\n",
      "3068 tensor(76288.8047, grad_fn=<MseLossBackward0>)\n",
      "3069 tensor(76288.3906, grad_fn=<MseLossBackward0>)\n",
      "3070 tensor(76287.9688, grad_fn=<MseLossBackward0>)\n",
      "3071 tensor(76287.5625, grad_fn=<MseLossBackward0>)\n",
      "3072 tensor(76287.1484, grad_fn=<MseLossBackward0>)\n",
      "3073 tensor(76286.7344, grad_fn=<MseLossBackward0>)\n",
      "3074 tensor(76286.3203, grad_fn=<MseLossBackward0>)\n",
      "3075 tensor(76285.9062, grad_fn=<MseLossBackward0>)\n",
      "3076 tensor(76285.5000, grad_fn=<MseLossBackward0>)\n",
      "3077 tensor(76285.0938, grad_fn=<MseLossBackward0>)\n",
      "3078 tensor(76284.6875, grad_fn=<MseLossBackward0>)\n",
      "3079 tensor(76284.2812, grad_fn=<MseLossBackward0>)\n",
      "3080 tensor(76283.8750, grad_fn=<MseLossBackward0>)\n",
      "3081 tensor(76283.4609, grad_fn=<MseLossBackward0>)\n",
      "3082 tensor(76283.0547, grad_fn=<MseLossBackward0>)\n",
      "3083 tensor(76282.6562, grad_fn=<MseLossBackward0>)\n",
      "3084 tensor(76282.2500, grad_fn=<MseLossBackward0>)\n",
      "3085 tensor(76281.8516, grad_fn=<MseLossBackward0>)\n",
      "3086 tensor(76281.4531, grad_fn=<MseLossBackward0>)\n",
      "3087 tensor(76281.0469, grad_fn=<MseLossBackward0>)\n",
      "3088 tensor(76280.6484, grad_fn=<MseLossBackward0>)\n",
      "3089 tensor(76280.2578, grad_fn=<MseLossBackward0>)\n",
      "3090 tensor(76279.8516, grad_fn=<MseLossBackward0>)\n",
      "3091 tensor(76279.4531, grad_fn=<MseLossBackward0>)\n",
      "3092 tensor(76279.0547, grad_fn=<MseLossBackward0>)\n",
      "3093 tensor(76278.6562, grad_fn=<MseLossBackward0>)\n",
      "3094 tensor(76278.2734, grad_fn=<MseLossBackward0>)\n",
      "3095 tensor(76277.8750, grad_fn=<MseLossBackward0>)\n",
      "3096 tensor(76277.4766, grad_fn=<MseLossBackward0>)\n",
      "3097 tensor(76277.0781, grad_fn=<MseLossBackward0>)\n",
      "3098 tensor(76276.6875, grad_fn=<MseLossBackward0>)\n",
      "3099 tensor(76276.3047, grad_fn=<MseLossBackward0>)\n",
      "3100 tensor(76275.9062, grad_fn=<MseLossBackward0>)\n",
      "3101 tensor(76275.5234, grad_fn=<MseLossBackward0>)\n",
      "3102 tensor(76275.1328, grad_fn=<MseLossBackward0>)\n",
      "3103 tensor(76274.7500, grad_fn=<MseLossBackward0>)\n",
      "3104 tensor(76274.3516, grad_fn=<MseLossBackward0>)\n",
      "3105 tensor(76273.9766, grad_fn=<MseLossBackward0>)\n",
      "3106 tensor(76273.5859, grad_fn=<MseLossBackward0>)\n",
      "3107 tensor(76273.1953, grad_fn=<MseLossBackward0>)\n",
      "3108 tensor(76272.8125, grad_fn=<MseLossBackward0>)\n",
      "3109 tensor(76272.4375, grad_fn=<MseLossBackward0>)\n",
      "3110 tensor(76272.0547, grad_fn=<MseLossBackward0>)\n",
      "3111 tensor(76271.6719, grad_fn=<MseLossBackward0>)\n",
      "3112 tensor(76271.2891, grad_fn=<MseLossBackward0>)\n",
      "3113 tensor(76270.9062, grad_fn=<MseLossBackward0>)\n",
      "3114 tensor(76270.5312, grad_fn=<MseLossBackward0>)\n",
      "3115 tensor(76270.1641, grad_fn=<MseLossBackward0>)\n",
      "3116 tensor(76269.7812, grad_fn=<MseLossBackward0>)\n",
      "3117 tensor(76269.3984, grad_fn=<MseLossBackward0>)\n",
      "3118 tensor(76269.0234, grad_fn=<MseLossBackward0>)\n",
      "3119 tensor(76268.6562, grad_fn=<MseLossBackward0>)\n",
      "3120 tensor(76268.2812, grad_fn=<MseLossBackward0>)\n",
      "3121 tensor(76267.8984, grad_fn=<MseLossBackward0>)\n",
      "3122 tensor(76267.5234, grad_fn=<MseLossBackward0>)\n",
      "3123 tensor(76267.1641, grad_fn=<MseLossBackward0>)\n",
      "3124 tensor(76266.7891, grad_fn=<MseLossBackward0>)\n",
      "3125 tensor(76266.4297, grad_fn=<MseLossBackward0>)\n",
      "3126 tensor(76266.0469, grad_fn=<MseLossBackward0>)\n",
      "3127 tensor(76265.6797, grad_fn=<MseLossBackward0>)\n",
      "3128 tensor(76265.3203, grad_fn=<MseLossBackward0>)\n",
      "3129 tensor(76264.9453, grad_fn=<MseLossBackward0>)\n",
      "3130 tensor(76264.5703, grad_fn=<MseLossBackward0>)\n",
      "3131 tensor(76264.2188, grad_fn=<MseLossBackward0>)\n",
      "3132 tensor(76263.8516, grad_fn=<MseLossBackward0>)\n",
      "3133 tensor(76263.4766, grad_fn=<MseLossBackward0>)\n",
      "3134 tensor(76263.1172, grad_fn=<MseLossBackward0>)\n",
      "3135 tensor(76262.7500, grad_fn=<MseLossBackward0>)\n",
      "3136 tensor(76262.3984, grad_fn=<MseLossBackward0>)\n",
      "3137 tensor(76262.0391, grad_fn=<MseLossBackward0>)\n",
      "3138 tensor(76261.6797, grad_fn=<MseLossBackward0>)\n",
      "3139 tensor(76261.3203, grad_fn=<MseLossBackward0>)\n",
      "3140 tensor(76260.9531, grad_fn=<MseLossBackward0>)\n",
      "3141 tensor(76260.6016, grad_fn=<MseLossBackward0>)\n",
      "3142 tensor(76260.2422, grad_fn=<MseLossBackward0>)\n",
      "3143 tensor(76259.8828, grad_fn=<MseLossBackward0>)\n",
      "3144 tensor(76259.5234, grad_fn=<MseLossBackward0>)\n",
      "3145 tensor(76259.1797, grad_fn=<MseLossBackward0>)\n",
      "3146 tensor(76258.8281, grad_fn=<MseLossBackward0>)\n",
      "3147 tensor(76258.4688, grad_fn=<MseLossBackward0>)\n",
      "3148 tensor(76258.1172, grad_fn=<MseLossBackward0>)\n",
      "3149 tensor(76257.7578, grad_fn=<MseLossBackward0>)\n",
      "3150 tensor(76257.4141, grad_fn=<MseLossBackward0>)\n",
      "3151 tensor(76257.0625, grad_fn=<MseLossBackward0>)\n",
      "3152 tensor(76256.7109, grad_fn=<MseLossBackward0>)\n",
      "3153 tensor(76256.3594, grad_fn=<MseLossBackward0>)\n",
      "3154 tensor(76256.0156, grad_fn=<MseLossBackward0>)\n",
      "3155 tensor(76255.6719, grad_fn=<MseLossBackward0>)\n",
      "3156 tensor(76255.3281, grad_fn=<MseLossBackward0>)\n",
      "3157 tensor(76254.9766, grad_fn=<MseLossBackward0>)\n",
      "3158 tensor(76254.6328, grad_fn=<MseLossBackward0>)\n",
      "3159 tensor(76254.2812, grad_fn=<MseLossBackward0>)\n",
      "3160 tensor(76253.9375, grad_fn=<MseLossBackward0>)\n",
      "3161 tensor(76253.6016, grad_fn=<MseLossBackward0>)\n",
      "3162 tensor(76253.2578, grad_fn=<MseLossBackward0>)\n",
      "3163 tensor(76252.9219, grad_fn=<MseLossBackward0>)\n",
      "3164 tensor(76252.5781, grad_fn=<MseLossBackward0>)\n",
      "3165 tensor(76252.2422, grad_fn=<MseLossBackward0>)\n",
      "3166 tensor(76251.8984, grad_fn=<MseLossBackward0>)\n",
      "3167 tensor(76251.5703, grad_fn=<MseLossBackward0>)\n",
      "3168 tensor(76251.2188, grad_fn=<MseLossBackward0>)\n",
      "3169 tensor(76250.8906, grad_fn=<MseLossBackward0>)\n",
      "3170 tensor(76250.5469, grad_fn=<MseLossBackward0>)\n",
      "3171 tensor(76250.2188, grad_fn=<MseLossBackward0>)\n",
      "3172 tensor(76249.8828, grad_fn=<MseLossBackward0>)\n",
      "3173 tensor(76249.5469, grad_fn=<MseLossBackward0>)\n",
      "3174 tensor(76249.2109, grad_fn=<MseLossBackward0>)\n",
      "3175 tensor(76248.8828, grad_fn=<MseLossBackward0>)\n",
      "3176 tensor(76248.5391, grad_fn=<MseLossBackward0>)\n",
      "3177 tensor(76248.2188, grad_fn=<MseLossBackward0>)\n",
      "3178 tensor(76247.8906, grad_fn=<MseLossBackward0>)\n",
      "3179 tensor(76247.5547, grad_fn=<MseLossBackward0>)\n",
      "3180 tensor(76247.2266, grad_fn=<MseLossBackward0>)\n",
      "3181 tensor(76246.9062, grad_fn=<MseLossBackward0>)\n",
      "3182 tensor(76246.5703, grad_fn=<MseLossBackward0>)\n",
      "3183 tensor(76246.2422, grad_fn=<MseLossBackward0>)\n",
      "3184 tensor(76245.9219, grad_fn=<MseLossBackward0>)\n",
      "3185 tensor(76245.6016, grad_fn=<MseLossBackward0>)\n",
      "3186 tensor(76245.2734, grad_fn=<MseLossBackward0>)\n",
      "3187 tensor(76244.9453, grad_fn=<MseLossBackward0>)\n",
      "3188 tensor(76244.6250, grad_fn=<MseLossBackward0>)\n",
      "3189 tensor(76244.3047, grad_fn=<MseLossBackward0>)\n",
      "3190 tensor(76243.9922, grad_fn=<MseLossBackward0>)\n",
      "3191 tensor(76243.6562, grad_fn=<MseLossBackward0>)\n",
      "3192 tensor(76243.3359, grad_fn=<MseLossBackward0>)\n",
      "3193 tensor(76243.0234, grad_fn=<MseLossBackward0>)\n",
      "3194 tensor(76242.7031, grad_fn=<MseLossBackward0>)\n",
      "3195 tensor(76242.3906, grad_fn=<MseLossBackward0>)\n",
      "3196 tensor(76242.0625, grad_fn=<MseLossBackward0>)\n",
      "3197 tensor(76241.7500, grad_fn=<MseLossBackward0>)\n",
      "3198 tensor(76241.4297, grad_fn=<MseLossBackward0>)\n",
      "3199 tensor(76241.1172, grad_fn=<MseLossBackward0>)\n",
      "3200 tensor(76240.8047, grad_fn=<MseLossBackward0>)\n",
      "3201 tensor(76240.4922, grad_fn=<MseLossBackward0>)\n",
      "3202 tensor(76240.1797, grad_fn=<MseLossBackward0>)\n",
      "3203 tensor(76239.8594, grad_fn=<MseLossBackward0>)\n",
      "3204 tensor(76239.5547, grad_fn=<MseLossBackward0>)\n",
      "3205 tensor(76239.2422, grad_fn=<MseLossBackward0>)\n",
      "3206 tensor(76238.9297, grad_fn=<MseLossBackward0>)\n",
      "3207 tensor(76238.6250, grad_fn=<MseLossBackward0>)\n",
      "3208 tensor(76238.3125, grad_fn=<MseLossBackward0>)\n",
      "3209 tensor(76238., grad_fn=<MseLossBackward0>)\n",
      "3210 tensor(76237.6875, grad_fn=<MseLossBackward0>)\n",
      "3211 tensor(76237.3906, grad_fn=<MseLossBackward0>)\n",
      "3212 tensor(76237.0859, grad_fn=<MseLossBackward0>)\n",
      "3213 tensor(76236.7734, grad_fn=<MseLossBackward0>)\n",
      "3214 tensor(76236.4688, grad_fn=<MseLossBackward0>)\n",
      "3215 tensor(76236.1719, grad_fn=<MseLossBackward0>)\n",
      "3216 tensor(76235.8750, grad_fn=<MseLossBackward0>)\n",
      "3217 tensor(76235.5625, grad_fn=<MseLossBackward0>)\n",
      "3218 tensor(76235.2500, grad_fn=<MseLossBackward0>)\n",
      "3219 tensor(76234.9453, grad_fn=<MseLossBackward0>)\n",
      "3220 tensor(76234.6562, grad_fn=<MseLossBackward0>)\n",
      "3221 tensor(76234.3594, grad_fn=<MseLossBackward0>)\n",
      "3222 tensor(76234.0547, grad_fn=<MseLossBackward0>)\n",
      "3223 tensor(76233.7578, grad_fn=<MseLossBackward0>)\n",
      "3224 tensor(76233.4609, grad_fn=<MseLossBackward0>)\n",
      "3225 tensor(76233.1641, grad_fn=<MseLossBackward0>)\n",
      "3226 tensor(76232.8672, grad_fn=<MseLossBackward0>)\n",
      "3227 tensor(76232.5703, grad_fn=<MseLossBackward0>)\n",
      "3228 tensor(76232.2812, grad_fn=<MseLossBackward0>)\n",
      "3229 tensor(76231.9688, grad_fn=<MseLossBackward0>)\n",
      "3230 tensor(76231.6797, grad_fn=<MseLossBackward0>)\n",
      "3231 tensor(76231.3984, grad_fn=<MseLossBackward0>)\n",
      "3232 tensor(76231.0938, grad_fn=<MseLossBackward0>)\n",
      "3233 tensor(76230.8047, grad_fn=<MseLossBackward0>)\n",
      "3234 tensor(76230.5312, grad_fn=<MseLossBackward0>)\n",
      "3235 tensor(76230.2266, grad_fn=<MseLossBackward0>)\n",
      "3236 tensor(76229.9297, grad_fn=<MseLossBackward0>)\n",
      "3237 tensor(76229.6406, grad_fn=<MseLossBackward0>)\n",
      "3238 tensor(76229.3594, grad_fn=<MseLossBackward0>)\n",
      "3239 tensor(76229.0625, grad_fn=<MseLossBackward0>)\n",
      "3240 tensor(76228.7812, grad_fn=<MseLossBackward0>)\n",
      "3241 tensor(76228.4922, grad_fn=<MseLossBackward0>)\n",
      "3242 tensor(76228.2109, grad_fn=<MseLossBackward0>)\n",
      "3243 tensor(76227.9219, grad_fn=<MseLossBackward0>)\n",
      "3244 tensor(76227.6328, grad_fn=<MseLossBackward0>)\n",
      "3245 tensor(76227.3516, grad_fn=<MseLossBackward0>)\n",
      "3246 tensor(76227.0703, grad_fn=<MseLossBackward0>)\n",
      "3247 tensor(76226.7891, grad_fn=<MseLossBackward0>)\n",
      "3248 tensor(76226.5000, grad_fn=<MseLossBackward0>)\n",
      "3249 tensor(76226.2266, grad_fn=<MseLossBackward0>)\n",
      "3250 tensor(76225.9375, grad_fn=<MseLossBackward0>)\n",
      "3251 tensor(76225.6641, grad_fn=<MseLossBackward0>)\n",
      "3252 tensor(76225.3750, grad_fn=<MseLossBackward0>)\n",
      "3253 tensor(76225.1016, grad_fn=<MseLossBackward0>)\n",
      "3254 tensor(76224.8203, grad_fn=<MseLossBackward0>)\n",
      "3255 tensor(76224.5469, grad_fn=<MseLossBackward0>)\n",
      "3256 tensor(76224.2734, grad_fn=<MseLossBackward0>)\n",
      "3257 tensor(76223.9922, grad_fn=<MseLossBackward0>)\n",
      "3258 tensor(76223.7188, grad_fn=<MseLossBackward0>)\n",
      "3259 tensor(76223.4375, grad_fn=<MseLossBackward0>)\n",
      "3260 tensor(76223.1797, grad_fn=<MseLossBackward0>)\n",
      "3261 tensor(76222.8984, grad_fn=<MseLossBackward0>)\n",
      "3262 tensor(76222.6250, grad_fn=<MseLossBackward0>)\n",
      "3263 tensor(76222.3438, grad_fn=<MseLossBackward0>)\n",
      "3264 tensor(76222.0781, grad_fn=<MseLossBackward0>)\n",
      "3265 tensor(76221.8047, grad_fn=<MseLossBackward0>)\n",
      "3266 tensor(76221.5312, grad_fn=<MseLossBackward0>)\n",
      "3267 tensor(76221.2656, grad_fn=<MseLossBackward0>)\n",
      "3268 tensor(76220.9922, grad_fn=<MseLossBackward0>)\n",
      "3269 tensor(76220.7266, grad_fn=<MseLossBackward0>)\n",
      "3270 tensor(76220.4531, grad_fn=<MseLossBackward0>)\n",
      "3271 tensor(76220.1797, grad_fn=<MseLossBackward0>)\n",
      "3272 tensor(76219.9141, grad_fn=<MseLossBackward0>)\n",
      "3273 tensor(76219.6641, grad_fn=<MseLossBackward0>)\n",
      "3274 tensor(76219.3828, grad_fn=<MseLossBackward0>)\n",
      "3275 tensor(76219.1250, grad_fn=<MseLossBackward0>)\n",
      "3276 tensor(76218.8594, grad_fn=<MseLossBackward0>)\n",
      "3277 tensor(76218.5938, grad_fn=<MseLossBackward0>)\n",
      "3278 tensor(76218.3281, grad_fn=<MseLossBackward0>)\n",
      "3279 tensor(76218.0703, grad_fn=<MseLossBackward0>)\n",
      "3280 tensor(76217.7969, grad_fn=<MseLossBackward0>)\n",
      "3281 tensor(76217.5469, grad_fn=<MseLossBackward0>)\n",
      "3282 tensor(76217.2812, grad_fn=<MseLossBackward0>)\n",
      "3283 tensor(76217.0234, grad_fn=<MseLossBackward0>)\n",
      "3284 tensor(76216.7656, grad_fn=<MseLossBackward0>)\n",
      "3285 tensor(76216.5078, grad_fn=<MseLossBackward0>)\n",
      "3286 tensor(76216.2500, grad_fn=<MseLossBackward0>)\n",
      "3287 tensor(76215.9844, grad_fn=<MseLossBackward0>)\n",
      "3288 tensor(76215.7266, grad_fn=<MseLossBackward0>)\n",
      "3289 tensor(76215.4766, grad_fn=<MseLossBackward0>)\n",
      "3290 tensor(76215.2188, grad_fn=<MseLossBackward0>)\n",
      "3291 tensor(76214.9609, grad_fn=<MseLossBackward0>)\n",
      "3292 tensor(76214.7109, grad_fn=<MseLossBackward0>)\n",
      "3293 tensor(76214.4609, grad_fn=<MseLossBackward0>)\n",
      "3294 tensor(76214.2031, grad_fn=<MseLossBackward0>)\n",
      "3295 tensor(76213.9453, grad_fn=<MseLossBackward0>)\n",
      "3296 tensor(76213.6953, grad_fn=<MseLossBackward0>)\n",
      "3297 tensor(76213.4453, grad_fn=<MseLossBackward0>)\n",
      "3298 tensor(76213.1875, grad_fn=<MseLossBackward0>)\n",
      "3299 tensor(76212.9453, grad_fn=<MseLossBackward0>)\n",
      "3300 tensor(76212.6875, grad_fn=<MseLossBackward0>)\n",
      "3301 tensor(76212.4375, grad_fn=<MseLossBackward0>)\n",
      "3302 tensor(76212.1953, grad_fn=<MseLossBackward0>)\n",
      "3303 tensor(76211.9453, grad_fn=<MseLossBackward0>)\n",
      "3304 tensor(76211.6953, grad_fn=<MseLossBackward0>)\n",
      "3305 tensor(76211.4531, grad_fn=<MseLossBackward0>)\n",
      "3306 tensor(76211.2031, grad_fn=<MseLossBackward0>)\n",
      "3307 tensor(76210.9609, grad_fn=<MseLossBackward0>)\n",
      "3308 tensor(76210.7031, grad_fn=<MseLossBackward0>)\n",
      "3309 tensor(76210.4609, grad_fn=<MseLossBackward0>)\n",
      "3310 tensor(76210.2266, grad_fn=<MseLossBackward0>)\n",
      "3311 tensor(76209.9844, grad_fn=<MseLossBackward0>)\n",
      "3312 tensor(76209.7422, grad_fn=<MseLossBackward0>)\n",
      "3313 tensor(76209.4922, grad_fn=<MseLossBackward0>)\n",
      "3314 tensor(76209.2500, grad_fn=<MseLossBackward0>)\n",
      "3315 tensor(76209.0156, grad_fn=<MseLossBackward0>)\n",
      "3316 tensor(76208.7734, grad_fn=<MseLossBackward0>)\n",
      "3317 tensor(76208.5312, grad_fn=<MseLossBackward0>)\n",
      "3318 tensor(76208.2969, grad_fn=<MseLossBackward0>)\n",
      "3319 tensor(76208.0469, grad_fn=<MseLossBackward0>)\n",
      "3320 tensor(76207.8125, grad_fn=<MseLossBackward0>)\n",
      "3321 tensor(76207.5781, grad_fn=<MseLossBackward0>)\n",
      "3322 tensor(76207.3438, grad_fn=<MseLossBackward0>)\n",
      "3323 tensor(76207.1016, grad_fn=<MseLossBackward0>)\n",
      "3324 tensor(76206.8672, grad_fn=<MseLossBackward0>)\n",
      "3325 tensor(76206.6172, grad_fn=<MseLossBackward0>)\n",
      "3326 tensor(76206.3984, grad_fn=<MseLossBackward0>)\n",
      "3327 tensor(76206.1641, grad_fn=<MseLossBackward0>)\n",
      "3328 tensor(76205.9297, grad_fn=<MseLossBackward0>)\n",
      "3329 tensor(76205.6953, grad_fn=<MseLossBackward0>)\n",
      "3330 tensor(76205.4688, grad_fn=<MseLossBackward0>)\n",
      "3331 tensor(76205.2344, grad_fn=<MseLossBackward0>)\n",
      "3332 tensor(76205., grad_fn=<MseLossBackward0>)\n",
      "3333 tensor(76204.7656, grad_fn=<MseLossBackward0>)\n",
      "3334 tensor(76204.5391, grad_fn=<MseLossBackward0>)\n",
      "3335 tensor(76204.2969, grad_fn=<MseLossBackward0>)\n",
      "3336 tensor(76204.0781, grad_fn=<MseLossBackward0>)\n",
      "3337 tensor(76203.8516, grad_fn=<MseLossBackward0>)\n",
      "3338 tensor(76203.6250, grad_fn=<MseLossBackward0>)\n",
      "3339 tensor(76203.3984, grad_fn=<MseLossBackward0>)\n",
      "3340 tensor(76203.1719, grad_fn=<MseLossBackward0>)\n",
      "3341 tensor(76202.9453, grad_fn=<MseLossBackward0>)\n",
      "3342 tensor(76202.7109, grad_fn=<MseLossBackward0>)\n",
      "3343 tensor(76202.4922, grad_fn=<MseLossBackward0>)\n",
      "3344 tensor(76202.2578, grad_fn=<MseLossBackward0>)\n",
      "3345 tensor(76202.0391, grad_fn=<MseLossBackward0>)\n",
      "3346 tensor(76201.8047, grad_fn=<MseLossBackward0>)\n",
      "3347 tensor(76201.5859, grad_fn=<MseLossBackward0>)\n",
      "3348 tensor(76201.3750, grad_fn=<MseLossBackward0>)\n",
      "3349 tensor(76201.1484, grad_fn=<MseLossBackward0>)\n",
      "3350 tensor(76200.9219, grad_fn=<MseLossBackward0>)\n",
      "3351 tensor(76200.7031, grad_fn=<MseLossBackward0>)\n",
      "3352 tensor(76200.4766, grad_fn=<MseLossBackward0>)\n",
      "3353 tensor(76200.2578, grad_fn=<MseLossBackward0>)\n",
      "3354 tensor(76200.0391, grad_fn=<MseLossBackward0>)\n",
      "3355 tensor(76199.8203, grad_fn=<MseLossBackward0>)\n",
      "3356 tensor(76199.6016, grad_fn=<MseLossBackward0>)\n",
      "3357 tensor(76199.3828, grad_fn=<MseLossBackward0>)\n",
      "3358 tensor(76199.1641, grad_fn=<MseLossBackward0>)\n",
      "3359 tensor(76198.9531, grad_fn=<MseLossBackward0>)\n",
      "3360 tensor(76198.7344, grad_fn=<MseLossBackward0>)\n",
      "3361 tensor(76198.5156, grad_fn=<MseLossBackward0>)\n",
      "3362 tensor(76198.3047, grad_fn=<MseLossBackward0>)\n",
      "3363 tensor(76198.0938, grad_fn=<MseLossBackward0>)\n",
      "3364 tensor(76197.8750, grad_fn=<MseLossBackward0>)\n",
      "3365 tensor(76197.6641, grad_fn=<MseLossBackward0>)\n",
      "3366 tensor(76197.4453, grad_fn=<MseLossBackward0>)\n",
      "3367 tensor(76197.2344, grad_fn=<MseLossBackward0>)\n",
      "3368 tensor(76197.0234, grad_fn=<MseLossBackward0>)\n",
      "3369 tensor(76196.8125, grad_fn=<MseLossBackward0>)\n",
      "3370 tensor(76196.6094, grad_fn=<MseLossBackward0>)\n",
      "3371 tensor(76196.3906, grad_fn=<MseLossBackward0>)\n",
      "3372 tensor(76196.1797, grad_fn=<MseLossBackward0>)\n",
      "3373 tensor(76195.9766, grad_fn=<MseLossBackward0>)\n",
      "3374 tensor(76195.7656, grad_fn=<MseLossBackward0>)\n",
      "3375 tensor(76195.5625, grad_fn=<MseLossBackward0>)\n",
      "3376 tensor(76195.3516, grad_fn=<MseLossBackward0>)\n",
      "3377 tensor(76195.1406, grad_fn=<MseLossBackward0>)\n",
      "3378 tensor(76194.9375, grad_fn=<MseLossBackward0>)\n",
      "3379 tensor(76194.7344, grad_fn=<MseLossBackward0>)\n",
      "3380 tensor(76194.5234, grad_fn=<MseLossBackward0>)\n",
      "3381 tensor(76194.3125, grad_fn=<MseLossBackward0>)\n",
      "3382 tensor(76194.1094, grad_fn=<MseLossBackward0>)\n",
      "3383 tensor(76193.9062, grad_fn=<MseLossBackward0>)\n",
      "3384 tensor(76193.7031, grad_fn=<MseLossBackward0>)\n",
      "3385 tensor(76193.5078, grad_fn=<MseLossBackward0>)\n",
      "3386 tensor(76193.3047, grad_fn=<MseLossBackward0>)\n",
      "3387 tensor(76193.1016, grad_fn=<MseLossBackward0>)\n",
      "3388 tensor(76192.8906, grad_fn=<MseLossBackward0>)\n",
      "3389 tensor(76192.6953, grad_fn=<MseLossBackward0>)\n",
      "3390 tensor(76192.4844, grad_fn=<MseLossBackward0>)\n",
      "3391 tensor(76192.2969, grad_fn=<MseLossBackward0>)\n",
      "3392 tensor(76192.0938, grad_fn=<MseLossBackward0>)\n",
      "3393 tensor(76191.8906, grad_fn=<MseLossBackward0>)\n",
      "3394 tensor(76191.6953, grad_fn=<MseLossBackward0>)\n",
      "3395 tensor(76191.4922, grad_fn=<MseLossBackward0>)\n",
      "3396 tensor(76191.2969, grad_fn=<MseLossBackward0>)\n",
      "3397 tensor(76191.1016, grad_fn=<MseLossBackward0>)\n",
      "3398 tensor(76190.9062, grad_fn=<MseLossBackward0>)\n",
      "3399 tensor(76190.7109, grad_fn=<MseLossBackward0>)\n",
      "3400 tensor(76190.5156, grad_fn=<MseLossBackward0>)\n",
      "3401 tensor(76190.3203, grad_fn=<MseLossBackward0>)\n",
      "3402 tensor(76190.1328, grad_fn=<MseLossBackward0>)\n",
      "3403 tensor(76189.9219, grad_fn=<MseLossBackward0>)\n",
      "3404 tensor(76189.7344, grad_fn=<MseLossBackward0>)\n",
      "3405 tensor(76189.5469, grad_fn=<MseLossBackward0>)\n",
      "3406 tensor(76189.3516, grad_fn=<MseLossBackward0>)\n",
      "3407 tensor(76189.1562, grad_fn=<MseLossBackward0>)\n",
      "3408 tensor(76188.9688, grad_fn=<MseLossBackward0>)\n",
      "3409 tensor(76188.7812, grad_fn=<MseLossBackward0>)\n",
      "3410 tensor(76188.5781, grad_fn=<MseLossBackward0>)\n",
      "3411 tensor(76188.3828, grad_fn=<MseLossBackward0>)\n",
      "3412 tensor(76188.2031, grad_fn=<MseLossBackward0>)\n",
      "3413 tensor(76188.0156, grad_fn=<MseLossBackward0>)\n",
      "3414 tensor(76187.8281, grad_fn=<MseLossBackward0>)\n",
      "3415 tensor(76187.6406, grad_fn=<MseLossBackward0>)\n",
      "3416 tensor(76187.4453, grad_fn=<MseLossBackward0>)\n",
      "3417 tensor(76187.2656, grad_fn=<MseLossBackward0>)\n",
      "3418 tensor(76187.0703, grad_fn=<MseLossBackward0>)\n",
      "3419 tensor(76186.8906, grad_fn=<MseLossBackward0>)\n",
      "3420 tensor(76186.7031, grad_fn=<MseLossBackward0>)\n",
      "3421 tensor(76186.5156, grad_fn=<MseLossBackward0>)\n",
      "3422 tensor(76186.3281, grad_fn=<MseLossBackward0>)\n",
      "3423 tensor(76186.1484, grad_fn=<MseLossBackward0>)\n",
      "3424 tensor(76185.9609, grad_fn=<MseLossBackward0>)\n",
      "3425 tensor(76185.7734, grad_fn=<MseLossBackward0>)\n",
      "3426 tensor(76185.6016, grad_fn=<MseLossBackward0>)\n",
      "3427 tensor(76185.4141, grad_fn=<MseLossBackward0>)\n",
      "3428 tensor(76185.2344, grad_fn=<MseLossBackward0>)\n",
      "3429 tensor(76185.0469, grad_fn=<MseLossBackward0>)\n",
      "3430 tensor(76184.8672, grad_fn=<MseLossBackward0>)\n",
      "3431 tensor(76184.6797, grad_fn=<MseLossBackward0>)\n",
      "3432 tensor(76184.5078, grad_fn=<MseLossBackward0>)\n",
      "3433 tensor(76184.3281, grad_fn=<MseLossBackward0>)\n",
      "3434 tensor(76184.1562, grad_fn=<MseLossBackward0>)\n",
      "3435 tensor(76183.9688, grad_fn=<MseLossBackward0>)\n",
      "3436 tensor(76183.7891, grad_fn=<MseLossBackward0>)\n",
      "3437 tensor(76183.6172, grad_fn=<MseLossBackward0>)\n",
      "3438 tensor(76183.4375, grad_fn=<MseLossBackward0>)\n",
      "3439 tensor(76183.2500, grad_fn=<MseLossBackward0>)\n",
      "3440 tensor(76183.0781, grad_fn=<MseLossBackward0>)\n",
      "3441 tensor(76182.8984, grad_fn=<MseLossBackward0>)\n",
      "3442 tensor(76182.7266, grad_fn=<MseLossBackward0>)\n",
      "3443 tensor(76182.5547, grad_fn=<MseLossBackward0>)\n",
      "3444 tensor(76182.3828, grad_fn=<MseLossBackward0>)\n",
      "3445 tensor(76182.2031, grad_fn=<MseLossBackward0>)\n",
      "3446 tensor(76182.0312, grad_fn=<MseLossBackward0>)\n",
      "3447 tensor(76181.8516, grad_fn=<MseLossBackward0>)\n",
      "3448 tensor(76181.6797, grad_fn=<MseLossBackward0>)\n",
      "3449 tensor(76181.5078, grad_fn=<MseLossBackward0>)\n",
      "3450 tensor(76181.3281, grad_fn=<MseLossBackward0>)\n",
      "3451 tensor(76181.1641, grad_fn=<MseLossBackward0>)\n",
      "3452 tensor(76181., grad_fn=<MseLossBackward0>)\n",
      "3453 tensor(76180.8203, grad_fn=<MseLossBackward0>)\n",
      "3454 tensor(76180.6484, grad_fn=<MseLossBackward0>)\n",
      "3455 tensor(76180.4844, grad_fn=<MseLossBackward0>)\n",
      "3456 tensor(76180.3203, grad_fn=<MseLossBackward0>)\n",
      "3457 tensor(76180.1406, grad_fn=<MseLossBackward0>)\n",
      "3458 tensor(76179.9766, grad_fn=<MseLossBackward0>)\n",
      "3459 tensor(76179.8125, grad_fn=<MseLossBackward0>)\n",
      "3460 tensor(76179.6484, grad_fn=<MseLossBackward0>)\n",
      "3461 tensor(76179.4766, grad_fn=<MseLossBackward0>)\n",
      "3462 tensor(76179.2969, grad_fn=<MseLossBackward0>)\n",
      "3463 tensor(76179.1484, grad_fn=<MseLossBackward0>)\n",
      "3464 tensor(76178.9766, grad_fn=<MseLossBackward0>)\n",
      "3465 tensor(76178.8047, grad_fn=<MseLossBackward0>)\n",
      "3466 tensor(76178.6484, grad_fn=<MseLossBackward0>)\n",
      "3467 tensor(76178.4844, grad_fn=<MseLossBackward0>)\n",
      "3468 tensor(76178.3203, grad_fn=<MseLossBackward0>)\n",
      "3469 tensor(76178.1641, grad_fn=<MseLossBackward0>)\n",
      "3470 tensor(76177.9922, grad_fn=<MseLossBackward0>)\n",
      "3471 tensor(76177.8359, grad_fn=<MseLossBackward0>)\n",
      "3472 tensor(76177.6641, grad_fn=<MseLossBackward0>)\n",
      "3473 tensor(76177.5078, grad_fn=<MseLossBackward0>)\n",
      "3474 tensor(76177.3438, grad_fn=<MseLossBackward0>)\n",
      "3475 tensor(76177.1797, grad_fn=<MseLossBackward0>)\n",
      "3476 tensor(76177.0234, grad_fn=<MseLossBackward0>)\n",
      "3477 tensor(76176.8594, grad_fn=<MseLossBackward0>)\n",
      "3478 tensor(76176.7031, grad_fn=<MseLossBackward0>)\n",
      "3479 tensor(76176.5391, grad_fn=<MseLossBackward0>)\n",
      "3480 tensor(76176.3828, grad_fn=<MseLossBackward0>)\n",
      "3481 tensor(76176.2188, grad_fn=<MseLossBackward0>)\n",
      "3482 tensor(76176.0625, grad_fn=<MseLossBackward0>)\n",
      "3483 tensor(76175.9062, grad_fn=<MseLossBackward0>)\n",
      "3484 tensor(76175.7422, grad_fn=<MseLossBackward0>)\n",
      "3485 tensor(76175.5938, grad_fn=<MseLossBackward0>)\n",
      "3486 tensor(76175.4375, grad_fn=<MseLossBackward0>)\n",
      "3487 tensor(76175.2812, grad_fn=<MseLossBackward0>)\n",
      "3488 tensor(76175.1250, grad_fn=<MseLossBackward0>)\n",
      "3489 tensor(76174.9688, grad_fn=<MseLossBackward0>)\n",
      "3490 tensor(76174.8203, grad_fn=<MseLossBackward0>)\n",
      "3491 tensor(76174.6562, grad_fn=<MseLossBackward0>)\n",
      "3492 tensor(76174.5078, grad_fn=<MseLossBackward0>)\n",
      "3493 tensor(76174.3516, grad_fn=<MseLossBackward0>)\n",
      "3494 tensor(76174.2031, grad_fn=<MseLossBackward0>)\n",
      "3495 tensor(76174.0469, grad_fn=<MseLossBackward0>)\n",
      "3496 tensor(76173.8906, grad_fn=<MseLossBackward0>)\n",
      "3497 tensor(76173.7422, grad_fn=<MseLossBackward0>)\n",
      "3498 tensor(76173.5859, grad_fn=<MseLossBackward0>)\n",
      "3499 tensor(76173.4375, grad_fn=<MseLossBackward0>)\n",
      "3500 tensor(76173.2891, grad_fn=<MseLossBackward0>)\n",
      "3501 tensor(76173.1406, grad_fn=<MseLossBackward0>)\n",
      "3502 tensor(76172.9844, grad_fn=<MseLossBackward0>)\n",
      "3503 tensor(76172.8359, grad_fn=<MseLossBackward0>)\n",
      "3504 tensor(76172.6875, grad_fn=<MseLossBackward0>)\n",
      "3505 tensor(76172.5391, grad_fn=<MseLossBackward0>)\n",
      "3506 tensor(76172.3906, grad_fn=<MseLossBackward0>)\n",
      "3507 tensor(76172.2422, grad_fn=<MseLossBackward0>)\n",
      "3508 tensor(76172.1016, grad_fn=<MseLossBackward0>)\n",
      "3509 tensor(76171.9453, grad_fn=<MseLossBackward0>)\n",
      "3510 tensor(76171.8047, grad_fn=<MseLossBackward0>)\n",
      "3511 tensor(76171.6641, grad_fn=<MseLossBackward0>)\n",
      "3512 tensor(76171.5078, grad_fn=<MseLossBackward0>)\n",
      "3513 tensor(76171.3594, grad_fn=<MseLossBackward0>)\n",
      "3514 tensor(76171.2188, grad_fn=<MseLossBackward0>)\n",
      "3515 tensor(76171.0781, grad_fn=<MseLossBackward0>)\n",
      "3516 tensor(76170.9297, grad_fn=<MseLossBackward0>)\n",
      "3517 tensor(76170.7969, grad_fn=<MseLossBackward0>)\n",
      "3518 tensor(76170.6406, grad_fn=<MseLossBackward0>)\n",
      "3519 tensor(76170.5000, grad_fn=<MseLossBackward0>)\n",
      "3520 tensor(76170.3594, grad_fn=<MseLossBackward0>)\n",
      "3521 tensor(76170.2188, grad_fn=<MseLossBackward0>)\n",
      "3522 tensor(76170.0781, grad_fn=<MseLossBackward0>)\n",
      "3523 tensor(76169.9375, grad_fn=<MseLossBackward0>)\n",
      "3524 tensor(76169.7969, grad_fn=<MseLossBackward0>)\n",
      "3525 tensor(76169.6484, grad_fn=<MseLossBackward0>)\n",
      "3526 tensor(76169.5078, grad_fn=<MseLossBackward0>)\n",
      "3527 tensor(76169.3750, grad_fn=<MseLossBackward0>)\n",
      "3528 tensor(76169.2344, grad_fn=<MseLossBackward0>)\n",
      "3529 tensor(76169.0938, grad_fn=<MseLossBackward0>)\n",
      "3530 tensor(76168.9531, grad_fn=<MseLossBackward0>)\n",
      "3531 tensor(76168.8203, grad_fn=<MseLossBackward0>)\n",
      "3532 tensor(76168.6797, grad_fn=<MseLossBackward0>)\n",
      "3533 tensor(76168.5391, grad_fn=<MseLossBackward0>)\n",
      "3534 tensor(76168.3984, grad_fn=<MseLossBackward0>)\n",
      "3535 tensor(76168.2656, grad_fn=<MseLossBackward0>)\n",
      "3536 tensor(76168.1328, grad_fn=<MseLossBackward0>)\n",
      "3537 tensor(76167.9922, grad_fn=<MseLossBackward0>)\n",
      "3538 tensor(76167.8594, grad_fn=<MseLossBackward0>)\n",
      "3539 tensor(76167.7188, grad_fn=<MseLossBackward0>)\n",
      "3540 tensor(76167.5859, grad_fn=<MseLossBackward0>)\n",
      "3541 tensor(76167.4453, grad_fn=<MseLossBackward0>)\n",
      "3542 tensor(76167.3125, grad_fn=<MseLossBackward0>)\n",
      "3543 tensor(76167.1875, grad_fn=<MseLossBackward0>)\n",
      "3544 tensor(76167.0547, grad_fn=<MseLossBackward0>)\n",
      "3545 tensor(76166.9141, grad_fn=<MseLossBackward0>)\n",
      "3546 tensor(76166.7812, grad_fn=<MseLossBackward0>)\n",
      "3547 tensor(76166.6484, grad_fn=<MseLossBackward0>)\n",
      "3548 tensor(76166.5156, grad_fn=<MseLossBackward0>)\n",
      "3549 tensor(76166.3828, grad_fn=<MseLossBackward0>)\n",
      "3550 tensor(76166.2500, grad_fn=<MseLossBackward0>)\n",
      "3551 tensor(76166.1250, grad_fn=<MseLossBackward0>)\n",
      "3552 tensor(76165.9922, grad_fn=<MseLossBackward0>)\n",
      "3553 tensor(76165.8594, grad_fn=<MseLossBackward0>)\n",
      "3554 tensor(76165.7422, grad_fn=<MseLossBackward0>)\n",
      "3555 tensor(76165.6094, grad_fn=<MseLossBackward0>)\n",
      "3556 tensor(76165.4766, grad_fn=<MseLossBackward0>)\n",
      "3557 tensor(76165.3438, grad_fn=<MseLossBackward0>)\n",
      "3558 tensor(76165.2109, grad_fn=<MseLossBackward0>)\n",
      "3559 tensor(76165.0938, grad_fn=<MseLossBackward0>)\n",
      "3560 tensor(76164.9609, grad_fn=<MseLossBackward0>)\n",
      "3561 tensor(76164.8359, grad_fn=<MseLossBackward0>)\n",
      "3562 tensor(76164.7109, grad_fn=<MseLossBackward0>)\n",
      "3563 tensor(76164.5781, grad_fn=<MseLossBackward0>)\n",
      "3564 tensor(76164.4453, grad_fn=<MseLossBackward0>)\n",
      "3565 tensor(76164.3359, grad_fn=<MseLossBackward0>)\n",
      "3566 tensor(76164.2031, grad_fn=<MseLossBackward0>)\n",
      "3567 tensor(76164.0781, grad_fn=<MseLossBackward0>)\n",
      "3568 tensor(76163.9531, grad_fn=<MseLossBackward0>)\n",
      "3569 tensor(76163.8203, grad_fn=<MseLossBackward0>)\n",
      "3570 tensor(76163.7031, grad_fn=<MseLossBackward0>)\n",
      "3571 tensor(76163.5703, grad_fn=<MseLossBackward0>)\n",
      "3572 tensor(76163.4531, grad_fn=<MseLossBackward0>)\n",
      "3573 tensor(76163.3281, grad_fn=<MseLossBackward0>)\n",
      "3574 tensor(76163.2109, grad_fn=<MseLossBackward0>)\n",
      "3575 tensor(76163.0859, grad_fn=<MseLossBackward0>)\n",
      "3576 tensor(76162.9609, grad_fn=<MseLossBackward0>)\n",
      "3577 tensor(76162.8438, grad_fn=<MseLossBackward0>)\n",
      "3578 tensor(76162.7188, grad_fn=<MseLossBackward0>)\n",
      "3579 tensor(76162.5938, grad_fn=<MseLossBackward0>)\n",
      "3580 tensor(76162.4766, grad_fn=<MseLossBackward0>)\n",
      "3581 tensor(76162.3594, grad_fn=<MseLossBackward0>)\n",
      "3582 tensor(76162.2344, grad_fn=<MseLossBackward0>)\n",
      "3583 tensor(76162.1250, grad_fn=<MseLossBackward0>)\n",
      "3584 tensor(76162., grad_fn=<MseLossBackward0>)\n",
      "3585 tensor(76161.8750, grad_fn=<MseLossBackward0>)\n",
      "3586 tensor(76161.7656, grad_fn=<MseLossBackward0>)\n",
      "3587 tensor(76161.6484, grad_fn=<MseLossBackward0>)\n",
      "3588 tensor(76161.5156, grad_fn=<MseLossBackward0>)\n",
      "3589 tensor(76161.4062, grad_fn=<MseLossBackward0>)\n",
      "3590 tensor(76161.2891, grad_fn=<MseLossBackward0>)\n",
      "3591 tensor(76161.1719, grad_fn=<MseLossBackward0>)\n",
      "3592 tensor(76161.0469, grad_fn=<MseLossBackward0>)\n",
      "3593 tensor(76160.9375, grad_fn=<MseLossBackward0>)\n",
      "3594 tensor(76160.8203, grad_fn=<MseLossBackward0>)\n",
      "3595 tensor(76160.7031, grad_fn=<MseLossBackward0>)\n",
      "3596 tensor(76160.5938, grad_fn=<MseLossBackward0>)\n",
      "3597 tensor(76160.4766, grad_fn=<MseLossBackward0>)\n",
      "3598 tensor(76160.3672, grad_fn=<MseLossBackward0>)\n",
      "3599 tensor(76160.2500, grad_fn=<MseLossBackward0>)\n",
      "3600 tensor(76160.1328, grad_fn=<MseLossBackward0>)\n",
      "3601 tensor(76160.0234, grad_fn=<MseLossBackward0>)\n",
      "3602 tensor(76159.9062, grad_fn=<MseLossBackward0>)\n",
      "3603 tensor(76159.7891, grad_fn=<MseLossBackward0>)\n",
      "3604 tensor(76159.6875, grad_fn=<MseLossBackward0>)\n",
      "3605 tensor(76159.5625, grad_fn=<MseLossBackward0>)\n",
      "3606 tensor(76159.4609, grad_fn=<MseLossBackward0>)\n",
      "3607 tensor(76159.3438, grad_fn=<MseLossBackward0>)\n",
      "3608 tensor(76159.2266, grad_fn=<MseLossBackward0>)\n",
      "3609 tensor(76159.1172, grad_fn=<MseLossBackward0>)\n",
      "3610 tensor(76159.0078, grad_fn=<MseLossBackward0>)\n",
      "3611 tensor(76158.8906, grad_fn=<MseLossBackward0>)\n",
      "3612 tensor(76158.7891, grad_fn=<MseLossBackward0>)\n",
      "3613 tensor(76158.6797, grad_fn=<MseLossBackward0>)\n",
      "3614 tensor(76158.5703, grad_fn=<MseLossBackward0>)\n",
      "3615 tensor(76158.4609, grad_fn=<MseLossBackward0>)\n",
      "3616 tensor(76158.3516, grad_fn=<MseLossBackward0>)\n",
      "3617 tensor(76158.2422, grad_fn=<MseLossBackward0>)\n",
      "3618 tensor(76158.1328, grad_fn=<MseLossBackward0>)\n",
      "3619 tensor(76158.0312, grad_fn=<MseLossBackward0>)\n",
      "3620 tensor(76157.9219, grad_fn=<MseLossBackward0>)\n",
      "3621 tensor(76157.8125, grad_fn=<MseLossBackward0>)\n",
      "3622 tensor(76157.7109, grad_fn=<MseLossBackward0>)\n",
      "3623 tensor(76157.6016, grad_fn=<MseLossBackward0>)\n",
      "3624 tensor(76157.4844, grad_fn=<MseLossBackward0>)\n",
      "3625 tensor(76157.3828, grad_fn=<MseLossBackward0>)\n",
      "3626 tensor(76157.2812, grad_fn=<MseLossBackward0>)\n",
      "3627 tensor(76157.1719, grad_fn=<MseLossBackward0>)\n",
      "3628 tensor(76157.0703, grad_fn=<MseLossBackward0>)\n",
      "3629 tensor(76156.9688, grad_fn=<MseLossBackward0>)\n",
      "3630 tensor(76156.8594, grad_fn=<MseLossBackward0>)\n",
      "3631 tensor(76156.7578, grad_fn=<MseLossBackward0>)\n",
      "3632 tensor(76156.6484, grad_fn=<MseLossBackward0>)\n",
      "3633 tensor(76156.5391, grad_fn=<MseLossBackward0>)\n",
      "3634 tensor(76156.4453, grad_fn=<MseLossBackward0>)\n",
      "3635 tensor(76156.3359, grad_fn=<MseLossBackward0>)\n",
      "3636 tensor(76156.2422, grad_fn=<MseLossBackward0>)\n",
      "3637 tensor(76156.1250, grad_fn=<MseLossBackward0>)\n",
      "3638 tensor(76156.0312, grad_fn=<MseLossBackward0>)\n",
      "3639 tensor(76155.9297, grad_fn=<MseLossBackward0>)\n",
      "3640 tensor(76155.8281, grad_fn=<MseLossBackward0>)\n",
      "3641 tensor(76155.7266, grad_fn=<MseLossBackward0>)\n",
      "3642 tensor(76155.6250, grad_fn=<MseLossBackward0>)\n",
      "3643 tensor(76155.5234, grad_fn=<MseLossBackward0>)\n",
      "3644 tensor(76155.4297, grad_fn=<MseLossBackward0>)\n",
      "3645 tensor(76155.3281, grad_fn=<MseLossBackward0>)\n",
      "3646 tensor(76155.2266, grad_fn=<MseLossBackward0>)\n",
      "3647 tensor(76155.1250, grad_fn=<MseLossBackward0>)\n",
      "3648 tensor(76155.0312, grad_fn=<MseLossBackward0>)\n",
      "3649 tensor(76154.9297, grad_fn=<MseLossBackward0>)\n",
      "3650 tensor(76154.8281, grad_fn=<MseLossBackward0>)\n",
      "3651 tensor(76154.7266, grad_fn=<MseLossBackward0>)\n",
      "3652 tensor(76154.6328, grad_fn=<MseLossBackward0>)\n",
      "3653 tensor(76154.5391, grad_fn=<MseLossBackward0>)\n",
      "3654 tensor(76154.4453, grad_fn=<MseLossBackward0>)\n",
      "3655 tensor(76154.3438, grad_fn=<MseLossBackward0>)\n",
      "3656 tensor(76154.2500, grad_fn=<MseLossBackward0>)\n",
      "3657 tensor(76154.1484, grad_fn=<MseLossBackward0>)\n",
      "3658 tensor(76154.0469, grad_fn=<MseLossBackward0>)\n",
      "3659 tensor(76153.9531, grad_fn=<MseLossBackward0>)\n",
      "3660 tensor(76153.8594, grad_fn=<MseLossBackward0>)\n",
      "3661 tensor(76153.7656, grad_fn=<MseLossBackward0>)\n",
      "3662 tensor(76153.6797, grad_fn=<MseLossBackward0>)\n",
      "3663 tensor(76153.5781, grad_fn=<MseLossBackward0>)\n",
      "3664 tensor(76153.4766, grad_fn=<MseLossBackward0>)\n",
      "3665 tensor(76153.3750, grad_fn=<MseLossBackward0>)\n",
      "3666 tensor(76153.2812, grad_fn=<MseLossBackward0>)\n",
      "3667 tensor(76153.1875, grad_fn=<MseLossBackward0>)\n",
      "3668 tensor(76153.1016, grad_fn=<MseLossBackward0>)\n",
      "3669 tensor(76153.0078, grad_fn=<MseLossBackward0>)\n",
      "3670 tensor(76152.9219, grad_fn=<MseLossBackward0>)\n",
      "3671 tensor(76152.8203, grad_fn=<MseLossBackward0>)\n",
      "3672 tensor(76152.7266, grad_fn=<MseLossBackward0>)\n",
      "3673 tensor(76152.6328, grad_fn=<MseLossBackward0>)\n",
      "3674 tensor(76152.5469, grad_fn=<MseLossBackward0>)\n",
      "3675 tensor(76152.4609, grad_fn=<MseLossBackward0>)\n",
      "3676 tensor(76152.3672, grad_fn=<MseLossBackward0>)\n",
      "3677 tensor(76152.2734, grad_fn=<MseLossBackward0>)\n",
      "3678 tensor(76152.1797, grad_fn=<MseLossBackward0>)\n",
      "3679 tensor(76152.0938, grad_fn=<MseLossBackward0>)\n",
      "3680 tensor(76152.0078, grad_fn=<MseLossBackward0>)\n",
      "3681 tensor(76151.9062, grad_fn=<MseLossBackward0>)\n",
      "3682 tensor(76151.8203, grad_fn=<MseLossBackward0>)\n",
      "3683 tensor(76151.7266, grad_fn=<MseLossBackward0>)\n",
      "3684 tensor(76151.6406, grad_fn=<MseLossBackward0>)\n",
      "3685 tensor(76151.5547, grad_fn=<MseLossBackward0>)\n",
      "3686 tensor(76151.4688, grad_fn=<MseLossBackward0>)\n",
      "3687 tensor(76151.3828, grad_fn=<MseLossBackward0>)\n",
      "3688 tensor(76151.2891, grad_fn=<MseLossBackward0>)\n",
      "3689 tensor(76151.2031, grad_fn=<MseLossBackward0>)\n",
      "3690 tensor(76151.1094, grad_fn=<MseLossBackward0>)\n",
      "3691 tensor(76151.0234, grad_fn=<MseLossBackward0>)\n",
      "3692 tensor(76150.9453, grad_fn=<MseLossBackward0>)\n",
      "3693 tensor(76150.8516, grad_fn=<MseLossBackward0>)\n",
      "3694 tensor(76150.7656, grad_fn=<MseLossBackward0>)\n",
      "3695 tensor(76150.6797, grad_fn=<MseLossBackward0>)\n",
      "3696 tensor(76150.5938, grad_fn=<MseLossBackward0>)\n",
      "3697 tensor(76150.5078, grad_fn=<MseLossBackward0>)\n",
      "3698 tensor(76150.4219, grad_fn=<MseLossBackward0>)\n",
      "3699 tensor(76150.3359, grad_fn=<MseLossBackward0>)\n",
      "3700 tensor(76150.2500, grad_fn=<MseLossBackward0>)\n",
      "3701 tensor(76150.1719, grad_fn=<MseLossBackward0>)\n",
      "3702 tensor(76150.0781, grad_fn=<MseLossBackward0>)\n",
      "3703 tensor(76150., grad_fn=<MseLossBackward0>)\n",
      "3704 tensor(76149.9219, grad_fn=<MseLossBackward0>)\n",
      "3705 tensor(76149.8359, grad_fn=<MseLossBackward0>)\n",
      "3706 tensor(76149.7500, grad_fn=<MseLossBackward0>)\n",
      "3707 tensor(76149.6641, grad_fn=<MseLossBackward0>)\n",
      "3708 tensor(76149.5859, grad_fn=<MseLossBackward0>)\n",
      "3709 tensor(76149.5078, grad_fn=<MseLossBackward0>)\n",
      "3710 tensor(76149.4219, grad_fn=<MseLossBackward0>)\n",
      "3711 tensor(76149.3359, grad_fn=<MseLossBackward0>)\n",
      "3712 tensor(76149.2578, grad_fn=<MseLossBackward0>)\n",
      "3713 tensor(76149.1797, grad_fn=<MseLossBackward0>)\n",
      "3714 tensor(76149.0938, grad_fn=<MseLossBackward0>)\n",
      "3715 tensor(76149.0156, grad_fn=<MseLossBackward0>)\n",
      "3716 tensor(76148.9297, grad_fn=<MseLossBackward0>)\n",
      "3717 tensor(76148.8516, grad_fn=<MseLossBackward0>)\n",
      "3718 tensor(76148.7656, grad_fn=<MseLossBackward0>)\n",
      "3719 tensor(76148.6875, grad_fn=<MseLossBackward0>)\n",
      "3720 tensor(76148.6094, grad_fn=<MseLossBackward0>)\n",
      "3721 tensor(76148.5312, grad_fn=<MseLossBackward0>)\n",
      "3722 tensor(76148.4531, grad_fn=<MseLossBackward0>)\n",
      "3723 tensor(76148.3750, grad_fn=<MseLossBackward0>)\n",
      "3724 tensor(76148.2891, grad_fn=<MseLossBackward0>)\n",
      "3725 tensor(76148.2109, grad_fn=<MseLossBackward0>)\n",
      "3726 tensor(76148.1406, grad_fn=<MseLossBackward0>)\n",
      "3727 tensor(76148.0625, grad_fn=<MseLossBackward0>)\n",
      "3728 tensor(76147.9766, grad_fn=<MseLossBackward0>)\n",
      "3729 tensor(76147.9062, grad_fn=<MseLossBackward0>)\n",
      "3730 tensor(76147.8281, grad_fn=<MseLossBackward0>)\n",
      "3731 tensor(76147.7500, grad_fn=<MseLossBackward0>)\n",
      "3732 tensor(76147.6719, grad_fn=<MseLossBackward0>)\n",
      "3733 tensor(76147.6016, grad_fn=<MseLossBackward0>)\n",
      "3734 tensor(76147.5234, grad_fn=<MseLossBackward0>)\n",
      "3735 tensor(76147.4375, grad_fn=<MseLossBackward0>)\n",
      "3736 tensor(76147.3672, grad_fn=<MseLossBackward0>)\n",
      "3737 tensor(76147.2891, grad_fn=<MseLossBackward0>)\n",
      "3738 tensor(76147.2109, grad_fn=<MseLossBackward0>)\n",
      "3739 tensor(76147.1484, grad_fn=<MseLossBackward0>)\n",
      "3740 tensor(76147.0625, grad_fn=<MseLossBackward0>)\n",
      "3741 tensor(76146.9922, grad_fn=<MseLossBackward0>)\n",
      "3742 tensor(76146.9141, grad_fn=<MseLossBackward0>)\n",
      "3743 tensor(76146.8438, grad_fn=<MseLossBackward0>)\n",
      "3744 tensor(76146.7656, grad_fn=<MseLossBackward0>)\n",
      "3745 tensor(76146.6875, grad_fn=<MseLossBackward0>)\n",
      "3746 tensor(76146.6250, grad_fn=<MseLossBackward0>)\n",
      "3747 tensor(76146.5547, grad_fn=<MseLossBackward0>)\n",
      "3748 tensor(76146.4688, grad_fn=<MseLossBackward0>)\n",
      "3749 tensor(76146.3984, grad_fn=<MseLossBackward0>)\n",
      "3750 tensor(76146.3359, grad_fn=<MseLossBackward0>)\n",
      "3751 tensor(76146.2500, grad_fn=<MseLossBackward0>)\n",
      "3752 tensor(76146.1875, grad_fn=<MseLossBackward0>)\n",
      "3753 tensor(76146.1094, grad_fn=<MseLossBackward0>)\n",
      "3754 tensor(76146.0391, grad_fn=<MseLossBackward0>)\n",
      "3755 tensor(76145.9766, grad_fn=<MseLossBackward0>)\n",
      "3756 tensor(76145.8906, grad_fn=<MseLossBackward0>)\n",
      "3757 tensor(76145.8281, grad_fn=<MseLossBackward0>)\n",
      "3758 tensor(76145.7500, grad_fn=<MseLossBackward0>)\n",
      "3759 tensor(76145.6875, grad_fn=<MseLossBackward0>)\n",
      "3760 tensor(76145.6094, grad_fn=<MseLossBackward0>)\n",
      "3761 tensor(76145.5469, grad_fn=<MseLossBackward0>)\n",
      "3762 tensor(76145.4766, grad_fn=<MseLossBackward0>)\n",
      "3763 tensor(76145.4062, grad_fn=<MseLossBackward0>)\n",
      "3764 tensor(76145.3359, grad_fn=<MseLossBackward0>)\n",
      "3765 tensor(76145.2578, grad_fn=<MseLossBackward0>)\n",
      "3766 tensor(76145.1953, grad_fn=<MseLossBackward0>)\n",
      "3767 tensor(76145.1250, grad_fn=<MseLossBackward0>)\n",
      "3768 tensor(76145.0625, grad_fn=<MseLossBackward0>)\n",
      "3769 tensor(76144.9844, grad_fn=<MseLossBackward0>)\n",
      "3770 tensor(76144.9219, grad_fn=<MseLossBackward0>)\n",
      "3771 tensor(76144.8516, grad_fn=<MseLossBackward0>)\n",
      "3772 tensor(76144.7891, grad_fn=<MseLossBackward0>)\n",
      "3773 tensor(76144.7188, grad_fn=<MseLossBackward0>)\n",
      "3774 tensor(76144.6484, grad_fn=<MseLossBackward0>)\n",
      "3775 tensor(76144.5781, grad_fn=<MseLossBackward0>)\n",
      "3776 tensor(76144.5156, grad_fn=<MseLossBackward0>)\n",
      "3777 tensor(76144.4531, grad_fn=<MseLossBackward0>)\n",
      "3778 tensor(76144.3828, grad_fn=<MseLossBackward0>)\n",
      "3779 tensor(76144.3203, grad_fn=<MseLossBackward0>)\n",
      "3780 tensor(76144.2500, grad_fn=<MseLossBackward0>)\n",
      "3781 tensor(76144.1875, grad_fn=<MseLossBackward0>)\n",
      "3782 tensor(76144.1172, grad_fn=<MseLossBackward0>)\n",
      "3783 tensor(76144.0547, grad_fn=<MseLossBackward0>)\n",
      "3784 tensor(76143.9922, grad_fn=<MseLossBackward0>)\n",
      "3785 tensor(76143.9219, grad_fn=<MseLossBackward0>)\n",
      "3786 tensor(76143.8594, grad_fn=<MseLossBackward0>)\n",
      "3787 tensor(76143.7969, grad_fn=<MseLossBackward0>)\n",
      "3788 tensor(76143.7344, grad_fn=<MseLossBackward0>)\n",
      "3789 tensor(76143.6641, grad_fn=<MseLossBackward0>)\n",
      "3790 tensor(76143.6016, grad_fn=<MseLossBackward0>)\n",
      "3791 tensor(76143.5391, grad_fn=<MseLossBackward0>)\n",
      "3792 tensor(76143.4766, grad_fn=<MseLossBackward0>)\n",
      "3793 tensor(76143.4141, grad_fn=<MseLossBackward0>)\n",
      "3794 tensor(76143.3438, grad_fn=<MseLossBackward0>)\n",
      "3795 tensor(76143.2812, grad_fn=<MseLossBackward0>)\n",
      "3796 tensor(76143.2266, grad_fn=<MseLossBackward0>)\n",
      "3797 tensor(76143.1562, grad_fn=<MseLossBackward0>)\n",
      "3798 tensor(76143.0938, grad_fn=<MseLossBackward0>)\n",
      "3799 tensor(76143.0312, grad_fn=<MseLossBackward0>)\n",
      "3800 tensor(76142.9766, grad_fn=<MseLossBackward0>)\n",
      "3801 tensor(76142.9062, grad_fn=<MseLossBackward0>)\n",
      "3802 tensor(76142.8516, grad_fn=<MseLossBackward0>)\n",
      "3803 tensor(76142.7969, grad_fn=<MseLossBackward0>)\n",
      "3804 tensor(76142.7266, grad_fn=<MseLossBackward0>)\n",
      "3805 tensor(76142.6719, grad_fn=<MseLossBackward0>)\n",
      "3806 tensor(76142.6016, grad_fn=<MseLossBackward0>)\n",
      "3807 tensor(76142.5547, grad_fn=<MseLossBackward0>)\n",
      "3808 tensor(76142.4844, grad_fn=<MseLossBackward0>)\n",
      "3809 tensor(76142.4297, grad_fn=<MseLossBackward0>)\n",
      "3810 tensor(76142.3672, grad_fn=<MseLossBackward0>)\n",
      "3811 tensor(76142.3047, grad_fn=<MseLossBackward0>)\n",
      "3812 tensor(76142.2500, grad_fn=<MseLossBackward0>)\n",
      "3813 tensor(76142.1875, grad_fn=<MseLossBackward0>)\n",
      "3814 tensor(76142.1328, grad_fn=<MseLossBackward0>)\n",
      "3815 tensor(76142.0625, grad_fn=<MseLossBackward0>)\n",
      "3816 tensor(76142.0156, grad_fn=<MseLossBackward0>)\n",
      "3817 tensor(76141.9453, grad_fn=<MseLossBackward0>)\n",
      "3818 tensor(76141.8906, grad_fn=<MseLossBackward0>)\n",
      "3819 tensor(76141.8359, grad_fn=<MseLossBackward0>)\n",
      "3820 tensor(76141.7734, grad_fn=<MseLossBackward0>)\n",
      "3821 tensor(76141.7188, grad_fn=<MseLossBackward0>)\n",
      "3822 tensor(76141.6641, grad_fn=<MseLossBackward0>)\n",
      "3823 tensor(76141.6094, grad_fn=<MseLossBackward0>)\n",
      "3824 tensor(76141.5469, grad_fn=<MseLossBackward0>)\n",
      "3825 tensor(76141.4922, grad_fn=<MseLossBackward0>)\n",
      "3826 tensor(76141.4297, grad_fn=<MseLossBackward0>)\n",
      "3827 tensor(76141.3750, grad_fn=<MseLossBackward0>)\n",
      "3828 tensor(76141.3125, grad_fn=<MseLossBackward0>)\n",
      "3829 tensor(76141.2656, grad_fn=<MseLossBackward0>)\n",
      "3830 tensor(76141.2031, grad_fn=<MseLossBackward0>)\n",
      "3831 tensor(76141.1562, grad_fn=<MseLossBackward0>)\n",
      "3832 tensor(76141.0938, grad_fn=<MseLossBackward0>)\n",
      "3833 tensor(76141.0391, grad_fn=<MseLossBackward0>)\n",
      "3834 tensor(76140.9766, grad_fn=<MseLossBackward0>)\n",
      "3835 tensor(76140.9297, grad_fn=<MseLossBackward0>)\n",
      "3836 tensor(76140.8750, grad_fn=<MseLossBackward0>)\n",
      "3837 tensor(76140.8203, grad_fn=<MseLossBackward0>)\n",
      "3838 tensor(76140.7656, grad_fn=<MseLossBackward0>)\n",
      "3839 tensor(76140.7109, grad_fn=<MseLossBackward0>)\n",
      "3840 tensor(76140.6562, grad_fn=<MseLossBackward0>)\n",
      "3841 tensor(76140.6016, grad_fn=<MseLossBackward0>)\n",
      "3842 tensor(76140.5391, grad_fn=<MseLossBackward0>)\n",
      "3843 tensor(76140.4922, grad_fn=<MseLossBackward0>)\n",
      "3844 tensor(76140.4375, grad_fn=<MseLossBackward0>)\n",
      "3845 tensor(76140.3828, grad_fn=<MseLossBackward0>)\n",
      "3846 tensor(76140.3359, grad_fn=<MseLossBackward0>)\n",
      "3847 tensor(76140.2812, grad_fn=<MseLossBackward0>)\n",
      "3848 tensor(76140.2266, grad_fn=<MseLossBackward0>)\n",
      "3849 tensor(76140.1797, grad_fn=<MseLossBackward0>)\n",
      "3850 tensor(76140.1172, grad_fn=<MseLossBackward0>)\n",
      "3851 tensor(76140.0625, grad_fn=<MseLossBackward0>)\n",
      "3852 tensor(76140.0156, grad_fn=<MseLossBackward0>)\n",
      "3853 tensor(76139.9609, grad_fn=<MseLossBackward0>)\n",
      "3854 tensor(76139.9141, grad_fn=<MseLossBackward0>)\n",
      "3855 tensor(76139.8594, grad_fn=<MseLossBackward0>)\n",
      "3856 tensor(76139.8047, grad_fn=<MseLossBackward0>)\n",
      "3857 tensor(76139.7578, grad_fn=<MseLossBackward0>)\n",
      "3858 tensor(76139.7109, grad_fn=<MseLossBackward0>)\n",
      "3859 tensor(76139.6562, grad_fn=<MseLossBackward0>)\n",
      "3860 tensor(76139.6172, grad_fn=<MseLossBackward0>)\n",
      "3861 tensor(76139.5547, grad_fn=<MseLossBackward0>)\n",
      "3862 tensor(76139.5000, grad_fn=<MseLossBackward0>)\n",
      "3863 tensor(76139.4531, grad_fn=<MseLossBackward0>)\n",
      "3864 tensor(76139.4141, grad_fn=<MseLossBackward0>)\n",
      "3865 tensor(76139.3516, grad_fn=<MseLossBackward0>)\n",
      "3866 tensor(76139.3047, grad_fn=<MseLossBackward0>)\n",
      "3867 tensor(76139.2500, grad_fn=<MseLossBackward0>)\n",
      "3868 tensor(76139.1953, grad_fn=<MseLossBackward0>)\n",
      "3869 tensor(76139.1562, grad_fn=<MseLossBackward0>)\n",
      "3870 tensor(76139.1094, grad_fn=<MseLossBackward0>)\n",
      "3871 tensor(76139.0625, grad_fn=<MseLossBackward0>)\n",
      "3872 tensor(76139.0078, grad_fn=<MseLossBackward0>)\n",
      "3873 tensor(76138.9609, grad_fn=<MseLossBackward0>)\n",
      "3874 tensor(76138.9219, grad_fn=<MseLossBackward0>)\n",
      "3875 tensor(76138.8594, grad_fn=<MseLossBackward0>)\n",
      "3876 tensor(76138.8125, grad_fn=<MseLossBackward0>)\n",
      "3877 tensor(76138.7578, grad_fn=<MseLossBackward0>)\n",
      "3878 tensor(76138.7109, grad_fn=<MseLossBackward0>)\n",
      "3879 tensor(76138.6641, grad_fn=<MseLossBackward0>)\n",
      "3880 tensor(76138.6250, grad_fn=<MseLossBackward0>)\n",
      "3881 tensor(76138.5703, grad_fn=<MseLossBackward0>)\n",
      "3882 tensor(76138.5312, grad_fn=<MseLossBackward0>)\n",
      "3883 tensor(76138.4844, grad_fn=<MseLossBackward0>)\n",
      "3884 tensor(76138.4297, grad_fn=<MseLossBackward0>)\n",
      "3885 tensor(76138.3906, grad_fn=<MseLossBackward0>)\n",
      "3886 tensor(76138.3359, grad_fn=<MseLossBackward0>)\n",
      "3887 tensor(76138.2969, grad_fn=<MseLossBackward0>)\n",
      "3888 tensor(76138.2500, grad_fn=<MseLossBackward0>)\n",
      "3889 tensor(76138.2031, grad_fn=<MseLossBackward0>)\n",
      "3890 tensor(76138.1562, grad_fn=<MseLossBackward0>)\n",
      "3891 tensor(76138.1016, grad_fn=<MseLossBackward0>)\n",
      "3892 tensor(76138.0625, grad_fn=<MseLossBackward0>)\n",
      "3893 tensor(76138.0156, grad_fn=<MseLossBackward0>)\n",
      "3894 tensor(76137.9766, grad_fn=<MseLossBackward0>)\n",
      "3895 tensor(76137.9297, grad_fn=<MseLossBackward0>)\n",
      "3896 tensor(76137.8828, grad_fn=<MseLossBackward0>)\n",
      "3897 tensor(76137.8438, grad_fn=<MseLossBackward0>)\n",
      "3898 tensor(76137.7969, grad_fn=<MseLossBackward0>)\n",
      "3899 tensor(76137.7578, grad_fn=<MseLossBackward0>)\n",
      "3900 tensor(76137.7109, grad_fn=<MseLossBackward0>)\n",
      "3901 tensor(76137.6641, grad_fn=<MseLossBackward0>)\n",
      "3902 tensor(76137.6172, grad_fn=<MseLossBackward0>)\n",
      "3903 tensor(76137.5781, grad_fn=<MseLossBackward0>)\n",
      "3904 tensor(76137.5312, grad_fn=<MseLossBackward0>)\n",
      "3905 tensor(76137.4844, grad_fn=<MseLossBackward0>)\n",
      "3906 tensor(76137.4375, grad_fn=<MseLossBackward0>)\n",
      "3907 tensor(76137.4062, grad_fn=<MseLossBackward0>)\n",
      "3908 tensor(76137.3516, grad_fn=<MseLossBackward0>)\n",
      "3909 tensor(76137.3125, grad_fn=<MseLossBackward0>)\n",
      "3910 tensor(76137.2734, grad_fn=<MseLossBackward0>)\n",
      "3911 tensor(76137.2266, grad_fn=<MseLossBackward0>)\n",
      "3912 tensor(76137.1953, grad_fn=<MseLossBackward0>)\n",
      "3913 tensor(76137.1484, grad_fn=<MseLossBackward0>)\n",
      "3914 tensor(76137.1016, grad_fn=<MseLossBackward0>)\n",
      "3915 tensor(76137.0625, grad_fn=<MseLossBackward0>)\n",
      "3916 tensor(76137.0234, grad_fn=<MseLossBackward0>)\n",
      "3917 tensor(76136.9766, grad_fn=<MseLossBackward0>)\n",
      "3918 tensor(76136.9375, grad_fn=<MseLossBackward0>)\n",
      "3919 tensor(76136.8906, grad_fn=<MseLossBackward0>)\n",
      "3920 tensor(76136.8516, grad_fn=<MseLossBackward0>)\n",
      "3921 tensor(76136.8047, grad_fn=<MseLossBackward0>)\n",
      "3922 tensor(76136.7656, grad_fn=<MseLossBackward0>)\n",
      "3923 tensor(76136.7344, grad_fn=<MseLossBackward0>)\n",
      "3924 tensor(76136.6953, grad_fn=<MseLossBackward0>)\n",
      "3925 tensor(76136.6562, grad_fn=<MseLossBackward0>)\n",
      "3926 tensor(76136.6094, grad_fn=<MseLossBackward0>)\n",
      "3927 tensor(76136.5703, grad_fn=<MseLossBackward0>)\n",
      "3928 tensor(76136.5312, grad_fn=<MseLossBackward0>)\n",
      "3929 tensor(76136.4844, grad_fn=<MseLossBackward0>)\n",
      "3930 tensor(76136.4531, grad_fn=<MseLossBackward0>)\n",
      "3931 tensor(76136.4062, grad_fn=<MseLossBackward0>)\n",
      "3932 tensor(76136.3672, grad_fn=<MseLossBackward0>)\n",
      "3933 tensor(76136.3359, grad_fn=<MseLossBackward0>)\n",
      "3934 tensor(76136.2891, grad_fn=<MseLossBackward0>)\n",
      "3935 tensor(76136.2422, grad_fn=<MseLossBackward0>)\n",
      "3936 tensor(76136.2109, grad_fn=<MseLossBackward0>)\n",
      "3937 tensor(76136.1641, grad_fn=<MseLossBackward0>)\n",
      "3938 tensor(76136.1328, grad_fn=<MseLossBackward0>)\n",
      "3939 tensor(76136.1094, grad_fn=<MseLossBackward0>)\n",
      "3940 tensor(76136.0625, grad_fn=<MseLossBackward0>)\n",
      "3941 tensor(76136.0156, grad_fn=<MseLossBackward0>)\n",
      "3942 tensor(76135.9766, grad_fn=<MseLossBackward0>)\n",
      "3943 tensor(76135.9375, grad_fn=<MseLossBackward0>)\n",
      "3944 tensor(76135.9062, grad_fn=<MseLossBackward0>)\n",
      "3945 tensor(76135.8594, grad_fn=<MseLossBackward0>)\n",
      "3946 tensor(76135.8281, grad_fn=<MseLossBackward0>)\n",
      "3947 tensor(76135.7891, grad_fn=<MseLossBackward0>)\n",
      "3948 tensor(76135.7578, grad_fn=<MseLossBackward0>)\n",
      "3949 tensor(76135.7109, grad_fn=<MseLossBackward0>)\n",
      "3950 tensor(76135.6719, grad_fn=<MseLossBackward0>)\n",
      "3951 tensor(76135.6406, grad_fn=<MseLossBackward0>)\n",
      "3952 tensor(76135.6016, grad_fn=<MseLossBackward0>)\n",
      "3953 tensor(76135.5703, grad_fn=<MseLossBackward0>)\n",
      "3954 tensor(76135.5234, grad_fn=<MseLossBackward0>)\n",
      "3955 tensor(76135.4844, grad_fn=<MseLossBackward0>)\n",
      "3956 tensor(76135.4609, grad_fn=<MseLossBackward0>)\n",
      "3957 tensor(76135.4219, grad_fn=<MseLossBackward0>)\n",
      "3958 tensor(76135.3828, grad_fn=<MseLossBackward0>)\n",
      "3959 tensor(76135.3516, grad_fn=<MseLossBackward0>)\n",
      "3960 tensor(76135.3125, grad_fn=<MseLossBackward0>)\n",
      "3961 tensor(76135.2812, grad_fn=<MseLossBackward0>)\n",
      "3962 tensor(76135.2422, grad_fn=<MseLossBackward0>)\n",
      "3963 tensor(76135.2031, grad_fn=<MseLossBackward0>)\n",
      "3964 tensor(76135.1719, grad_fn=<MseLossBackward0>)\n",
      "3965 tensor(76135.1328, grad_fn=<MseLossBackward0>)\n",
      "3966 tensor(76135.1016, grad_fn=<MseLossBackward0>)\n",
      "3967 tensor(76135.0547, grad_fn=<MseLossBackward0>)\n",
      "3968 tensor(76135.0234, grad_fn=<MseLossBackward0>)\n",
      "3969 tensor(76135., grad_fn=<MseLossBackward0>)\n",
      "3970 tensor(76134.9609, grad_fn=<MseLossBackward0>)\n",
      "3971 tensor(76134.9219, grad_fn=<MseLossBackward0>)\n",
      "3972 tensor(76134.8906, grad_fn=<MseLossBackward0>)\n",
      "3973 tensor(76134.8516, grad_fn=<MseLossBackward0>)\n",
      "3974 tensor(76134.8203, grad_fn=<MseLossBackward0>)\n",
      "3975 tensor(76134.7969, grad_fn=<MseLossBackward0>)\n",
      "3976 tensor(76134.7500, grad_fn=<MseLossBackward0>)\n",
      "3977 tensor(76134.7188, grad_fn=<MseLossBackward0>)\n",
      "3978 tensor(76134.6875, grad_fn=<MseLossBackward0>)\n",
      "3979 tensor(76134.6484, grad_fn=<MseLossBackward0>)\n",
      "3980 tensor(76134.6172, grad_fn=<MseLossBackward0>)\n",
      "3981 tensor(76134.5859, grad_fn=<MseLossBackward0>)\n",
      "3982 tensor(76134.5547, grad_fn=<MseLossBackward0>)\n",
      "3983 tensor(76134.5156, grad_fn=<MseLossBackward0>)\n",
      "3984 tensor(76134.4844, grad_fn=<MseLossBackward0>)\n",
      "3985 tensor(76134.4609, grad_fn=<MseLossBackward0>)\n",
      "3986 tensor(76134.4219, grad_fn=<MseLossBackward0>)\n",
      "3987 tensor(76134.3828, grad_fn=<MseLossBackward0>)\n",
      "3988 tensor(76134.3594, grad_fn=<MseLossBackward0>)\n",
      "3989 tensor(76134.3281, grad_fn=<MseLossBackward0>)\n",
      "3990 tensor(76134.2891, grad_fn=<MseLossBackward0>)\n",
      "3991 tensor(76134.2578, grad_fn=<MseLossBackward0>)\n",
      "3992 tensor(76134.2344, grad_fn=<MseLossBackward0>)\n",
      "3993 tensor(76134.1953, grad_fn=<MseLossBackward0>)\n",
      "3994 tensor(76134.1562, grad_fn=<MseLossBackward0>)\n",
      "3995 tensor(76134.1406, grad_fn=<MseLossBackward0>)\n",
      "3996 tensor(76134.1016, grad_fn=<MseLossBackward0>)\n",
      "3997 tensor(76134.0625, grad_fn=<MseLossBackward0>)\n",
      "3998 tensor(76134.0391, grad_fn=<MseLossBackward0>)\n",
      "3999 tensor(76134.0078, grad_fn=<MseLossBackward0>)\n",
      "4000 tensor(76133.9688, grad_fn=<MseLossBackward0>)\n",
      "4001 tensor(76133.9453, grad_fn=<MseLossBackward0>)\n",
      "4002 tensor(76133.9219, grad_fn=<MseLossBackward0>)\n",
      "4003 tensor(76133.8828, grad_fn=<MseLossBackward0>)\n",
      "4004 tensor(76133.8438, grad_fn=<MseLossBackward0>)\n",
      "4005 tensor(76133.8203, grad_fn=<MseLossBackward0>)\n",
      "4006 tensor(76133.7891, grad_fn=<MseLossBackward0>)\n",
      "4007 tensor(76133.7578, grad_fn=<MseLossBackward0>)\n",
      "4008 tensor(76133.7266, grad_fn=<MseLossBackward0>)\n",
      "4009 tensor(76133.7031, grad_fn=<MseLossBackward0>)\n",
      "4010 tensor(76133.6719, grad_fn=<MseLossBackward0>)\n",
      "4011 tensor(76133.6406, grad_fn=<MseLossBackward0>)\n",
      "4012 tensor(76133.6094, grad_fn=<MseLossBackward0>)\n",
      "4013 tensor(76133.5859, grad_fn=<MseLossBackward0>)\n",
      "4014 tensor(76133.5469, grad_fn=<MseLossBackward0>)\n",
      "4015 tensor(76133.5234, grad_fn=<MseLossBackward0>)\n",
      "4016 tensor(76133.4922, grad_fn=<MseLossBackward0>)\n",
      "4017 tensor(76133.4609, grad_fn=<MseLossBackward0>)\n",
      "4018 tensor(76133.4375, grad_fn=<MseLossBackward0>)\n",
      "4019 tensor(76133.4062, grad_fn=<MseLossBackward0>)\n",
      "4020 tensor(76133.3750, grad_fn=<MseLossBackward0>)\n",
      "4021 tensor(76133.3516, grad_fn=<MseLossBackward0>)\n",
      "4022 tensor(76133.3203, grad_fn=<MseLossBackward0>)\n",
      "4023 tensor(76133.2891, grad_fn=<MseLossBackward0>)\n",
      "4024 tensor(76133.2656, grad_fn=<MseLossBackward0>)\n",
      "4025 tensor(76133.2344, grad_fn=<MseLossBackward0>)\n",
      "4026 tensor(76133.2031, grad_fn=<MseLossBackward0>)\n",
      "4027 tensor(76133.1797, grad_fn=<MseLossBackward0>)\n",
      "4028 tensor(76133.1562, grad_fn=<MseLossBackward0>)\n",
      "4029 tensor(76133.1172, grad_fn=<MseLossBackward0>)\n",
      "4030 tensor(76133.1016, grad_fn=<MseLossBackward0>)\n",
      "4031 tensor(76133.0625, grad_fn=<MseLossBackward0>)\n",
      "4032 tensor(76133.0469, grad_fn=<MseLossBackward0>)\n",
      "4033 tensor(76133.0156, grad_fn=<MseLossBackward0>)\n",
      "4034 tensor(76132.9844, grad_fn=<MseLossBackward0>)\n",
      "4035 tensor(76132.9531, grad_fn=<MseLossBackward0>)\n",
      "4036 tensor(76132.9297, grad_fn=<MseLossBackward0>)\n",
      "4037 tensor(76132.8984, grad_fn=<MseLossBackward0>)\n",
      "4038 tensor(76132.8750, grad_fn=<MseLossBackward0>)\n",
      "4039 tensor(76132.8516, grad_fn=<MseLossBackward0>)\n",
      "4040 tensor(76132.8281, grad_fn=<MseLossBackward0>)\n",
      "4041 tensor(76132.7891, grad_fn=<MseLossBackward0>)\n",
      "4042 tensor(76132.7734, grad_fn=<MseLossBackward0>)\n",
      "4043 tensor(76132.7422, grad_fn=<MseLossBackward0>)\n",
      "4044 tensor(76132.7188, grad_fn=<MseLossBackward0>)\n",
      "4045 tensor(76132.6875, grad_fn=<MseLossBackward0>)\n",
      "4046 tensor(76132.6562, grad_fn=<MseLossBackward0>)\n",
      "4047 tensor(76132.6328, grad_fn=<MseLossBackward0>)\n",
      "4048 tensor(76132.6094, grad_fn=<MseLossBackward0>)\n",
      "4049 tensor(76132.5938, grad_fn=<MseLossBackward0>)\n",
      "4050 tensor(76132.5625, grad_fn=<MseLossBackward0>)\n",
      "4051 tensor(76132.5312, grad_fn=<MseLossBackward0>)\n",
      "4052 tensor(76132.5000, grad_fn=<MseLossBackward0>)\n",
      "4053 tensor(76132.4844, grad_fn=<MseLossBackward0>)\n",
      "4054 tensor(76132.4609, grad_fn=<MseLossBackward0>)\n",
      "4055 tensor(76132.4297, grad_fn=<MseLossBackward0>)\n",
      "4056 tensor(76132.4062, grad_fn=<MseLossBackward0>)\n",
      "4057 tensor(76132.3828, grad_fn=<MseLossBackward0>)\n",
      "4058 tensor(76132.3594, grad_fn=<MseLossBackward0>)\n",
      "4059 tensor(76132.3281, grad_fn=<MseLossBackward0>)\n",
      "4060 tensor(76132.3125, grad_fn=<MseLossBackward0>)\n",
      "4061 tensor(76132.2812, grad_fn=<MseLossBackward0>)\n",
      "4062 tensor(76132.2578, grad_fn=<MseLossBackward0>)\n",
      "4063 tensor(76132.2344, grad_fn=<MseLossBackward0>)\n",
      "4064 tensor(76132.2031, grad_fn=<MseLossBackward0>)\n",
      "4065 tensor(76132.1797, grad_fn=<MseLossBackward0>)\n",
      "4066 tensor(76132.1641, grad_fn=<MseLossBackward0>)\n",
      "4067 tensor(76132.1406, grad_fn=<MseLossBackward0>)\n",
      "4068 tensor(76132.1094, grad_fn=<MseLossBackward0>)\n",
      "4069 tensor(76132.0859, grad_fn=<MseLossBackward0>)\n",
      "4070 tensor(76132.0625, grad_fn=<MseLossBackward0>)\n",
      "4071 tensor(76132.0469, grad_fn=<MseLossBackward0>)\n",
      "4072 tensor(76132.0156, grad_fn=<MseLossBackward0>)\n",
      "4073 tensor(76132., grad_fn=<MseLossBackward0>)\n",
      "4074 tensor(76131.9688, grad_fn=<MseLossBackward0>)\n",
      "4075 tensor(76131.9531, grad_fn=<MseLossBackward0>)\n",
      "4076 tensor(76131.9219, grad_fn=<MseLossBackward0>)\n",
      "4077 tensor(76131.8984, grad_fn=<MseLossBackward0>)\n",
      "4078 tensor(76131.8750, grad_fn=<MseLossBackward0>)\n",
      "4079 tensor(76131.8516, grad_fn=<MseLossBackward0>)\n",
      "4080 tensor(76131.8281, grad_fn=<MseLossBackward0>)\n",
      "4081 tensor(76131.8125, grad_fn=<MseLossBackward0>)\n",
      "4082 tensor(76131.7812, grad_fn=<MseLossBackward0>)\n",
      "4083 tensor(76131.7656, grad_fn=<MseLossBackward0>)\n",
      "4084 tensor(76131.7344, grad_fn=<MseLossBackward0>)\n",
      "4085 tensor(76131.7188, grad_fn=<MseLossBackward0>)\n",
      "4086 tensor(76131.6953, grad_fn=<MseLossBackward0>)\n",
      "4087 tensor(76131.6797, grad_fn=<MseLossBackward0>)\n",
      "4088 tensor(76131.6406, grad_fn=<MseLossBackward0>)\n",
      "4089 tensor(76131.6250, grad_fn=<MseLossBackward0>)\n",
      "4090 tensor(76131.6016, grad_fn=<MseLossBackward0>)\n",
      "4091 tensor(76131.5859, grad_fn=<MseLossBackward0>)\n",
      "4092 tensor(76131.5547, grad_fn=<MseLossBackward0>)\n",
      "4093 tensor(76131.5391, grad_fn=<MseLossBackward0>)\n",
      "4094 tensor(76131.5156, grad_fn=<MseLossBackward0>)\n",
      "4095 tensor(76131.5000, grad_fn=<MseLossBackward0>)\n",
      "4096 tensor(76131.4688, grad_fn=<MseLossBackward0>)\n",
      "4097 tensor(76131.4531, grad_fn=<MseLossBackward0>)\n",
      "4098 tensor(76131.4219, grad_fn=<MseLossBackward0>)\n",
      "4099 tensor(76131.4062, grad_fn=<MseLossBackward0>)\n",
      "4100 tensor(76131.3828, grad_fn=<MseLossBackward0>)\n",
      "4101 tensor(76131.3672, grad_fn=<MseLossBackward0>)\n",
      "4102 tensor(76131.3516, grad_fn=<MseLossBackward0>)\n",
      "4103 tensor(76131.3203, grad_fn=<MseLossBackward0>)\n",
      "4104 tensor(76131.3047, grad_fn=<MseLossBackward0>)\n",
      "4105 tensor(76131.2812, grad_fn=<MseLossBackward0>)\n",
      "4106 tensor(76131.2656, grad_fn=<MseLossBackward0>)\n",
      "4107 tensor(76131.2344, grad_fn=<MseLossBackward0>)\n",
      "4108 tensor(76131.2188, grad_fn=<MseLossBackward0>)\n",
      "4109 tensor(76131.1953, grad_fn=<MseLossBackward0>)\n",
      "4110 tensor(76131.1797, grad_fn=<MseLossBackward0>)\n",
      "4111 tensor(76131.1562, grad_fn=<MseLossBackward0>)\n",
      "4112 tensor(76131.1406, grad_fn=<MseLossBackward0>)\n",
      "4113 tensor(76131.1172, grad_fn=<MseLossBackward0>)\n",
      "4114 tensor(76131.0938, grad_fn=<MseLossBackward0>)\n",
      "4115 tensor(76131.0703, grad_fn=<MseLossBackward0>)\n",
      "4116 tensor(76131.0547, grad_fn=<MseLossBackward0>)\n",
      "4117 tensor(76131.0391, grad_fn=<MseLossBackward0>)\n",
      "4118 tensor(76131.0078, grad_fn=<MseLossBackward0>)\n",
      "4119 tensor(76131., grad_fn=<MseLossBackward0>)\n",
      "4120 tensor(76130.9688, grad_fn=<MseLossBackward0>)\n",
      "4121 tensor(76130.9609, grad_fn=<MseLossBackward0>)\n",
      "4122 tensor(76130.9297, grad_fn=<MseLossBackward0>)\n",
      "4123 tensor(76130.9219, grad_fn=<MseLossBackward0>)\n",
      "4124 tensor(76130.8984, grad_fn=<MseLossBackward0>)\n",
      "4125 tensor(76130.8750, grad_fn=<MseLossBackward0>)\n",
      "4126 tensor(76130.8594, grad_fn=<MseLossBackward0>)\n",
      "4127 tensor(76130.8438, grad_fn=<MseLossBackward0>)\n",
      "4128 tensor(76130.8281, grad_fn=<MseLossBackward0>)\n",
      "4129 tensor(76130.8047, grad_fn=<MseLossBackward0>)\n",
      "4130 tensor(76130.7812, grad_fn=<MseLossBackward0>)\n",
      "4131 tensor(76130.7578, grad_fn=<MseLossBackward0>)\n",
      "4132 tensor(76130.7422, grad_fn=<MseLossBackward0>)\n",
      "4133 tensor(76130.7266, grad_fn=<MseLossBackward0>)\n",
      "4134 tensor(76130.7109, grad_fn=<MseLossBackward0>)\n",
      "4135 tensor(76130.6875, grad_fn=<MseLossBackward0>)\n",
      "4136 tensor(76130.6719, grad_fn=<MseLossBackward0>)\n",
      "4137 tensor(76130.6484, grad_fn=<MseLossBackward0>)\n",
      "4138 tensor(76130.6328, grad_fn=<MseLossBackward0>)\n",
      "4139 tensor(76130.6250, grad_fn=<MseLossBackward0>)\n",
      "4140 tensor(76130.6016, grad_fn=<MseLossBackward0>)\n",
      "4141 tensor(76130.5859, grad_fn=<MseLossBackward0>)\n",
      "4142 tensor(76130.5625, grad_fn=<MseLossBackward0>)\n",
      "4143 tensor(76130.5391, grad_fn=<MseLossBackward0>)\n",
      "4144 tensor(76130.5234, grad_fn=<MseLossBackward0>)\n",
      "4145 tensor(76130.5078, grad_fn=<MseLossBackward0>)\n",
      "4146 tensor(76130.4922, grad_fn=<MseLossBackward0>)\n",
      "4147 tensor(76130.4766, grad_fn=<MseLossBackward0>)\n",
      "4148 tensor(76130.4609, grad_fn=<MseLossBackward0>)\n",
      "4149 tensor(76130.4453, grad_fn=<MseLossBackward0>)\n",
      "4150 tensor(76130.4141, grad_fn=<MseLossBackward0>)\n",
      "4151 tensor(76130.4062, grad_fn=<MseLossBackward0>)\n",
      "4152 tensor(76130.3906, grad_fn=<MseLossBackward0>)\n",
      "4153 tensor(76130.3672, grad_fn=<MseLossBackward0>)\n",
      "4154 tensor(76130.3516, grad_fn=<MseLossBackward0>)\n",
      "4155 tensor(76130.3281, grad_fn=<MseLossBackward0>)\n",
      "4156 tensor(76130.3125, grad_fn=<MseLossBackward0>)\n",
      "4157 tensor(76130.3047, grad_fn=<MseLossBackward0>)\n",
      "4158 tensor(76130.2812, grad_fn=<MseLossBackward0>)\n",
      "4159 tensor(76130.2656, grad_fn=<MseLossBackward0>)\n",
      "4160 tensor(76130.2422, grad_fn=<MseLossBackward0>)\n",
      "4161 tensor(76130.2266, grad_fn=<MseLossBackward0>)\n",
      "4162 tensor(76130.2109, grad_fn=<MseLossBackward0>)\n",
      "4163 tensor(76130.1953, grad_fn=<MseLossBackward0>)\n",
      "4164 tensor(76130.1875, grad_fn=<MseLossBackward0>)\n",
      "4165 tensor(76130.1719, grad_fn=<MseLossBackward0>)\n",
      "4166 tensor(76130.1484, grad_fn=<MseLossBackward0>)\n",
      "4167 tensor(76130.1328, grad_fn=<MseLossBackward0>)\n",
      "4168 tensor(76130.1094, grad_fn=<MseLossBackward0>)\n",
      "4169 tensor(76130.0938, grad_fn=<MseLossBackward0>)\n",
      "4170 tensor(76130.0859, grad_fn=<MseLossBackward0>)\n",
      "4171 tensor(76130.0703, grad_fn=<MseLossBackward0>)\n",
      "4172 tensor(76130.0469, grad_fn=<MseLossBackward0>)\n",
      "4173 tensor(76130.0391, grad_fn=<MseLossBackward0>)\n",
      "4174 tensor(76130.0234, grad_fn=<MseLossBackward0>)\n",
      "4175 tensor(76130.0078, grad_fn=<MseLossBackward0>)\n",
      "4176 tensor(76129.9844, grad_fn=<MseLossBackward0>)\n",
      "4177 tensor(76129.9766, grad_fn=<MseLossBackward0>)\n",
      "4178 tensor(76129.9609, grad_fn=<MseLossBackward0>)\n",
      "4179 tensor(76129.9453, grad_fn=<MseLossBackward0>)\n",
      "4180 tensor(76129.9219, grad_fn=<MseLossBackward0>)\n",
      "4181 tensor(76129.9141, grad_fn=<MseLossBackward0>)\n",
      "4182 tensor(76129.8906, grad_fn=<MseLossBackward0>)\n",
      "4183 tensor(76129.8672, grad_fn=<MseLossBackward0>)\n",
      "4184 tensor(76129.8672, grad_fn=<MseLossBackward0>)\n",
      "4185 tensor(76129.8516, grad_fn=<MseLossBackward0>)\n",
      "4186 tensor(76129.8359, grad_fn=<MseLossBackward0>)\n",
      "4187 tensor(76129.8203, grad_fn=<MseLossBackward0>)\n",
      "4188 tensor(76129.8047, grad_fn=<MseLossBackward0>)\n",
      "4189 tensor(76129.7891, grad_fn=<MseLossBackward0>)\n",
      "4190 tensor(76129.7734, grad_fn=<MseLossBackward0>)\n",
      "4191 tensor(76129.7578, grad_fn=<MseLossBackward0>)\n",
      "4192 tensor(76129.7500, grad_fn=<MseLossBackward0>)\n",
      "4193 tensor(76129.7344, grad_fn=<MseLossBackward0>)\n",
      "4194 tensor(76129.7188, grad_fn=<MseLossBackward0>)\n",
      "4195 tensor(76129.7031, grad_fn=<MseLossBackward0>)\n",
      "4196 tensor(76129.6875, grad_fn=<MseLossBackward0>)\n",
      "4197 tensor(76129.6719, grad_fn=<MseLossBackward0>)\n",
      "4198 tensor(76129.6562, grad_fn=<MseLossBackward0>)\n",
      "4199 tensor(76129.6484, grad_fn=<MseLossBackward0>)\n",
      "4200 tensor(76129.6328, grad_fn=<MseLossBackward0>)\n",
      "4201 tensor(76129.6250, grad_fn=<MseLossBackward0>)\n",
      "4202 tensor(76129.6016, grad_fn=<MseLossBackward0>)\n",
      "4203 tensor(76129.5859, grad_fn=<MseLossBackward0>)\n",
      "4204 tensor(76129.5781, grad_fn=<MseLossBackward0>)\n",
      "4205 tensor(76129.5547, grad_fn=<MseLossBackward0>)\n",
      "4206 tensor(76129.5391, grad_fn=<MseLossBackward0>)\n",
      "4207 tensor(76129.5391, grad_fn=<MseLossBackward0>)\n",
      "4208 tensor(76129.5156, grad_fn=<MseLossBackward0>)\n",
      "4209 tensor(76129.5000, grad_fn=<MseLossBackward0>)\n",
      "4210 tensor(76129.4922, grad_fn=<MseLossBackward0>)\n",
      "4211 tensor(76129.4766, grad_fn=<MseLossBackward0>)\n",
      "4212 tensor(76129.4531, grad_fn=<MseLossBackward0>)\n",
      "4213 tensor(76129.4453, grad_fn=<MseLossBackward0>)\n",
      "4214 tensor(76129.4375, grad_fn=<MseLossBackward0>)\n",
      "4215 tensor(76129.4297, grad_fn=<MseLossBackward0>)\n",
      "4216 tensor(76129.4141, grad_fn=<MseLossBackward0>)\n",
      "4217 tensor(76129.3984, grad_fn=<MseLossBackward0>)\n",
      "4218 tensor(76129.3828, grad_fn=<MseLossBackward0>)\n",
      "4219 tensor(76129.3672, grad_fn=<MseLossBackward0>)\n",
      "4220 tensor(76129.3594, grad_fn=<MseLossBackward0>)\n",
      "4221 tensor(76129.3438, grad_fn=<MseLossBackward0>)\n",
      "4222 tensor(76129.3203, grad_fn=<MseLossBackward0>)\n",
      "4223 tensor(76129.3203, grad_fn=<MseLossBackward0>)\n",
      "4224 tensor(76129.3125, grad_fn=<MseLossBackward0>)\n",
      "4225 tensor(76129.2812, grad_fn=<MseLossBackward0>)\n",
      "4226 tensor(76129.2812, grad_fn=<MseLossBackward0>)\n",
      "4227 tensor(76129.2656, grad_fn=<MseLossBackward0>)\n",
      "4228 tensor(76129.2500, grad_fn=<MseLossBackward0>)\n",
      "4229 tensor(76129.2344, grad_fn=<MseLossBackward0>)\n",
      "4230 tensor(76129.2266, grad_fn=<MseLossBackward0>)\n",
      "4231 tensor(76129.2109, grad_fn=<MseLossBackward0>)\n",
      "4232 tensor(76129.2031, grad_fn=<MseLossBackward0>)\n",
      "4233 tensor(76129.1953, grad_fn=<MseLossBackward0>)\n",
      "4234 tensor(76129.1875, grad_fn=<MseLossBackward0>)\n",
      "4235 tensor(76129.1641, grad_fn=<MseLossBackward0>)\n",
      "4236 tensor(76129.1484, grad_fn=<MseLossBackward0>)\n",
      "4237 tensor(76129.1406, grad_fn=<MseLossBackward0>)\n",
      "4238 tensor(76129.1250, grad_fn=<MseLossBackward0>)\n",
      "4239 tensor(76129.1172, grad_fn=<MseLossBackward0>)\n",
      "4240 tensor(76129.1016, grad_fn=<MseLossBackward0>)\n",
      "4241 tensor(76129.0938, grad_fn=<MseLossBackward0>)\n",
      "4242 tensor(76129.0859, grad_fn=<MseLossBackward0>)\n",
      "4243 tensor(76129.0703, grad_fn=<MseLossBackward0>)\n",
      "4244 tensor(76129.0625, grad_fn=<MseLossBackward0>)\n",
      "4245 tensor(76129.0391, grad_fn=<MseLossBackward0>)\n",
      "4246 tensor(76129.0312, grad_fn=<MseLossBackward0>)\n",
      "4247 tensor(76129.0234, grad_fn=<MseLossBackward0>)\n",
      "4248 tensor(76129., grad_fn=<MseLossBackward0>)\n",
      "4249 tensor(76128.9922, grad_fn=<MseLossBackward0>)\n",
      "4250 tensor(76128.9844, grad_fn=<MseLossBackward0>)\n",
      "4251 tensor(76128.9766, grad_fn=<MseLossBackward0>)\n",
      "4252 tensor(76128.9766, grad_fn=<MseLossBackward0>)\n",
      "4253 tensor(76128.9531, grad_fn=<MseLossBackward0>)\n",
      "4254 tensor(76128.9453, grad_fn=<MseLossBackward0>)\n",
      "4255 tensor(76128.9297, grad_fn=<MseLossBackward0>)\n",
      "4256 tensor(76128.9141, grad_fn=<MseLossBackward0>)\n",
      "4257 tensor(76128.9062, grad_fn=<MseLossBackward0>)\n",
      "4258 tensor(76128.8906, grad_fn=<MseLossBackward0>)\n",
      "4259 tensor(76128.8828, grad_fn=<MseLossBackward0>)\n",
      "4260 tensor(76128.8750, grad_fn=<MseLossBackward0>)\n",
      "4261 tensor(76128.8672, grad_fn=<MseLossBackward0>)\n",
      "4262 tensor(76128.8516, grad_fn=<MseLossBackward0>)\n",
      "4263 tensor(76128.8438, grad_fn=<MseLossBackward0>)\n",
      "4264 tensor(76128.8281, grad_fn=<MseLossBackward0>)\n",
      "4265 tensor(76128.8125, grad_fn=<MseLossBackward0>)\n",
      "4266 tensor(76128.8047, grad_fn=<MseLossBackward0>)\n",
      "4267 tensor(76128.7969, grad_fn=<MseLossBackward0>)\n",
      "4268 tensor(76128.7812, grad_fn=<MseLossBackward0>)\n",
      "4269 tensor(76128.7734, grad_fn=<MseLossBackward0>)\n",
      "4270 tensor(76128.7656, grad_fn=<MseLossBackward0>)\n",
      "4271 tensor(76128.7578, grad_fn=<MseLossBackward0>)\n",
      "4272 tensor(76128.7422, grad_fn=<MseLossBackward0>)\n",
      "4273 tensor(76128.7266, grad_fn=<MseLossBackward0>)\n",
      "4274 tensor(76128.7266, grad_fn=<MseLossBackward0>)\n",
      "4275 tensor(76128.7109, grad_fn=<MseLossBackward0>)\n",
      "4276 tensor(76128.7031, grad_fn=<MseLossBackward0>)\n",
      "4277 tensor(76128.6953, grad_fn=<MseLossBackward0>)\n",
      "4278 tensor(76128.6719, grad_fn=<MseLossBackward0>)\n",
      "4279 tensor(76128.6641, grad_fn=<MseLossBackward0>)\n",
      "4280 tensor(76128.6562, grad_fn=<MseLossBackward0>)\n",
      "4281 tensor(76128.6562, grad_fn=<MseLossBackward0>)\n",
      "4282 tensor(76128.6328, grad_fn=<MseLossBackward0>)\n",
      "4283 tensor(76128.6328, grad_fn=<MseLossBackward0>)\n",
      "4284 tensor(76128.6250, grad_fn=<MseLossBackward0>)\n",
      "4285 tensor(76128.6172, grad_fn=<MseLossBackward0>)\n",
      "4286 tensor(76128.5938, grad_fn=<MseLossBackward0>)\n",
      "4287 tensor(76128.5859, grad_fn=<MseLossBackward0>)\n",
      "4288 tensor(76128.5703, grad_fn=<MseLossBackward0>)\n",
      "4289 tensor(76128.5703, grad_fn=<MseLossBackward0>)\n",
      "4290 tensor(76128.5625, grad_fn=<MseLossBackward0>)\n",
      "4291 tensor(76128.5469, grad_fn=<MseLossBackward0>)\n",
      "4292 tensor(76128.5391, grad_fn=<MseLossBackward0>)\n",
      "4293 tensor(76128.5312, grad_fn=<MseLossBackward0>)\n",
      "4294 tensor(76128.5312, grad_fn=<MseLossBackward0>)\n",
      "4295 tensor(76128.5078, grad_fn=<MseLossBackward0>)\n",
      "4296 tensor(76128.5078, grad_fn=<MseLossBackward0>)\n",
      "4297 tensor(76128.4922, grad_fn=<MseLossBackward0>)\n",
      "4298 tensor(76128.4844, grad_fn=<MseLossBackward0>)\n",
      "4299 tensor(76128.4688, grad_fn=<MseLossBackward0>)\n",
      "4300 tensor(76128.4609, grad_fn=<MseLossBackward0>)\n",
      "4301 tensor(76128.4453, grad_fn=<MseLossBackward0>)\n",
      "4302 tensor(76128.4375, grad_fn=<MseLossBackward0>)\n",
      "4303 tensor(76128.4375, grad_fn=<MseLossBackward0>)\n",
      "4304 tensor(76128.4297, grad_fn=<MseLossBackward0>)\n",
      "4305 tensor(76128.4219, grad_fn=<MseLossBackward0>)\n",
      "4306 tensor(76128.4219, grad_fn=<MseLossBackward0>)\n",
      "4307 tensor(76128.3984, grad_fn=<MseLossBackward0>)\n",
      "4308 tensor(76128.3984, grad_fn=<MseLossBackward0>)\n",
      "4309 tensor(76128.3828, grad_fn=<MseLossBackward0>)\n",
      "4310 tensor(76128.3750, grad_fn=<MseLossBackward0>)\n",
      "4311 tensor(76128.3594, grad_fn=<MseLossBackward0>)\n",
      "4312 tensor(76128.3516, grad_fn=<MseLossBackward0>)\n",
      "4313 tensor(76128.3516, grad_fn=<MseLossBackward0>)\n",
      "4314 tensor(76128.3359, grad_fn=<MseLossBackward0>)\n",
      "4315 tensor(76128.3281, grad_fn=<MseLossBackward0>)\n",
      "4316 tensor(76128.3281, grad_fn=<MseLossBackward0>)\n",
      "4317 tensor(76128.3125, grad_fn=<MseLossBackward0>)\n",
      "4318 tensor(76128.3047, grad_fn=<MseLossBackward0>)\n",
      "4319 tensor(76128.2969, grad_fn=<MseLossBackward0>)\n",
      "4320 tensor(76128.2891, grad_fn=<MseLossBackward0>)\n",
      "4321 tensor(76128.2734, grad_fn=<MseLossBackward0>)\n",
      "4322 tensor(76128.2656, grad_fn=<MseLossBackward0>)\n",
      "4323 tensor(76128.2578, grad_fn=<MseLossBackward0>)\n",
      "4324 tensor(76128.2500, grad_fn=<MseLossBackward0>)\n",
      "4325 tensor(76128.2422, grad_fn=<MseLossBackward0>)\n",
      "4326 tensor(76128.2344, grad_fn=<MseLossBackward0>)\n",
      "4327 tensor(76128.2266, grad_fn=<MseLossBackward0>)\n",
      "4328 tensor(76128.2188, grad_fn=<MseLossBackward0>)\n",
      "4329 tensor(76128.2188, grad_fn=<MseLossBackward0>)\n",
      "4330 tensor(76128.2031, grad_fn=<MseLossBackward0>)\n",
      "4331 tensor(76128.2031, grad_fn=<MseLossBackward0>)\n",
      "4332 tensor(76128.1875, grad_fn=<MseLossBackward0>)\n",
      "4333 tensor(76128.1719, grad_fn=<MseLossBackward0>)\n",
      "4334 tensor(76128.1719, grad_fn=<MseLossBackward0>)\n",
      "4335 tensor(76128.1562, grad_fn=<MseLossBackward0>)\n",
      "4336 tensor(76128.1484, grad_fn=<MseLossBackward0>)\n",
      "4337 tensor(76128.1484, grad_fn=<MseLossBackward0>)\n",
      "4338 tensor(76128.1406, grad_fn=<MseLossBackward0>)\n",
      "4339 tensor(76128.1250, grad_fn=<MseLossBackward0>)\n",
      "4340 tensor(76128.1250, grad_fn=<MseLossBackward0>)\n",
      "4341 tensor(76128.1094, grad_fn=<MseLossBackward0>)\n",
      "4342 tensor(76128.1094, grad_fn=<MseLossBackward0>)\n",
      "4343 tensor(76128.1094, grad_fn=<MseLossBackward0>)\n",
      "4344 tensor(76128.1016, grad_fn=<MseLossBackward0>)\n",
      "4345 tensor(76128.0859, grad_fn=<MseLossBackward0>)\n",
      "4346 tensor(76128.0703, grad_fn=<MseLossBackward0>)\n",
      "4347 tensor(76128.0703, grad_fn=<MseLossBackward0>)\n",
      "4348 tensor(76128.0625, grad_fn=<MseLossBackward0>)\n",
      "4349 tensor(76128.0547, grad_fn=<MseLossBackward0>)\n",
      "4350 tensor(76128.0547, grad_fn=<MseLossBackward0>)\n",
      "4351 tensor(76128.0391, grad_fn=<MseLossBackward0>)\n",
      "4352 tensor(76128.0312, grad_fn=<MseLossBackward0>)\n",
      "4353 tensor(76128.0234, grad_fn=<MseLossBackward0>)\n",
      "4354 tensor(76128.0156, grad_fn=<MseLossBackward0>)\n",
      "4355 tensor(76128.0078, grad_fn=<MseLossBackward0>)\n",
      "4356 tensor(76128., grad_fn=<MseLossBackward0>)\n",
      "4357 tensor(76128., grad_fn=<MseLossBackward0>)\n",
      "4358 tensor(76127.9844, grad_fn=<MseLossBackward0>)\n",
      "4359 tensor(76127.9844, grad_fn=<MseLossBackward0>)\n",
      "4360 tensor(76127.9844, grad_fn=<MseLossBackward0>)\n",
      "4361 tensor(76127.9688, grad_fn=<MseLossBackward0>)\n",
      "4362 tensor(76127.9688, grad_fn=<MseLossBackward0>)\n",
      "4363 tensor(76127.9531, grad_fn=<MseLossBackward0>)\n",
      "4364 tensor(76127.9453, grad_fn=<MseLossBackward0>)\n",
      "4365 tensor(76127.9375, grad_fn=<MseLossBackward0>)\n",
      "4366 tensor(76127.9297, grad_fn=<MseLossBackward0>)\n",
      "4367 tensor(76127.9219, grad_fn=<MseLossBackward0>)\n",
      "4368 tensor(76127.9219, grad_fn=<MseLossBackward0>)\n",
      "4369 tensor(76127.9062, grad_fn=<MseLossBackward0>)\n",
      "4370 tensor(76127.8906, grad_fn=<MseLossBackward0>)\n",
      "4371 tensor(76127.8906, grad_fn=<MseLossBackward0>)\n",
      "4372 tensor(76127.8906, grad_fn=<MseLossBackward0>)\n",
      "4373 tensor(76127.8906, grad_fn=<MseLossBackward0>)\n",
      "4374 tensor(76127.8828, grad_fn=<MseLossBackward0>)\n",
      "4375 tensor(76127.8828, grad_fn=<MseLossBackward0>)\n",
      "4376 tensor(76127.8672, grad_fn=<MseLossBackward0>)\n",
      "4377 tensor(76127.8516, grad_fn=<MseLossBackward0>)\n",
      "4378 tensor(76127.8516, grad_fn=<MseLossBackward0>)\n",
      "4379 tensor(76127.8516, grad_fn=<MseLossBackward0>)\n",
      "4380 tensor(76127.8359, grad_fn=<MseLossBackward0>)\n",
      "4381 tensor(76127.8359, grad_fn=<MseLossBackward0>)\n",
      "4382 tensor(76127.8281, grad_fn=<MseLossBackward0>)\n",
      "4383 tensor(76127.8203, grad_fn=<MseLossBackward0>)\n",
      "4384 tensor(76127.8047, grad_fn=<MseLossBackward0>)\n",
      "4385 tensor(76127.8047, grad_fn=<MseLossBackward0>)\n",
      "4386 tensor(76127.7969, grad_fn=<MseLossBackward0>)\n",
      "4387 tensor(76127.7891, grad_fn=<MseLossBackward0>)\n",
      "4388 tensor(76127.7812, grad_fn=<MseLossBackward0>)\n",
      "4389 tensor(76127.7812, grad_fn=<MseLossBackward0>)\n",
      "4390 tensor(76127.7656, grad_fn=<MseLossBackward0>)\n",
      "4391 tensor(76127.7656, grad_fn=<MseLossBackward0>)\n",
      "4392 tensor(76127.7578, grad_fn=<MseLossBackward0>)\n",
      "4393 tensor(76127.7578, grad_fn=<MseLossBackward0>)\n",
      "4394 tensor(76127.7500, grad_fn=<MseLossBackward0>)\n",
      "4395 tensor(76127.7422, grad_fn=<MseLossBackward0>)\n",
      "4396 tensor(76127.7422, grad_fn=<MseLossBackward0>)\n",
      "4397 tensor(76127.7344, grad_fn=<MseLossBackward0>)\n",
      "4398 tensor(76127.7188, grad_fn=<MseLossBackward0>)\n",
      "4399 tensor(76127.7188, grad_fn=<MseLossBackward0>)\n",
      "4400 tensor(76127.7109, grad_fn=<MseLossBackward0>)\n",
      "4401 tensor(76127.7031, grad_fn=<MseLossBackward0>)\n",
      "4402 tensor(76127.7031, grad_fn=<MseLossBackward0>)\n",
      "4403 tensor(76127.6953, grad_fn=<MseLossBackward0>)\n",
      "4404 tensor(76127.6875, grad_fn=<MseLossBackward0>)\n",
      "4405 tensor(76127.6719, grad_fn=<MseLossBackward0>)\n",
      "4406 tensor(76127.6719, grad_fn=<MseLossBackward0>)\n",
      "4407 tensor(76127.6719, grad_fn=<MseLossBackward0>)\n",
      "4408 tensor(76127.6719, grad_fn=<MseLossBackward0>)\n",
      "4409 tensor(76127.6641, grad_fn=<MseLossBackward0>)\n",
      "4410 tensor(76127.6562, grad_fn=<MseLossBackward0>)\n",
      "4411 tensor(76127.6562, grad_fn=<MseLossBackward0>)\n",
      "4412 tensor(76127.6484, grad_fn=<MseLossBackward0>)\n",
      "4413 tensor(76127.6406, grad_fn=<MseLossBackward0>)\n",
      "4414 tensor(76127.6328, grad_fn=<MseLossBackward0>)\n",
      "4415 tensor(76127.6250, grad_fn=<MseLossBackward0>)\n",
      "4416 tensor(76127.6250, grad_fn=<MseLossBackward0>)\n",
      "4417 tensor(76127.6172, grad_fn=<MseLossBackward0>)\n",
      "4418 tensor(76127.6094, grad_fn=<MseLossBackward0>)\n",
      "4419 tensor(76127.6094, grad_fn=<MseLossBackward0>)\n",
      "4420 tensor(76127.6016, grad_fn=<MseLossBackward0>)\n",
      "4421 tensor(76127.5938, grad_fn=<MseLossBackward0>)\n",
      "4422 tensor(76127.5859, grad_fn=<MseLossBackward0>)\n",
      "4423 tensor(76127.5859, grad_fn=<MseLossBackward0>)\n",
      "4424 tensor(76127.5781, grad_fn=<MseLossBackward0>)\n",
      "4425 tensor(76127.5625, grad_fn=<MseLossBackward0>)\n",
      "4426 tensor(76127.5625, grad_fn=<MseLossBackward0>)\n",
      "4427 tensor(76127.5625, grad_fn=<MseLossBackward0>)\n",
      "4428 tensor(76127.5625, grad_fn=<MseLossBackward0>)\n",
      "4429 tensor(76127.5547, grad_fn=<MseLossBackward0>)\n",
      "4430 tensor(76127.5469, grad_fn=<MseLossBackward0>)\n",
      "4431 tensor(76127.5469, grad_fn=<MseLossBackward0>)\n",
      "4432 tensor(76127.5391, grad_fn=<MseLossBackward0>)\n",
      "4433 tensor(76127.5312, grad_fn=<MseLossBackward0>)\n",
      "4434 tensor(76127.5312, grad_fn=<MseLossBackward0>)\n",
      "4435 tensor(76127.5234, grad_fn=<MseLossBackward0>)\n",
      "4436 tensor(76127.5156, grad_fn=<MseLossBackward0>)\n",
      "4437 tensor(76127.5078, grad_fn=<MseLossBackward0>)\n",
      "4438 tensor(76127.5000, grad_fn=<MseLossBackward0>)\n",
      "4439 tensor(76127.5000, grad_fn=<MseLossBackward0>)\n",
      "4440 tensor(76127.5000, grad_fn=<MseLossBackward0>)\n",
      "4441 tensor(76127.5000, grad_fn=<MseLossBackward0>)\n",
      "4442 tensor(76127.4766, grad_fn=<MseLossBackward0>)\n",
      "4443 tensor(76127.4766, grad_fn=<MseLossBackward0>)\n",
      "4444 tensor(76127.4766, grad_fn=<MseLossBackward0>)\n",
      "4445 tensor(76127.4688, grad_fn=<MseLossBackward0>)\n",
      "4446 tensor(76127.4609, grad_fn=<MseLossBackward0>)\n",
      "4447 tensor(76127.4531, grad_fn=<MseLossBackward0>)\n",
      "4448 tensor(76127.4531, grad_fn=<MseLossBackward0>)\n",
      "4449 tensor(76127.4531, grad_fn=<MseLossBackward0>)\n",
      "4450 tensor(76127.4453, grad_fn=<MseLossBackward0>)\n",
      "4451 tensor(76127.4453, grad_fn=<MseLossBackward0>)\n",
      "4452 tensor(76127.4375, grad_fn=<MseLossBackward0>)\n",
      "4453 tensor(76127.4375, grad_fn=<MseLossBackward0>)\n",
      "4454 tensor(76127.4375, grad_fn=<MseLossBackward0>)\n",
      "4455 tensor(76127.4297, grad_fn=<MseLossBackward0>)\n",
      "4456 tensor(76127.4219, grad_fn=<MseLossBackward0>)\n",
      "4457 tensor(76127.4141, grad_fn=<MseLossBackward0>)\n",
      "4458 tensor(76127.4141, grad_fn=<MseLossBackward0>)\n",
      "4459 tensor(76127.4141, grad_fn=<MseLossBackward0>)\n",
      "4460 tensor(76127.3984, grad_fn=<MseLossBackward0>)\n",
      "4461 tensor(76127.3906, grad_fn=<MseLossBackward0>)\n",
      "4462 tensor(76127.3906, grad_fn=<MseLossBackward0>)\n",
      "4463 tensor(76127.3906, grad_fn=<MseLossBackward0>)\n",
      "4464 tensor(76127.3828, grad_fn=<MseLossBackward0>)\n",
      "4465 tensor(76127.3750, grad_fn=<MseLossBackward0>)\n",
      "4466 tensor(76127.3672, grad_fn=<MseLossBackward0>)\n",
      "4467 tensor(76127.3672, grad_fn=<MseLossBackward0>)\n",
      "4468 tensor(76127.3672, grad_fn=<MseLossBackward0>)\n",
      "4469 tensor(76127.3594, grad_fn=<MseLossBackward0>)\n",
      "4470 tensor(76127.3594, grad_fn=<MseLossBackward0>)\n",
      "4471 tensor(76127.3516, grad_fn=<MseLossBackward0>)\n",
      "4472 tensor(76127.3438, grad_fn=<MseLossBackward0>)\n",
      "4473 tensor(76127.3438, grad_fn=<MseLossBackward0>)\n",
      "4474 tensor(76127.3438, grad_fn=<MseLossBackward0>)\n",
      "4475 tensor(76127.3438, grad_fn=<MseLossBackward0>)\n",
      "4476 tensor(76127.3281, grad_fn=<MseLossBackward0>)\n",
      "4477 tensor(76127.3281, grad_fn=<MseLossBackward0>)\n",
      "4478 tensor(76127.3281, grad_fn=<MseLossBackward0>)\n",
      "4479 tensor(76127.3281, grad_fn=<MseLossBackward0>)\n",
      "4480 tensor(76127.3203, grad_fn=<MseLossBackward0>)\n",
      "4481 tensor(76127.3125, grad_fn=<MseLossBackward0>)\n",
      "4482 tensor(76127.3125, grad_fn=<MseLossBackward0>)\n",
      "4483 tensor(76127.3125, grad_fn=<MseLossBackward0>)\n",
      "4484 tensor(76127.2969, grad_fn=<MseLossBackward0>)\n",
      "4485 tensor(76127.2969, grad_fn=<MseLossBackward0>)\n",
      "4486 tensor(76127.2969, grad_fn=<MseLossBackward0>)\n",
      "4487 tensor(76127.2812, grad_fn=<MseLossBackward0>)\n",
      "4488 tensor(76127.2812, grad_fn=<MseLossBackward0>)\n",
      "4489 tensor(76127.2812, grad_fn=<MseLossBackward0>)\n",
      "4490 tensor(76127.2734, grad_fn=<MseLossBackward0>)\n",
      "4491 tensor(76127.2734, grad_fn=<MseLossBackward0>)\n",
      "4492 tensor(76127.2656, grad_fn=<MseLossBackward0>)\n",
      "4493 tensor(76127.2656, grad_fn=<MseLossBackward0>)\n",
      "4494 tensor(76127.2656, grad_fn=<MseLossBackward0>)\n",
      "4495 tensor(76127.2500, grad_fn=<MseLossBackward0>)\n",
      "4496 tensor(76127.2500, grad_fn=<MseLossBackward0>)\n",
      "4497 tensor(76127.2500, grad_fn=<MseLossBackward0>)\n",
      "4498 tensor(76127.2500, grad_fn=<MseLossBackward0>)\n",
      "4499 tensor(76127.2344, grad_fn=<MseLossBackward0>)\n",
      "4500 tensor(76127.2344, grad_fn=<MseLossBackward0>)\n",
      "4501 tensor(76127.2344, grad_fn=<MseLossBackward0>)\n",
      "4502 tensor(76127.2344, grad_fn=<MseLossBackward0>)\n",
      "4503 tensor(76127.2266, grad_fn=<MseLossBackward0>)\n",
      "4504 tensor(76127.2266, grad_fn=<MseLossBackward0>)\n",
      "4505 tensor(76127.2266, grad_fn=<MseLossBackward0>)\n",
      "4506 tensor(76127.2109, grad_fn=<MseLossBackward0>)\n",
      "4507 tensor(76127.2109, grad_fn=<MseLossBackward0>)\n",
      "4508 tensor(76127.2109, grad_fn=<MseLossBackward0>)\n",
      "4509 tensor(76127.2031, grad_fn=<MseLossBackward0>)\n",
      "4510 tensor(76127.2031, grad_fn=<MseLossBackward0>)\n",
      "4511 tensor(76127.2031, grad_fn=<MseLossBackward0>)\n",
      "4512 tensor(76127.1953, grad_fn=<MseLossBackward0>)\n",
      "4513 tensor(76127.1953, grad_fn=<MseLossBackward0>)\n",
      "4514 tensor(76127.1875, grad_fn=<MseLossBackward0>)\n",
      "4515 tensor(76127.1875, grad_fn=<MseLossBackward0>)\n",
      "4516 tensor(76127.1797, grad_fn=<MseLossBackward0>)\n",
      "4517 tensor(76127.1797, grad_fn=<MseLossBackward0>)\n",
      "4518 tensor(76127.1797, grad_fn=<MseLossBackward0>)\n",
      "4519 tensor(76127.1641, grad_fn=<MseLossBackward0>)\n",
      "4520 tensor(76127.1641, grad_fn=<MseLossBackward0>)\n",
      "4521 tensor(76127.1641, grad_fn=<MseLossBackward0>)\n",
      "4522 tensor(76127.1562, grad_fn=<MseLossBackward0>)\n",
      "4523 tensor(76127.1562, grad_fn=<MseLossBackward0>)\n",
      "4524 tensor(76127.1484, grad_fn=<MseLossBackward0>)\n",
      "4525 tensor(76127.1484, grad_fn=<MseLossBackward0>)\n",
      "4526 tensor(76127.1484, grad_fn=<MseLossBackward0>)\n",
      "4527 tensor(76127.1484, grad_fn=<MseLossBackward0>)\n",
      "4528 tensor(76127.1406, grad_fn=<MseLossBackward0>)\n",
      "4529 tensor(76127.1406, grad_fn=<MseLossBackward0>)\n",
      "4530 tensor(76127.1328, grad_fn=<MseLossBackward0>)\n",
      "4531 tensor(76127.1328, grad_fn=<MseLossBackward0>)\n",
      "4532 tensor(76127.1328, grad_fn=<MseLossBackward0>)\n",
      "4533 tensor(76127.1250, grad_fn=<MseLossBackward0>)\n",
      "4534 tensor(76127.1250, grad_fn=<MseLossBackward0>)\n",
      "4535 tensor(76127.1250, grad_fn=<MseLossBackward0>)\n",
      "4536 tensor(76127.1172, grad_fn=<MseLossBackward0>)\n",
      "4537 tensor(76127.1172, grad_fn=<MseLossBackward0>)\n",
      "4538 tensor(76127.1094, grad_fn=<MseLossBackward0>)\n",
      "4539 tensor(76127.1094, grad_fn=<MseLossBackward0>)\n",
      "4540 tensor(76127.1094, grad_fn=<MseLossBackward0>)\n",
      "4541 tensor(76127.1094, grad_fn=<MseLossBackward0>)\n",
      "4542 tensor(76127.1094, grad_fn=<MseLossBackward0>)\n",
      "4543 tensor(76127.0938, grad_fn=<MseLossBackward0>)\n",
      "4544 tensor(76127.0938, grad_fn=<MseLossBackward0>)\n",
      "4545 tensor(76127.0859, grad_fn=<MseLossBackward0>)\n",
      "4546 tensor(76127.0859, grad_fn=<MseLossBackward0>)\n",
      "4547 tensor(76127.0859, grad_fn=<MseLossBackward0>)\n",
      "4548 tensor(76127.0859, grad_fn=<MseLossBackward0>)\n",
      "4549 tensor(76127.0781, grad_fn=<MseLossBackward0>)\n",
      "4550 tensor(76127.0781, grad_fn=<MseLossBackward0>)\n",
      "4551 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4552 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4553 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4554 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4555 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4556 tensor(76127.0625, grad_fn=<MseLossBackward0>)\n",
      "4557 tensor(76127.0547, grad_fn=<MseLossBackward0>)\n",
      "4558 tensor(76127.0547, grad_fn=<MseLossBackward0>)\n",
      "4559 tensor(76127.0469, grad_fn=<MseLossBackward0>)\n",
      "4560 tensor(76127.0469, grad_fn=<MseLossBackward0>)\n",
      "4561 tensor(76127.0469, grad_fn=<MseLossBackward0>)\n",
      "4562 tensor(76127.0469, grad_fn=<MseLossBackward0>)\n",
      "4563 tensor(76127.0391, grad_fn=<MseLossBackward0>)\n",
      "4564 tensor(76127.0391, grad_fn=<MseLossBackward0>)\n",
      "4565 tensor(76127.0312, grad_fn=<MseLossBackward0>)\n",
      "4566 tensor(76127.0312, grad_fn=<MseLossBackward0>)\n",
      "4567 tensor(76127.0312, grad_fn=<MseLossBackward0>)\n",
      "4568 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4569 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4570 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4571 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4572 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4573 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4574 tensor(76127.0156, grad_fn=<MseLossBackward0>)\n",
      "4575 tensor(76127.0078, grad_fn=<MseLossBackward0>)\n",
      "4576 tensor(76127.0078, grad_fn=<MseLossBackward0>)\n",
      "4577 tensor(76127.0078, grad_fn=<MseLossBackward0>)\n",
      "4578 tensor(76127.0078, grad_fn=<MseLossBackward0>)\n",
      "4579 tensor(76127., grad_fn=<MseLossBackward0>)\n",
      "4580 tensor(76127., grad_fn=<MseLossBackward0>)\n",
      "4581 tensor(76127., grad_fn=<MseLossBackward0>)\n",
      "4582 tensor(76127., grad_fn=<MseLossBackward0>)\n",
      "4583 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4584 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4585 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4586 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4587 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4588 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4589 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4590 tensor(76126.9766, grad_fn=<MseLossBackward0>)\n",
      "4591 tensor(76126.9688, grad_fn=<MseLossBackward0>)\n",
      "4592 tensor(76126.9688, grad_fn=<MseLossBackward0>)\n",
      "4593 tensor(76126.9688, grad_fn=<MseLossBackward0>)\n",
      "4594 tensor(76126.9688, grad_fn=<MseLossBackward0>)\n",
      "4595 tensor(76126.9609, grad_fn=<MseLossBackward0>)\n",
      "4596 tensor(76126.9609, grad_fn=<MseLossBackward0>)\n",
      "4597 tensor(76126.9609, grad_fn=<MseLossBackward0>)\n",
      "4598 tensor(76126.9531, grad_fn=<MseLossBackward0>)\n",
      "4599 tensor(76126.9531, grad_fn=<MseLossBackward0>)\n",
      "4600 tensor(76126.9453, grad_fn=<MseLossBackward0>)\n",
      "4601 tensor(76126.9453, grad_fn=<MseLossBackward0>)\n",
      "4602 tensor(76126.9453, grad_fn=<MseLossBackward0>)\n",
      "4603 tensor(76126.9453, grad_fn=<MseLossBackward0>)\n",
      "4604 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4605 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4606 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4607 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4608 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4609 tensor(76126.9297, grad_fn=<MseLossBackward0>)\n",
      "4610 tensor(76126.9219, grad_fn=<MseLossBackward0>)\n",
      "4611 tensor(76126.9219, grad_fn=<MseLossBackward0>)\n",
      "4612 tensor(76126.9219, grad_fn=<MseLossBackward0>)\n",
      "4613 tensor(76126.9219, grad_fn=<MseLossBackward0>)\n",
      "4614 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4615 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4616 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4617 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4618 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4619 tensor(76126.9141, grad_fn=<MseLossBackward0>)\n",
      "4620 tensor(76126.9062, grad_fn=<MseLossBackward0>)\n",
      "4621 tensor(76126.9062, grad_fn=<MseLossBackward0>)\n",
      "4622 tensor(76126.9062, grad_fn=<MseLossBackward0>)\n",
      "4623 tensor(76126.9062, grad_fn=<MseLossBackward0>)\n",
      "4624 tensor(76126.8984, grad_fn=<MseLossBackward0>)\n",
      "4625 tensor(76126.8984, grad_fn=<MseLossBackward0>)\n",
      "4626 tensor(76126.8984, grad_fn=<MseLossBackward0>)\n",
      "4627 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4628 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4629 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4630 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4631 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4632 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4633 tensor(76126.8906, grad_fn=<MseLossBackward0>)\n",
      "4634 tensor(76126.8828, grad_fn=<MseLossBackward0>)\n",
      "4635 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4636 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4637 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4638 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4639 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4640 tensor(76126.8750, grad_fn=<MseLossBackward0>)\n",
      "4641 tensor(76126.8672, grad_fn=<MseLossBackward0>)\n",
      "4642 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4643 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4644 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4645 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4646 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4647 tensor(76126.8594, grad_fn=<MseLossBackward0>)\n",
      "4648 tensor(76126.8516, grad_fn=<MseLossBackward0>)\n",
      "4649 tensor(76126.8516, grad_fn=<MseLossBackward0>)\n",
      "4650 tensor(76126.8516, grad_fn=<MseLossBackward0>)\n",
      "4651 tensor(76126.8438, grad_fn=<MseLossBackward0>)\n",
      "4652 tensor(76126.8438, grad_fn=<MseLossBackward0>)\n",
      "4653 tensor(76126.8438, grad_fn=<MseLossBackward0>)\n",
      "4654 tensor(76126.8438, grad_fn=<MseLossBackward0>)\n",
      "4655 tensor(76126.8438, grad_fn=<MseLossBackward0>)\n",
      "4656 tensor(76126.8359, grad_fn=<MseLossBackward0>)\n",
      "4657 tensor(76126.8359, grad_fn=<MseLossBackward0>)\n",
      "4658 tensor(76126.8359, grad_fn=<MseLossBackward0>)\n",
      "4659 tensor(76126.8359, grad_fn=<MseLossBackward0>)\n",
      "4660 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4661 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4662 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4663 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4664 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4665 tensor(76126.8281, grad_fn=<MseLossBackward0>)\n",
      "4666 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4667 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4668 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4669 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4670 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4671 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4672 tensor(76126.8203, grad_fn=<MseLossBackward0>)\n",
      "4673 tensor(76126.8125, grad_fn=<MseLossBackward0>)\n",
      "4674 tensor(76126.8125, grad_fn=<MseLossBackward0>)\n",
      "4675 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4676 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4677 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4678 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4679 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4680 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4681 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4682 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4683 tensor(76126.8047, grad_fn=<MseLossBackward0>)\n",
      "4684 tensor(76126.7969, grad_fn=<MseLossBackward0>)\n",
      "4685 tensor(76126.7969, grad_fn=<MseLossBackward0>)\n",
      "4686 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4687 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4688 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4689 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4690 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4691 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4692 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4693 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4694 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4695 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4696 tensor(76126.7891, grad_fn=<MseLossBackward0>)\n",
      "4697 tensor(76126.7812, grad_fn=<MseLossBackward0>)\n",
      "4698 tensor(76126.7812, grad_fn=<MseLossBackward0>)\n",
      "4699 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4700 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4701 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4702 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4703 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4704 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4705 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4706 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4707 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4708 tensor(76126.7734, grad_fn=<MseLossBackward0>)\n",
      "4709 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4710 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4711 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4712 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4713 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4714 tensor(76126.7656, grad_fn=<MseLossBackward0>)\n",
      "4715 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4716 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4717 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4718 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4719 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4720 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4721 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4722 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4723 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4724 tensor(76126.7578, grad_fn=<MseLossBackward0>)\n",
      "4725 tensor(76126.7422, grad_fn=<MseLossBackward0>)\n",
      "4726 tensor(76126.7422, grad_fn=<MseLossBackward0>)\n",
      "4727 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4728 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4729 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4730 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4731 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4732 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4733 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4734 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4735 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4736 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4737 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4738 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4739 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4740 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4741 tensor(76126.7344, grad_fn=<MseLossBackward0>)\n",
      "4742 tensor(76126.7266, grad_fn=<MseLossBackward0>)\n",
      "4743 tensor(76126.7266, grad_fn=<MseLossBackward0>)\n",
      "4744 tensor(76126.7266, grad_fn=<MseLossBackward0>)\n",
      "4745 tensor(76126.7266, grad_fn=<MseLossBackward0>)\n",
      "4746 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4747 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4748 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4749 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4750 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4751 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4752 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4753 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4754 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4755 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4756 tensor(76126.7188, grad_fn=<MseLossBackward0>)\n",
      "4757 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4758 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4759 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4760 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4761 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4762 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4763 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4764 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4765 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4766 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4767 tensor(76126.7109, grad_fn=<MseLossBackward0>)\n",
      "4768 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4769 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4770 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4771 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4772 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4773 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4774 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4775 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4776 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4777 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4778 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4779 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4780 tensor(76126.6953, grad_fn=<MseLossBackward0>)\n",
      "4781 tensor(76126.6875, grad_fn=<MseLossBackward0>)\n",
      "4782 tensor(76126.6875, grad_fn=<MseLossBackward0>)\n",
      "4783 tensor(76126.6875, grad_fn=<MseLossBackward0>)\n",
      "4784 tensor(76126.6875, grad_fn=<MseLossBackward0>)\n",
      "4785 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4786 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4787 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4788 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4789 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4790 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4791 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4792 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4793 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4794 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4795 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4796 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4797 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4798 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4799 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4800 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4801 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4802 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4803 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4804 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4805 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4806 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4807 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4808 tensor(76126.6797, grad_fn=<MseLossBackward0>)\n",
      "4809 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4810 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4811 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4812 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4813 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4814 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4815 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4816 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4817 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4818 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4819 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4820 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4821 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4822 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4823 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4824 tensor(76126.6719, grad_fn=<MseLossBackward0>)\n",
      "4825 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4826 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4827 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4828 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4829 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4830 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4831 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4832 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4833 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4834 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4835 tensor(76126.6562, grad_fn=<MseLossBackward0>)\n",
      "4836 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4837 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4838 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4839 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4840 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4841 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4842 tensor(76126.6484, grad_fn=<MseLossBackward0>)\n",
      "4843 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4844 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4845 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4846 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4847 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4848 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4849 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4850 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4851 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4852 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4853 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4854 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4855 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4856 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4857 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4858 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4859 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4860 tensor(76126.6406, grad_fn=<MseLossBackward0>)\n",
      "4861 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4862 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4863 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4864 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4865 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4866 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4867 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4868 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4869 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4870 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4871 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4872 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4873 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4874 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4875 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4876 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4877 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4878 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4879 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4880 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4881 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4882 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4883 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4884 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4885 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4886 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4887 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4888 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4889 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4890 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4891 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4892 tensor(76126.6328, grad_fn=<MseLossBackward0>)\n",
      "4893 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4894 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4895 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4896 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4897 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4898 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4899 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4900 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4901 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4902 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4903 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4904 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4905 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4906 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4907 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4908 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4909 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4910 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4911 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4912 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4913 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4914 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4915 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4916 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4917 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4918 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4919 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4920 tensor(76126.6250, grad_fn=<MseLossBackward0>)\n",
      "4921 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4922 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4923 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4924 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4925 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4926 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4927 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4928 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4929 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4930 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4931 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4932 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4933 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4934 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4935 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4936 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4937 tensor(76126.6172, grad_fn=<MseLossBackward0>)\n",
      "4938 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4939 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4940 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4941 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4942 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4943 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4944 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4945 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4946 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4947 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4948 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4949 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4950 tensor(76126.6094, grad_fn=<MseLossBackward0>)\n",
      "4951 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4952 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4953 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4954 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4955 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4956 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4957 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4958 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4959 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4960 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4961 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4962 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4963 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4964 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4965 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4966 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4967 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4968 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4969 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4970 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4971 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4972 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4973 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4974 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4975 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4976 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4977 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4978 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4979 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4980 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4981 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4982 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4983 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4984 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4985 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4986 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4987 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4988 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4989 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4990 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4991 tensor(76126.6016, grad_fn=<MseLossBackward0>)\n",
      "4992 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4993 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4994 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4995 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4996 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4997 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4998 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "4999 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5000 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5001 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5002 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5003 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5004 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5005 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5006 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5007 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5008 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5009 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5010 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5011 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5012 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5013 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5014 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5015 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5016 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5017 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5018 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5019 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5020 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5021 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5022 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5023 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5024 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5025 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5026 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5027 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5028 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5029 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5030 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5031 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5032 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5033 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5034 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5035 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5036 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5037 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5038 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5039 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5040 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5041 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5042 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5043 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5044 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5045 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5046 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5047 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5048 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5049 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5050 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5051 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5052 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5053 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5054 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5055 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5056 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5057 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5058 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5059 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5060 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5061 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5062 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5063 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5064 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5065 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5066 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5067 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5068 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5069 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5070 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5071 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5072 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5073 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5074 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5075 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5076 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5077 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5078 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5079 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5080 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5081 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5082 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5083 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5084 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5085 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5086 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5087 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5088 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5089 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5090 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5091 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5092 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5093 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5094 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5095 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5096 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5097 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5098 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5099 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5100 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5101 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5102 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5103 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5104 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5105 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5106 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5107 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5108 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5109 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5110 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5111 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5112 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5113 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5114 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5115 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5116 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5117 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5118 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5119 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5120 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5121 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5122 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5123 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5124 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5125 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5126 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5127 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5128 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5129 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5130 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5131 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5132 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5133 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5134 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5135 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5136 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5137 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5138 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5139 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5140 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5141 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5142 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5143 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5144 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5145 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5146 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5147 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5148 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5149 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5150 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5151 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5152 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5153 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5154 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5155 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5156 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5157 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5158 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5159 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5160 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5161 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5162 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5163 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5164 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5165 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5166 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5167 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5168 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5169 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5170 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5171 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5172 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5173 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5174 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5175 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5176 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5177 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5178 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5179 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5180 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5181 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5182 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5183 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5184 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5185 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5186 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5187 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5188 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5189 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5190 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5191 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5192 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5193 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5194 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5195 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5196 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5197 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5198 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5199 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5200 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5201 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5202 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5203 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5204 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5205 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5206 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5207 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5208 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5209 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5210 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5211 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5212 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5213 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5214 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5215 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5216 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5217 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5218 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5219 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5220 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5221 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5222 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5223 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5224 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5225 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5226 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5227 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5228 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5229 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5230 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5231 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5232 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5233 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5234 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5235 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5236 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5237 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5238 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5239 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5240 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5241 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5242 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5243 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5244 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5245 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5246 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5247 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5248 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5249 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5250 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5251 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5252 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5253 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5254 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5255 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5256 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5257 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5258 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5259 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5260 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5261 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5262 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5263 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5264 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5265 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5266 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5267 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5268 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5269 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5270 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5271 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5272 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5273 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5274 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5275 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5276 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5277 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5278 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5279 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5280 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5281 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5282 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5283 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5284 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5285 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5286 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5287 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5288 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5289 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5290 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5291 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5292 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5293 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5294 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5295 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5296 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5297 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5298 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5299 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5300 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5301 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5302 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5303 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5304 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5305 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5306 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5307 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5308 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5309 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5310 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5311 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5312 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5313 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5314 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5315 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5316 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5317 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5318 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5319 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5320 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5321 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5322 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5323 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5324 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5325 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5326 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5327 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5328 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5329 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5330 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5331 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5332 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5333 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5334 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5335 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5336 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5337 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5338 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5339 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5340 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5341 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5342 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5343 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5344 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5345 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5346 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5347 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5348 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5349 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5350 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5351 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5352 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5353 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5354 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5355 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5356 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5357 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5358 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5359 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5360 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5361 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5362 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5363 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5364 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5365 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5366 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5367 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5368 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5369 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5370 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5371 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5372 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5373 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5374 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5375 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5376 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5377 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5378 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5379 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5380 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5381 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5382 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5383 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5384 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5385 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5386 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5387 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5388 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5389 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5390 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5391 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5392 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5393 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5394 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5395 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5396 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5397 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5398 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5399 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5400 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5401 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5402 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5403 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5404 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5405 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5406 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5407 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5408 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5409 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5410 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5411 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5412 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5413 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5414 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5415 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5416 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5417 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5418 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5419 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5420 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5421 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5422 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5423 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5424 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5425 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5426 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5427 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5428 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5429 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5430 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5431 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5432 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5433 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5434 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5435 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5436 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5437 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5438 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5439 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5440 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5441 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5442 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5443 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5444 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5445 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5446 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5447 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5448 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5449 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5450 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5451 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5452 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5453 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5454 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5455 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5456 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5457 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5458 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5459 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5460 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5461 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5462 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5463 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5464 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5465 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5466 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5467 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5468 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5469 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5470 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5471 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5472 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5473 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5474 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5475 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5476 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5477 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5478 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5479 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5480 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5481 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5482 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5483 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5484 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5485 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5486 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5487 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5488 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5489 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5490 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5491 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5492 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5493 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5494 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5495 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5496 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5497 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5498 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5499 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5500 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5501 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5502 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5503 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5504 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5505 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5506 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5507 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5508 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5509 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5510 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5511 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5512 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5513 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5514 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5515 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5516 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5517 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5518 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5519 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5520 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5521 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5522 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5523 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5524 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5525 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5526 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5527 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5528 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5529 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5530 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5531 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5532 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5533 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5534 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5535 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5536 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5537 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5538 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5539 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5540 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5541 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5542 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5543 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5544 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5545 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5546 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5547 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5548 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5549 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5550 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5551 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5552 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5553 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5554 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5555 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5556 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5557 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5558 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5559 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5560 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5561 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5562 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5563 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5564 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5565 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5566 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5567 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5568 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5569 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5570 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5571 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5572 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5573 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n",
      "5574 tensor(76126.5938, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[0;32m      9\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 10\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     11\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(out, data\u001b[39m.\u001b[39my)\n\u001b[0;32m     12\u001b[0m     loss_l\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[106], line 19\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index, torch\u001b[39m.\u001b[39;49mminimum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_weight\u001b[39m.\u001b[39;49mabs(),torch\u001b[39m.\u001b[39;49mones(data\u001b[39m.\u001b[39;49mnum_edges)))\n\u001b[0;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:232\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[0;32m    231\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[0;32m    233\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    235\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    236\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:459\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m decomp_args:\n\u001b[0;32m    457\u001b[0m         kwargs[arg] \u001b[39m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[1;32m--> 459\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_collect(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_user_args, edge_index, size,\n\u001b[0;32m    460\u001b[0m                           kwargs)\n\u001b[0;32m    462\u001b[0m msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m    463\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:336\u001b[0m, in \u001b[0;36mMessagePassing._collect\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    335\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_size(size, dim, data)\n\u001b[1;32m--> 336\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lift(data, edge_index, dim)\n\u001b[0;32m    338\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m is_torch_sparse_tensor(edge_index):\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:272\u001b[0m, in \u001b[0;36mMessagePassing._lift\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    271\u001b[0m     index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 272\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mindex_select(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim, index)\n\u001b[0;32m    273\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mIndexError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    274\u001b[0m     \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mmin() \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m index\u001b[39m.\u001b[39mmax() \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m src\u001b[39m.\u001b[39msize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dim):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "data = ssp_data.data.to(device)\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.mse_loss(out, data.y)\n",
    "    loss_l.append(loss.item())\n",
    "    print(epoch, loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2c4f9e1fcd0>]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_l[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00,\n",
       "        1.0281e+00, 2.3427e-01, 2.3410e-01, 2.3374e-01, 2.3368e-01, 2.3573e-01,\n",
       "        2.3519e-01, 2.3605e-01, 2.3806e-01, 2.3909e-01, 2.3808e-01, 2.3746e-01,\n",
       "        2.4096e-01, 2.3891e-01, 2.4134e-01, 9.2244e-01, 9.2243e-01, 9.2242e-01,\n",
       "        9.2242e-01, 9.2242e-01, 9.2241e-01, 9.2243e-01, 9.2188e-01, 9.2189e-01,\n",
       "        9.2188e-01, 9.2188e-01, 9.2185e-01, 9.2185e-01, 9.2186e-01, 5.6408e-04,\n",
       "        5.8485e-04, 5.6915e-04, 5.9098e-04, 5.5358e-04, 5.0742e-04, 5.4165e-04,\n",
       "        1.1606e-05, 1.2645e-05, 1.1900e-05, 1.3083e-05, 1.1248e-05, 8.5484e-06,\n",
       "        1.0548e-05, 1.9385e-02, 1.9439e-02, 1.9907e-02, 1.9607e-02, 1.9089e-02,\n",
       "        1.9989e-02, 1.9699e-02], requires_grad=True)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0621346235275269,\n",
       " 1.061711072921753,\n",
       " 1.0619031190872192,\n",
       " 1.0618290901184082,\n",
       " 1.0618948936462402,\n",
       " 1.0618715286254883,\n",
       " 1.0617121458053589,\n",
       " 1.0494590997695923,\n",
       " 1.049369215965271,\n",
       " 1.0494438409805298,\n",
       " 1.0494590997695923,\n",
       " 1.049442172050476,\n",
       " 1.0494471788406372,\n",
       " 1.0493615865707397,\n",
       " 0.9245324730873108,\n",
       " 0.9244717955589294,\n",
       " 0.9245195984840393,\n",
       " 0.9244185090065002,\n",
       " 0.9245076179504395,\n",
       " 0.9244663715362549,\n",
       " 0.9243170619010925,\n",
       " 0.6722093820571899,\n",
       " 0.6717312335968018,\n",
       " 0.6721544861793518,\n",
       " 0.6738019585609436,\n",
       " 0.6734118461608887,\n",
       " 0.6734402775764465,\n",
       " 0.6730117797851562,\n",
       " 0.10454306751489639,\n",
       " 0.10630414634943008,\n",
       " 0.11099547147750854,\n",
       " 0.10787973552942276,\n",
       " 0.10195371508598328,\n",
       " 0.10563800483942032,\n",
       " 0.11204907298088074,\n",
       " 0.6113467812538147,\n",
       " 0.6118078827857971,\n",
       " 0.6131083369255066,\n",
       " 0.6117194294929504,\n",
       " 0.6119213104248047,\n",
       " 0.6113260984420776,\n",
       " 0.6138107776641846,\n",
       " 0.16995438933372498,\n",
       " 0.1700158566236496,\n",
       " 0.17485535144805908,\n",
       " 0.17009152472019196,\n",
       " 0.17025677859783173,\n",
       " 0.16579557955265045,\n",
       " 0.17730098962783813,\n",
       " 0.9164835214614868,\n",
       " 0.9164519906044006,\n",
       " 0.91632080078125,\n",
       " 0.916401207447052,\n",
       " 0.9163721203804016,\n",
       " 0.9164198040962219,\n",
       " 0.9163880944252014]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.edge_weight.tolist()\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 84940.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\121057100.py:3: UserWarning: Using a target size (torch.Size([70200])) that is different to the input size (torch.Size([8, 70200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse = F.mse_loss(out, data.y)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(data)\n",
    "mse = F.mse_loss(out, data.y)\n",
    "print(f'MSE: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_AxesStack' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[39m=\u001b[39m torch_geometric\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mData(x\u001b[39m=\u001b[39mx, edge_index\u001b[39m=\u001b[39medge_index)\n\u001b[0;32m      7\u001b[0m g \u001b[39m=\u001b[39m torch_geometric\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_networkx(data, to_undirected\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m nx\u001b[39m.\u001b[39;49mdraw(g)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:113\u001b[0m, in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    111\u001b[0m cf\u001b[39m.\u001b[39mset_facecolor(\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m cf\u001b[39m.\u001b[39;49m_axstack() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m         ax \u001b[39m=\u001b[39m cf\u001b[39m.\u001b[39madd_axes((\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '_AxesStack' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "edge_index = ssp_data.data.edge_index\n",
    "x = ssp_data.data.x\n",
    "\n",
    "data = torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "nx.draw(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "         3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "         6, 7, 7, 7, 7, 7, 7, 7],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 0, 2, 3, 4, 5, 6, 7, 0, 1, 3, 4, 5, 6, 7, 0, 1, 2,\n",
       "         4, 5, 6, 7, 0, 1, 2, 3, 5, 6, 7, 0, 1, 2, 3, 4, 6, 7, 0, 1, 2, 3, 4, 5,\n",
       "         7, 0, 1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_data.data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
