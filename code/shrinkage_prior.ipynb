{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generator import ssp_data\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "# from torch.utils import to_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_001.nc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\shrinkage_prior.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ssp_obj \u001b[39m=\u001b[39m ssp_data()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m ssp_obj\u001b[39m.\u001b[39mto_pickle(\u001b[39m'\u001b[39m\u001b[39mdata_pickle\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\data_generator.py:17\u001b[0m, in \u001b[0;36mssp_data.__init__\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_file \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtas_scenario_245\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtas_mon_mod_ssp245_192_000.nc\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     16\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_file_list \u001b[39m=\u001b[39m [item \u001b[39mfor\u001b[39;00m item \u001b[39min\u001b[39;00m glob(\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtas_scenario_245\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mtas_mon_mod_ssp245_192_*.nc\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mif\u001b[39;00m item \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_file]][\u001b[39m0\u001b[39m : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn]\n\u001b[1;32m---> 17\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_df()\n\u001b[0;32m     18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest_train_split()\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\data_generator.py:37\u001b[0m, in \u001b[0;36mssp_data.create_df\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing\u001b[39m\u001b[39m'\u001b[39m, filename)\n\u001b[0;32m     36\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mempty:\n\u001b[1;32m---> 37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_vector(filename)\u001b[39m.\u001b[39mreset_index(drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(w\u001b[39m:=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_vector(filename)[\u001b[39m'\u001b[39m\u001b[39mtas\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\data_generator.py:58\u001b[0m, in \u001b[0;36mssp_data.create_vector\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# df = df.query('lat == -43.125 & lat == 288.750')\u001b[39;00m\n\u001b[0;32m     57\u001b[0m df \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mquery(\u001b[39m'\u001b[39m\u001b[39mlat >= -44 & lat <= -12 & lon >= 288 & lon <= 336\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m ret \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[(df[\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdt\u001b[39m.\u001b[39myear \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1960\u001b[39m) \u001b[39m&\u001b[39m (df[\u001b[39m'\u001b[39;49m\u001b[39mtime\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mdt\u001b[39m.\u001b[39;49myear \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1980\u001b[39m), [\u001b[39m'\u001b[39m\u001b[39mtime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlat\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlon\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtas\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\pandas\\core\\accessor.py:80\u001b[0m, in \u001b[0;36mPandasDelegate._add_delegate_accessors.<locals>._create_delegator_property.<locals>._getter\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getter\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 80\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_delegate_property_get(name)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py:87\u001b[0m, in \u001b[0;36mProperties._delegate_property_get\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mimport\u001b[39;00m Series\n\u001b[0;32m     85\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values()\n\u001b[1;32m---> 87\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(values, name)\n\u001b[0;32m     89\u001b[0m \u001b[39m# maybe need to upcast (ints)\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, np\u001b[39m.\u001b[39mndarray):\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\pandas\\core\\indexes\\extension.py:71\u001b[0m, in \u001b[0;36m_inherit_from_data.<locals>.fget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfget\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> 71\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data, name)\n\u001b[0;32m     72\u001b[0m     \u001b[39mif\u001b[39;00m wrap:\n\u001b[0;32m     73\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data)):\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:141\u001b[0m, in \u001b[0;36m_field_accessor.<locals>.f\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    138\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_mask_results(result, fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 141\u001b[0m     result \u001b[39m=\u001b[39m fields\u001b[39m.\u001b[39;49mget_date_field(values, field, reso\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reso)\n\u001b[0;32m    142\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_mask_results(\n\u001b[0;32m    143\u001b[0m         result, fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, convert\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    146\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ssp_obj = ssp_data()\n",
    "ssp_obj.to_pickle('data_pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_pickle', 'rb')\n",
    "ssp_obj = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[39, 163800], edge_index=[2, 1482], y=[39, 163800])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_obj.train_data = ssp_obj.test_data\n",
    "ssp_obj.train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp_obj.train_data.y = ssp_obj.train_data.y.repeat(39, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([39, 163800])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_obj.train_data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_2</th>\n",
       "      <th>tas_3</th>\n",
       "      <th>tas_4</th>\n",
       "      <th>tas_5</th>\n",
       "      <th>tas_6</th>\n",
       "      <th>tas_7</th>\n",
       "      <th>...</th>\n",
       "      <th>tas_30</th>\n",
       "      <th>tas_31</th>\n",
       "      <th>tas_32</th>\n",
       "      <th>tas_33</th>\n",
       "      <th>tas_34</th>\n",
       "      <th>tas_35</th>\n",
       "      <th>tas_36</th>\n",
       "      <th>tas_37</th>\n",
       "      <th>tas_38</th>\n",
       "      <th>tas_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1960-01-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>284.528320</td>\n",
       "      <td>282.464142</td>\n",
       "      <td>284.291168</td>\n",
       "      <td>283.132751</td>\n",
       "      <td>284.651947</td>\n",
       "      <td>284.831085</td>\n",
       "      <td>284.705200</td>\n",
       "      <td>...</td>\n",
       "      <td>281.811829</td>\n",
       "      <td>281.371918</td>\n",
       "      <td>283.208984</td>\n",
       "      <td>284.216949</td>\n",
       "      <td>286.015350</td>\n",
       "      <td>283.668304</td>\n",
       "      <td>284.809875</td>\n",
       "      <td>283.668304</td>\n",
       "      <td>284.835632</td>\n",
       "      <td>284.809875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1960-02-15 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>287.539368</td>\n",
       "      <td>280.244568</td>\n",
       "      <td>284.054016</td>\n",
       "      <td>285.201050</td>\n",
       "      <td>285.553284</td>\n",
       "      <td>284.454803</td>\n",
       "      <td>284.374817</td>\n",
       "      <td>...</td>\n",
       "      <td>282.837433</td>\n",
       "      <td>282.395935</td>\n",
       "      <td>282.835175</td>\n",
       "      <td>287.725464</td>\n",
       "      <td>286.617950</td>\n",
       "      <td>283.943146</td>\n",
       "      <td>284.162109</td>\n",
       "      <td>283.943146</td>\n",
       "      <td>285.790070</td>\n",
       "      <td>284.162109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1960-03-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>284.881317</td>\n",
       "      <td>280.398346</td>\n",
       "      <td>284.130188</td>\n",
       "      <td>283.143311</td>\n",
       "      <td>282.487152</td>\n",
       "      <td>282.092773</td>\n",
       "      <td>282.171570</td>\n",
       "      <td>...</td>\n",
       "      <td>280.508759</td>\n",
       "      <td>280.181793</td>\n",
       "      <td>281.891022</td>\n",
       "      <td>284.751038</td>\n",
       "      <td>284.893921</td>\n",
       "      <td>283.891754</td>\n",
       "      <td>282.453857</td>\n",
       "      <td>283.891754</td>\n",
       "      <td>287.167877</td>\n",
       "      <td>282.453857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1960-04-16 00:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>281.906555</td>\n",
       "      <td>276.135284</td>\n",
       "      <td>278.999359</td>\n",
       "      <td>278.682312</td>\n",
       "      <td>277.991150</td>\n",
       "      <td>278.428497</td>\n",
       "      <td>278.910461</td>\n",
       "      <td>...</td>\n",
       "      <td>276.122742</td>\n",
       "      <td>278.386505</td>\n",
       "      <td>277.180573</td>\n",
       "      <td>279.325195</td>\n",
       "      <td>280.907806</td>\n",
       "      <td>279.808960</td>\n",
       "      <td>278.433167</td>\n",
       "      <td>279.808960</td>\n",
       "      <td>288.571198</td>\n",
       "      <td>278.433167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1960-05-16 12:00:00</td>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>279.067780</td>\n",
       "      <td>274.095276</td>\n",
       "      <td>276.211304</td>\n",
       "      <td>275.564301</td>\n",
       "      <td>276.290802</td>\n",
       "      <td>276.003906</td>\n",
       "      <td>275.955292</td>\n",
       "      <td>...</td>\n",
       "      <td>272.721802</td>\n",
       "      <td>275.065002</td>\n",
       "      <td>274.005920</td>\n",
       "      <td>276.936218</td>\n",
       "      <td>279.518860</td>\n",
       "      <td>277.367950</td>\n",
       "      <td>275.130280</td>\n",
       "      <td>277.367950</td>\n",
       "      <td>289.716766</td>\n",
       "      <td>275.130280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163795</th>\n",
       "      <td>1980-08-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>295.138611</td>\n",
       "      <td>295.646790</td>\n",
       "      <td>297.660187</td>\n",
       "      <td>296.686462</td>\n",
       "      <td>295.769592</td>\n",
       "      <td>295.989685</td>\n",
       "      <td>296.137421</td>\n",
       "      <td>...</td>\n",
       "      <td>297.207520</td>\n",
       "      <td>296.141510</td>\n",
       "      <td>296.076263</td>\n",
       "      <td>296.818420</td>\n",
       "      <td>295.533142</td>\n",
       "      <td>294.159027</td>\n",
       "      <td>296.367096</td>\n",
       "      <td>294.159027</td>\n",
       "      <td>296.985901</td>\n",
       "      <td>296.367096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163796</th>\n",
       "      <td>1980-09-16 00:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>294.829285</td>\n",
       "      <td>295.332123</td>\n",
       "      <td>297.565948</td>\n",
       "      <td>296.689148</td>\n",
       "      <td>295.513763</td>\n",
       "      <td>295.840149</td>\n",
       "      <td>296.017670</td>\n",
       "      <td>...</td>\n",
       "      <td>296.929565</td>\n",
       "      <td>295.970123</td>\n",
       "      <td>296.137695</td>\n",
       "      <td>296.979309</td>\n",
       "      <td>295.515900</td>\n",
       "      <td>294.085693</td>\n",
       "      <td>296.406189</td>\n",
       "      <td>294.085693</td>\n",
       "      <td>297.174591</td>\n",
       "      <td>296.406189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163797</th>\n",
       "      <td>1980-10-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>295.266998</td>\n",
       "      <td>296.204254</td>\n",
       "      <td>297.976593</td>\n",
       "      <td>297.217041</td>\n",
       "      <td>295.990906</td>\n",
       "      <td>296.283142</td>\n",
       "      <td>296.494812</td>\n",
       "      <td>...</td>\n",
       "      <td>297.659912</td>\n",
       "      <td>296.652222</td>\n",
       "      <td>296.756897</td>\n",
       "      <td>297.968018</td>\n",
       "      <td>296.026703</td>\n",
       "      <td>294.279358</td>\n",
       "      <td>296.925720</td>\n",
       "      <td>294.279358</td>\n",
       "      <td>297.382996</td>\n",
       "      <td>296.925720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163798</th>\n",
       "      <td>1980-11-16 00:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>295.787415</td>\n",
       "      <td>296.935608</td>\n",
       "      <td>298.933594</td>\n",
       "      <td>298.348389</td>\n",
       "      <td>296.734222</td>\n",
       "      <td>297.134613</td>\n",
       "      <td>297.408020</td>\n",
       "      <td>...</td>\n",
       "      <td>298.514954</td>\n",
       "      <td>297.787598</td>\n",
       "      <td>297.787720</td>\n",
       "      <td>300.189636</td>\n",
       "      <td>296.724030</td>\n",
       "      <td>295.586273</td>\n",
       "      <td>297.436218</td>\n",
       "      <td>295.586273</td>\n",
       "      <td>297.640442</td>\n",
       "      <td>297.436218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163799</th>\n",
       "      <td>1980-12-16 12:00:00</td>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>296.471985</td>\n",
       "      <td>298.259705</td>\n",
       "      <td>299.563507</td>\n",
       "      <td>299.657440</td>\n",
       "      <td>297.646576</td>\n",
       "      <td>298.153778</td>\n",
       "      <td>298.396667</td>\n",
       "      <td>...</td>\n",
       "      <td>299.027649</td>\n",
       "      <td>298.872803</td>\n",
       "      <td>298.487122</td>\n",
       "      <td>300.479492</td>\n",
       "      <td>297.522369</td>\n",
       "      <td>296.703033</td>\n",
       "      <td>298.198212</td>\n",
       "      <td>296.703033</td>\n",
       "      <td>297.952118</td>\n",
       "      <td>298.198212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>163800 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      time     lat      lon         tas       tas_2  \\\n",
       "0      1960-01-16 12:00:00 -43.125  288.750  284.528320  282.464142   \n",
       "1      1960-02-15 12:00:00 -43.125  288.750  287.539368  280.244568   \n",
       "2      1960-03-16 12:00:00 -43.125  288.750  284.881317  280.398346   \n",
       "3      1960-04-16 00:00:00 -43.125  288.750  281.906555  276.135284   \n",
       "4      1960-05-16 12:00:00 -43.125  288.750  279.067780  274.095276   \n",
       "...                    ...     ...      ...         ...         ...   \n",
       "163795 1980-08-16 12:00:00 -13.125  335.625  295.138611  295.646790   \n",
       "163796 1980-09-16 00:00:00 -13.125  335.625  294.829285  295.332123   \n",
       "163797 1980-10-16 12:00:00 -13.125  335.625  295.266998  296.204254   \n",
       "163798 1980-11-16 00:00:00 -13.125  335.625  295.787415  296.935608   \n",
       "163799 1980-12-16 12:00:00 -13.125  335.625  296.471985  298.259705   \n",
       "\n",
       "             tas_3       tas_4       tas_5       tas_6       tas_7  ...  \\\n",
       "0       284.291168  283.132751  284.651947  284.831085  284.705200  ...   \n",
       "1       284.054016  285.201050  285.553284  284.454803  284.374817  ...   \n",
       "2       284.130188  283.143311  282.487152  282.092773  282.171570  ...   \n",
       "3       278.999359  278.682312  277.991150  278.428497  278.910461  ...   \n",
       "4       276.211304  275.564301  276.290802  276.003906  275.955292  ...   \n",
       "...            ...         ...         ...         ...         ...  ...   \n",
       "163795  297.660187  296.686462  295.769592  295.989685  296.137421  ...   \n",
       "163796  297.565948  296.689148  295.513763  295.840149  296.017670  ...   \n",
       "163797  297.976593  297.217041  295.990906  296.283142  296.494812  ...   \n",
       "163798  298.933594  298.348389  296.734222  297.134613  297.408020  ...   \n",
       "163799  299.563507  299.657440  297.646576  298.153778  298.396667  ...   \n",
       "\n",
       "            tas_30      tas_31      tas_32      tas_33      tas_34  \\\n",
       "0       281.811829  281.371918  283.208984  284.216949  286.015350   \n",
       "1       282.837433  282.395935  282.835175  287.725464  286.617950   \n",
       "2       280.508759  280.181793  281.891022  284.751038  284.893921   \n",
       "3       276.122742  278.386505  277.180573  279.325195  280.907806   \n",
       "4       272.721802  275.065002  274.005920  276.936218  279.518860   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "163795  297.207520  296.141510  296.076263  296.818420  295.533142   \n",
       "163796  296.929565  295.970123  296.137695  296.979309  295.515900   \n",
       "163797  297.659912  296.652222  296.756897  297.968018  296.026703   \n",
       "163798  298.514954  297.787598  297.787720  300.189636  296.724030   \n",
       "163799  299.027649  298.872803  298.487122  300.479492  297.522369   \n",
       "\n",
       "            tas_35      tas_36      tas_37      tas_38      tas_39  \n",
       "0       283.668304  284.809875  283.668304  284.835632  284.809875  \n",
       "1       283.943146  284.162109  283.943146  285.790070  284.162109  \n",
       "2       283.891754  282.453857  283.891754  287.167877  282.453857  \n",
       "3       279.808960  278.433167  279.808960  288.571198  278.433167  \n",
       "4       277.367950  275.130280  277.367950  289.716766  275.130280  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "163795  294.159027  296.367096  294.159027  296.985901  296.367096  \n",
       "163796  294.085693  296.406189  294.085693  297.174591  296.406189  \n",
       "163797  294.279358  296.925720  294.279358  297.382996  296.925720  \n",
       "163798  295.586273  297.436218  295.586273  297.640442  297.436218  \n",
       "163799  296.703033  298.198212  296.703033  297.952118  298.198212  \n",
       "\n",
       "[163800 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_obj.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.edge_weight = torch.nn.Parameter(torch.ones(ssp_obj.train_data.num_edges))\n",
    "        self.conv1 = GCNConv(-1, 36)\n",
    "        self.conv2 = GCNConv(36, 163800)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        # x = self.conv1(x, edge_index, torch.where(self.edge_weight.abs() > torch.ones(data.num_edges), self.edge_weight, torch.ones(data.num_edges)))\n",
    "        x = self.conv1(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        # x = self.conv2(x, edge_index, torch.where(self.edge_weight.abs() > torch.ones(data.num_edges), self.edge_weight, torch.ones(data.num_edges)))\n",
    "        x = self.conv2(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(85144.4922, grad_fn=<MseLossBackward0>)\n",
      "1 tensor(13070132., grad_fn=<MseLossBackward0>)\n",
      "2 tensor(85127.4922, grad_fn=<MseLossBackward0>)\n",
      "3 tensor(162686.6094, grad_fn=<MseLossBackward0>)\n",
      "4 tensor(84983.8594, grad_fn=<MseLossBackward0>)\n",
      "5 tensor(84965.9531, grad_fn=<MseLossBackward0>)\n",
      "6 tensor(84946.4844, grad_fn=<MseLossBackward0>)\n",
      "7 tensor(84925.7188, grad_fn=<MseLossBackward0>)\n",
      "8 tensor(84903.8672, grad_fn=<MseLossBackward0>)\n",
      "9 tensor(84881.0625, grad_fn=<MseLossBackward0>)\n",
      "10 tensor(84857.4453, grad_fn=<MseLossBackward0>)\n",
      "11 tensor(84833.0781, grad_fn=<MseLossBackward0>)\n",
      "12 tensor(84808.0781, grad_fn=<MseLossBackward0>)\n",
      "13 tensor(84782.4844, grad_fn=<MseLossBackward0>)\n",
      "14 tensor(84756.3750, grad_fn=<MseLossBackward0>)\n",
      "15 tensor(84729.7969, grad_fn=<MseLossBackward0>)\n",
      "16 tensor(84702.7891, grad_fn=<MseLossBackward0>)\n",
      "17 tensor(84675.3984, grad_fn=<MseLossBackward0>)\n",
      "18 tensor(84647.6641, grad_fn=<MseLossBackward0>)\n",
      "19 tensor(84619.6094, grad_fn=<MseLossBackward0>)\n",
      "20 tensor(84591.2812, grad_fn=<MseLossBackward0>)\n",
      "21 tensor(84562.6875, grad_fn=<MseLossBackward0>)\n",
      "22 tensor(84533.8672, grad_fn=<MseLossBackward0>)\n",
      "23 tensor(84504.8672, grad_fn=<MseLossBackward0>)\n",
      "24 tensor(84475.6562, grad_fn=<MseLossBackward0>)\n",
      "25 tensor(84446.3125, grad_fn=<MseLossBackward0>)\n",
      "26 tensor(84416.8125, grad_fn=<MseLossBackward0>)\n",
      "27 tensor(84387.1875, grad_fn=<MseLossBackward0>)\n",
      "28 tensor(84357.4844, grad_fn=<MseLossBackward0>)\n",
      "29 tensor(84327.6719, grad_fn=<MseLossBackward0>)\n",
      "30 tensor(84297.8125, grad_fn=<MseLossBackward0>)\n",
      "31 tensor(84267.8828, grad_fn=<MseLossBackward0>)\n",
      "32 tensor(84237.9219, grad_fn=<MseLossBackward0>)\n",
      "33 tensor(84207.9297, grad_fn=<MseLossBackward0>)\n",
      "34 tensor(84177.9219, grad_fn=<MseLossBackward0>)\n",
      "35 tensor(84147.9297, grad_fn=<MseLossBackward0>)\n",
      "36 tensor(84117.9453, grad_fn=<MseLossBackward0>)\n",
      "37 tensor(84087.9766, grad_fn=<MseLossBackward0>)\n",
      "38 tensor(84058.0312, grad_fn=<MseLossBackward0>)\n",
      "39 tensor(84028.1484, grad_fn=<MseLossBackward0>)\n",
      "40 tensor(83998.3125, grad_fn=<MseLossBackward0>)\n",
      "41 tensor(83968.5391, grad_fn=<MseLossBackward0>)\n",
      "42 tensor(83938.8438, grad_fn=<MseLossBackward0>)\n",
      "43 tensor(83909.2188, grad_fn=<MseLossBackward0>)\n",
      "44 tensor(83879.6797, grad_fn=<MseLossBackward0>)\n",
      "45 tensor(83850.2578, grad_fn=<MseLossBackward0>)\n",
      "46 tensor(83820.9219, grad_fn=<MseLossBackward0>)\n",
      "47 tensor(83791.7031, grad_fn=<MseLossBackward0>)\n",
      "48 tensor(83762.6016, grad_fn=<MseLossBackward0>)\n",
      "49 tensor(83733.6250, grad_fn=<MseLossBackward0>)\n",
      "50 tensor(83704.7734, grad_fn=<MseLossBackward0>)\n",
      "51 tensor(83676.0625, grad_fn=<MseLossBackward0>)\n",
      "52 tensor(83647.5000, grad_fn=<MseLossBackward0>)\n",
      "53 tensor(83619.0781, grad_fn=<MseLossBackward0>)\n",
      "54 tensor(83590.8125, grad_fn=<MseLossBackward0>)\n",
      "55 tensor(83562.7109, grad_fn=<MseLossBackward0>)\n",
      "56 tensor(83534.7578, grad_fn=<MseLossBackward0>)\n",
      "57 tensor(83506.9688, grad_fn=<MseLossBackward0>)\n",
      "58 tensor(83479.3672, grad_fn=<MseLossBackward0>)\n",
      "59 tensor(83451.9219, grad_fn=<MseLossBackward0>)\n",
      "60 tensor(83424.6641, grad_fn=<MseLossBackward0>)\n",
      "61 tensor(83397.5781, grad_fn=<MseLossBackward0>)\n",
      "62 tensor(83370.6953, grad_fn=<MseLossBackward0>)\n",
      "63 tensor(83343.9922, grad_fn=<MseLossBackward0>)\n",
      "64 tensor(83317.4766, grad_fn=<MseLossBackward0>)\n",
      "65 tensor(83291.1641, grad_fn=<MseLossBackward0>)\n",
      "66 tensor(83265.0391, grad_fn=<MseLossBackward0>)\n",
      "67 tensor(83239.1250, grad_fn=<MseLossBackward0>)\n",
      "68 tensor(83213.3906, grad_fn=<MseLossBackward0>)\n",
      "69 tensor(83187.8750, grad_fn=<MseLossBackward0>)\n",
      "70 tensor(83162.5703, grad_fn=<MseLossBackward0>)\n",
      "71 tensor(83137.4766, grad_fn=<MseLossBackward0>)\n",
      "72 tensor(83112.5859, grad_fn=<MseLossBackward0>)\n",
      "73 tensor(83087.8984, grad_fn=<MseLossBackward0>)\n",
      "74 tensor(83063.4297, grad_fn=<MseLossBackward0>)\n",
      "75 tensor(83039.1797, grad_fn=<MseLossBackward0>)\n",
      "76 tensor(83015.1406, grad_fn=<MseLossBackward0>)\n",
      "77 tensor(82991.3203, grad_fn=<MseLossBackward0>)\n",
      "78 tensor(82967.7109, grad_fn=<MseLossBackward0>)\n",
      "79 tensor(82944.3203, grad_fn=<MseLossBackward0>)\n",
      "80 tensor(82921.1562, grad_fn=<MseLossBackward0>)\n",
      "81 tensor(82898.2109, grad_fn=<MseLossBackward0>)\n",
      "82 tensor(82875.4844, grad_fn=<MseLossBackward0>)\n",
      "83 tensor(82852.9688, grad_fn=<MseLossBackward0>)\n",
      "84 tensor(82830.6875, grad_fn=<MseLossBackward0>)\n",
      "85 tensor(82808.6094, grad_fn=<MseLossBackward0>)\n",
      "86 tensor(82786.7656, grad_fn=<MseLossBackward0>)\n",
      "87 tensor(82765.1328, grad_fn=<MseLossBackward0>)\n",
      "88 tensor(82743.7422, grad_fn=<MseLossBackward0>)\n",
      "89 tensor(82722.5469, grad_fn=<MseLossBackward0>)\n",
      "90 tensor(82701.5781, grad_fn=<MseLossBackward0>)\n",
      "91 tensor(82680.8438, grad_fn=<MseLossBackward0>)\n",
      "92 tensor(82660.3125, grad_fn=<MseLossBackward0>)\n",
      "93 tensor(82640.0078, grad_fn=<MseLossBackward0>)\n",
      "94 tensor(82619.9219, grad_fn=<MseLossBackward0>)\n",
      "95 tensor(82600.0469, grad_fn=<MseLossBackward0>)\n",
      "96 tensor(82580.3984, grad_fn=<MseLossBackward0>)\n",
      "97 tensor(82560.9609, grad_fn=<MseLossBackward0>)\n",
      "98 tensor(82541.7500, grad_fn=<MseLossBackward0>)\n",
      "99 tensor(82522.7344, grad_fn=<MseLossBackward0>)\n",
      "100 tensor(82503.9531, grad_fn=<MseLossBackward0>)\n",
      "101 tensor(82485.3672, grad_fn=<MseLossBackward0>)\n",
      "102 tensor(82467.0078, grad_fn=<MseLossBackward0>)\n",
      "103 tensor(82448.8516, grad_fn=<MseLossBackward0>)\n",
      "104 tensor(82430.9062, grad_fn=<MseLossBackward0>)\n",
      "105 tensor(82413.1641, grad_fn=<MseLossBackward0>)\n",
      "106 tensor(82395.6328, grad_fn=<MseLossBackward0>)\n",
      "107 tensor(82378.3047, grad_fn=<MseLossBackward0>)\n",
      "108 tensor(82361.1953, grad_fn=<MseLossBackward0>)\n",
      "109 tensor(82344.2656, grad_fn=<MseLossBackward0>)\n",
      "110 tensor(82327.5469, grad_fn=<MseLossBackward0>)\n",
      "111 tensor(82311.0312, grad_fn=<MseLossBackward0>)\n",
      "112 tensor(82294.7188, grad_fn=<MseLossBackward0>)\n",
      "113 tensor(82278.5938, grad_fn=<MseLossBackward0>)\n",
      "114 tensor(82262.6719, grad_fn=<MseLossBackward0>)\n",
      "115 tensor(82246.9375, grad_fn=<MseLossBackward0>)\n",
      "116 tensor(82231.4062, grad_fn=<MseLossBackward0>)\n",
      "117 tensor(82216.0547, grad_fn=<MseLossBackward0>)\n",
      "118 tensor(82200.8984, grad_fn=<MseLossBackward0>)\n",
      "119 tensor(82185.9297, grad_fn=<MseLossBackward0>)\n",
      "120 tensor(82171.1562, grad_fn=<MseLossBackward0>)\n",
      "121 tensor(82156.5469, grad_fn=<MseLossBackward0>)\n",
      "122 tensor(82142.1406, grad_fn=<MseLossBackward0>)\n",
      "123 tensor(82127.8984, grad_fn=<MseLossBackward0>)\n",
      "124 tensor(82113.8281, grad_fn=<MseLossBackward0>)\n",
      "125 tensor(82099.9531, grad_fn=<MseLossBackward0>)\n",
      "126 tensor(82086.2578, grad_fn=<MseLossBackward0>)\n",
      "127 tensor(82072.7266, grad_fn=<MseLossBackward0>)\n",
      "128 tensor(82059.3750, grad_fn=<MseLossBackward0>)\n",
      "129 tensor(82046.1875, grad_fn=<MseLossBackward0>)\n",
      "130 tensor(82033.1641, grad_fn=<MseLossBackward0>)\n",
      "131 tensor(82020.3125, grad_fn=<MseLossBackward0>)\n",
      "132 tensor(82007.6250, grad_fn=<MseLossBackward0>)\n",
      "133 tensor(81995.1016, grad_fn=<MseLossBackward0>)\n",
      "134 tensor(81982.7422, grad_fn=<MseLossBackward0>)\n",
      "135 tensor(81970.5469, grad_fn=<MseLossBackward0>)\n",
      "136 tensor(81958.5000, grad_fn=<MseLossBackward0>)\n",
      "137 tensor(81946.6172, grad_fn=<MseLossBackward0>)\n",
      "138 tensor(81934.8672, grad_fn=<MseLossBackward0>)\n",
      "139 tensor(81923.3047, grad_fn=<MseLossBackward0>)\n",
      "140 tensor(81911.8672, grad_fn=<MseLossBackward0>)\n",
      "141 tensor(81900.5859, grad_fn=<MseLossBackward0>)\n",
      "142 tensor(81889.4453, grad_fn=<MseLossBackward0>)\n",
      "143 tensor(81878.4688, grad_fn=<MseLossBackward0>)\n",
      "144 tensor(81867.6250, grad_fn=<MseLossBackward0>)\n",
      "145 tensor(81856.9297, grad_fn=<MseLossBackward0>)\n",
      "146 tensor(81846.3672, grad_fn=<MseLossBackward0>)\n",
      "147 tensor(81835.9453, grad_fn=<MseLossBackward0>)\n",
      "148 tensor(81825.6562, grad_fn=<MseLossBackward0>)\n",
      "149 tensor(81815.5156, grad_fn=<MseLossBackward0>)\n",
      "150 tensor(81805.5078, grad_fn=<MseLossBackward0>)\n",
      "151 tensor(81795.6172, grad_fn=<MseLossBackward0>)\n",
      "152 tensor(81785.8672, grad_fn=<MseLossBackward0>)\n",
      "153 tensor(81776.2422, grad_fn=<MseLossBackward0>)\n",
      "154 tensor(81766.7578, grad_fn=<MseLossBackward0>)\n",
      "155 tensor(81757.3828, grad_fn=<MseLossBackward0>)\n",
      "156 tensor(81748.1250, grad_fn=<MseLossBackward0>)\n",
      "157 tensor(81739.0156, grad_fn=<MseLossBackward0>)\n",
      "158 tensor(81730.0078, grad_fn=<MseLossBackward0>)\n",
      "159 tensor(81721.1328, grad_fn=<MseLossBackward0>)\n",
      "160 tensor(81712.3594, grad_fn=<MseLossBackward0>)\n",
      "161 tensor(81703.7188, grad_fn=<MseLossBackward0>)\n",
      "162 tensor(81695.1797, grad_fn=<MseLossBackward0>)\n",
      "163 tensor(81686.7578, grad_fn=<MseLossBackward0>)\n",
      "164 tensor(81678.4531, grad_fn=<MseLossBackward0>)\n",
      "165 tensor(81670.2500, grad_fn=<MseLossBackward0>)\n",
      "166 tensor(81662.1641, grad_fn=<MseLossBackward0>)\n",
      "167 tensor(81654.1797, grad_fn=<MseLossBackward0>)\n",
      "168 tensor(81646.3047, grad_fn=<MseLossBackward0>)\n",
      "169 tensor(81638.5312, grad_fn=<MseLossBackward0>)\n",
      "170 tensor(81630.8750, grad_fn=<MseLossBackward0>)\n",
      "171 tensor(81623.2969, grad_fn=<MseLossBackward0>)\n",
      "172 tensor(81615.8359, grad_fn=<MseLossBackward0>)\n",
      "173 tensor(81608.4766, grad_fn=<MseLossBackward0>)\n",
      "174 tensor(81601.2109, grad_fn=<MseLossBackward0>)\n",
      "175 tensor(81594.0469, grad_fn=<MseLossBackward0>)\n",
      "176 tensor(81586.9688, grad_fn=<MseLossBackward0>)\n",
      "177 tensor(81579.9844, grad_fn=<MseLossBackward0>)\n",
      "178 tensor(81573.1016, grad_fn=<MseLossBackward0>)\n",
      "179 tensor(81566.3047, grad_fn=<MseLossBackward0>)\n",
      "180 tensor(81559.6016, grad_fn=<MseLossBackward0>)\n",
      "181 tensor(81552.9844, grad_fn=<MseLossBackward0>)\n",
      "182 tensor(81546.4609, grad_fn=<MseLossBackward0>)\n",
      "183 tensor(81540.0234, grad_fn=<MseLossBackward0>)\n",
      "184 tensor(81533.6719, grad_fn=<MseLossBackward0>)\n",
      "185 tensor(81527.3828, grad_fn=<MseLossBackward0>)\n",
      "186 tensor(81521.2109, grad_fn=<MseLossBackward0>)\n",
      "187 tensor(81515.1016, grad_fn=<MseLossBackward0>)\n",
      "188 tensor(81509.0703, grad_fn=<MseLossBackward0>)\n",
      "189 tensor(81503.1406, grad_fn=<MseLossBackward0>)\n",
      "190 tensor(81497.2812, grad_fn=<MseLossBackward0>)\n",
      "191 tensor(81491.4922, grad_fn=<MseLossBackward0>)\n",
      "192 tensor(81485.7891, grad_fn=<MseLossBackward0>)\n",
      "193 tensor(81480.1562, grad_fn=<MseLossBackward0>)\n",
      "194 tensor(81474.6016, grad_fn=<MseLossBackward0>)\n",
      "195 tensor(81469.1172, grad_fn=<MseLossBackward0>)\n",
      "196 tensor(81463.7031, grad_fn=<MseLossBackward0>)\n",
      "197 tensor(81458.3828, grad_fn=<MseLossBackward0>)\n",
      "198 tensor(81453.1172, grad_fn=<MseLossBackward0>)\n",
      "199 tensor(81447.9141, grad_fn=<MseLossBackward0>)\n",
      "200 tensor(81442.7812, grad_fn=<MseLossBackward0>)\n",
      "201 tensor(81437.7344, grad_fn=<MseLossBackward0>)\n",
      "202 tensor(81432.7422, grad_fn=<MseLossBackward0>)\n",
      "203 tensor(81427.8203, grad_fn=<MseLossBackward0>)\n",
      "204 tensor(81422.9688, grad_fn=<MseLossBackward0>)\n",
      "205 tensor(81418.1719, grad_fn=<MseLossBackward0>)\n",
      "206 tensor(81413.4453, grad_fn=<MseLossBackward0>)\n",
      "207 tensor(81408.7812, grad_fn=<MseLossBackward0>)\n",
      "208 tensor(81404.1719, grad_fn=<MseLossBackward0>)\n",
      "209 tensor(81399.6406, grad_fn=<MseLossBackward0>)\n",
      "210 tensor(81395.1562, grad_fn=<MseLossBackward0>)\n",
      "211 tensor(81390.7344, grad_fn=<MseLossBackward0>)\n",
      "212 tensor(81386.3672, grad_fn=<MseLossBackward0>)\n",
      "213 tensor(81382.0703, grad_fn=<MseLossBackward0>)\n",
      "214 tensor(81377.8125, grad_fn=<MseLossBackward0>)\n",
      "215 tensor(81373.6328, grad_fn=<MseLossBackward0>)\n",
      "216 tensor(81369.5078, grad_fn=<MseLossBackward0>)\n",
      "217 tensor(81365.4219, grad_fn=<MseLossBackward0>)\n",
      "218 tensor(81361.3984, grad_fn=<MseLossBackward0>)\n",
      "219 tensor(81357.4297, grad_fn=<MseLossBackward0>)\n",
      "220 tensor(81353.5156, grad_fn=<MseLossBackward0>)\n",
      "221 tensor(81349.6562, grad_fn=<MseLossBackward0>)\n",
      "222 tensor(81345.8438, grad_fn=<MseLossBackward0>)\n",
      "223 tensor(81342.0781, grad_fn=<MseLossBackward0>)\n",
      "224 tensor(81338.3828, grad_fn=<MseLossBackward0>)\n",
      "225 tensor(81334.7188, grad_fn=<MseLossBackward0>)\n",
      "226 tensor(81331.1016, grad_fn=<MseLossBackward0>)\n",
      "227 tensor(81327.5391, grad_fn=<MseLossBackward0>)\n",
      "228 tensor(81324.0156, grad_fn=<MseLossBackward0>)\n",
      "229 tensor(81320.5625, grad_fn=<MseLossBackward0>)\n",
      "230 tensor(81317.1328, grad_fn=<MseLossBackward0>)\n",
      "231 tensor(81313.7578, grad_fn=<MseLossBackward0>)\n",
      "232 tensor(81310.4375, grad_fn=<MseLossBackward0>)\n",
      "233 tensor(81307.1406, grad_fn=<MseLossBackward0>)\n",
      "234 tensor(81303.8984, grad_fn=<MseLossBackward0>)\n",
      "235 tensor(81300.7109, grad_fn=<MseLossBackward0>)\n",
      "236 tensor(81297.5547, grad_fn=<MseLossBackward0>)\n",
      "237 tensor(81294.4453, grad_fn=<MseLossBackward0>)\n",
      "238 tensor(81291.3828, grad_fn=<MseLossBackward0>)\n",
      "239 tensor(81288.3516, grad_fn=<MseLossBackward0>)\n",
      "240 tensor(81285.3672, grad_fn=<MseLossBackward0>)\n",
      "241 tensor(81282.4141, grad_fn=<MseLossBackward0>)\n",
      "242 tensor(81279.5078, grad_fn=<MseLossBackward0>)\n",
      "243 tensor(81276.6406, grad_fn=<MseLossBackward0>)\n",
      "244 tensor(81273.8125, grad_fn=<MseLossBackward0>)\n",
      "245 tensor(81271.0234, grad_fn=<MseLossBackward0>)\n",
      "246 tensor(81268.2734, grad_fn=<MseLossBackward0>)\n",
      "247 tensor(81265.5547, grad_fn=<MseLossBackward0>)\n",
      "248 tensor(81262.8672, grad_fn=<MseLossBackward0>)\n",
      "249 tensor(81260.2344, grad_fn=<MseLossBackward0>)\n",
      "250 tensor(81257.6250, grad_fn=<MseLossBackward0>)\n",
      "251 tensor(81255.0547, grad_fn=<MseLossBackward0>)\n",
      "252 tensor(81252.5234, grad_fn=<MseLossBackward0>)\n",
      "253 tensor(81250.0234, grad_fn=<MseLossBackward0>)\n",
      "254 tensor(81247.5469, grad_fn=<MseLossBackward0>)\n",
      "255 tensor(81245.1094, grad_fn=<MseLossBackward0>)\n",
      "256 tensor(81242.7188, grad_fn=<MseLossBackward0>)\n",
      "257 tensor(81240.3516, grad_fn=<MseLossBackward0>)\n",
      "258 tensor(81238.0156, grad_fn=<MseLossBackward0>)\n",
      "259 tensor(81235.7109, grad_fn=<MseLossBackward0>)\n",
      "260 tensor(81233.4375, grad_fn=<MseLossBackward0>)\n",
      "261 tensor(81231.2031, grad_fn=<MseLossBackward0>)\n",
      "262 tensor(81228.9844, grad_fn=<MseLossBackward0>)\n",
      "263 tensor(81226.7969, grad_fn=<MseLossBackward0>)\n",
      "264 tensor(81224.6562, grad_fn=<MseLossBackward0>)\n",
      "265 tensor(81222.5312, grad_fn=<MseLossBackward0>)\n",
      "266 tensor(81220.4375, grad_fn=<MseLossBackward0>)\n",
      "267 tensor(81218.3672, grad_fn=<MseLossBackward0>)\n",
      "268 tensor(81216.3359, grad_fn=<MseLossBackward0>)\n",
      "269 tensor(81214.3359, grad_fn=<MseLossBackward0>)\n",
      "270 tensor(81212.3516, grad_fn=<MseLossBackward0>)\n",
      "271 tensor(81210.3906, grad_fn=<MseLossBackward0>)\n",
      "272 tensor(81208.4688, grad_fn=<MseLossBackward0>)\n",
      "273 tensor(81206.5625, grad_fn=<MseLossBackward0>)\n",
      "274 tensor(81204.6875, grad_fn=<MseLossBackward0>)\n",
      "275 tensor(81202.8438, grad_fn=<MseLossBackward0>)\n",
      "276 tensor(81201.0234, grad_fn=<MseLossBackward0>)\n",
      "277 tensor(81199.2266, grad_fn=<MseLossBackward0>)\n",
      "278 tensor(81197.4453, grad_fn=<MseLossBackward0>)\n",
      "279 tensor(81195.7031, grad_fn=<MseLossBackward0>)\n",
      "280 tensor(81193.9688, grad_fn=<MseLossBackward0>)\n",
      "281 tensor(81192.2812, grad_fn=<MseLossBackward0>)\n",
      "282 tensor(81190.5938, grad_fn=<MseLossBackward0>)\n",
      "283 tensor(81188.9375, grad_fn=<MseLossBackward0>)\n",
      "284 tensor(81187.3203, grad_fn=<MseLossBackward0>)\n",
      "285 tensor(81185.7031, grad_fn=<MseLossBackward0>)\n",
      "286 tensor(81184.1172, grad_fn=<MseLossBackward0>)\n",
      "287 tensor(81182.5547, grad_fn=<MseLossBackward0>)\n",
      "288 tensor(81181.0078, grad_fn=<MseLossBackward0>)\n",
      "289 tensor(81179.4922, grad_fn=<MseLossBackward0>)\n",
      "290 tensor(81177.9844, grad_fn=<MseLossBackward0>)\n",
      "291 tensor(81176.5078, grad_fn=<MseLossBackward0>)\n",
      "292 tensor(81175.0469, grad_fn=<MseLossBackward0>)\n",
      "293 tensor(81173.6094, grad_fn=<MseLossBackward0>)\n",
      "294 tensor(81172.1875, grad_fn=<MseLossBackward0>)\n",
      "295 tensor(81170.7891, grad_fn=<MseLossBackward0>)\n",
      "296 tensor(81169.4062, grad_fn=<MseLossBackward0>)\n",
      "297 tensor(81168.0391, grad_fn=<MseLossBackward0>)\n",
      "298 tensor(81166.7109, grad_fn=<MseLossBackward0>)\n",
      "299 tensor(81165.3828, grad_fn=<MseLossBackward0>)\n",
      "300 tensor(81164.0781, grad_fn=<MseLossBackward0>)\n",
      "301 tensor(81162.7891, grad_fn=<MseLossBackward0>)\n",
      "302 tensor(81161.5234, grad_fn=<MseLossBackward0>)\n",
      "303 tensor(81160.2734, grad_fn=<MseLossBackward0>)\n",
      "304 tensor(81159.0391, grad_fn=<MseLossBackward0>)\n",
      "305 tensor(81157.8203, grad_fn=<MseLossBackward0>)\n",
      "306 tensor(81156.6250, grad_fn=<MseLossBackward0>)\n",
      "307 tensor(81155.4375, grad_fn=<MseLossBackward0>)\n",
      "308 tensor(81154.2734, grad_fn=<MseLossBackward0>)\n",
      "309 tensor(81153.1172, grad_fn=<MseLossBackward0>)\n",
      "310 tensor(81151.9844, grad_fn=<MseLossBackward0>)\n",
      "311 tensor(81150.8750, grad_fn=<MseLossBackward0>)\n",
      "312 tensor(81149.7734, grad_fn=<MseLossBackward0>)\n",
      "313 tensor(81148.6797, grad_fn=<MseLossBackward0>)\n",
      "314 tensor(81147.6094, grad_fn=<MseLossBackward0>)\n",
      "315 tensor(81146.5547, grad_fn=<MseLossBackward0>)\n",
      "316 tensor(81145.5156, grad_fn=<MseLossBackward0>)\n",
      "317 tensor(81144.4844, grad_fn=<MseLossBackward0>)\n",
      "318 tensor(81143.4688, grad_fn=<MseLossBackward0>)\n",
      "319 tensor(81142.4688, grad_fn=<MseLossBackward0>)\n",
      "320 tensor(81141.4844, grad_fn=<MseLossBackward0>)\n",
      "321 tensor(81140.5156, grad_fn=<MseLossBackward0>)\n",
      "322 tensor(81139.5625, grad_fn=<MseLossBackward0>)\n",
      "323 tensor(81138.6172, grad_fn=<MseLossBackward0>)\n",
      "324 tensor(81137.6875, grad_fn=<MseLossBackward0>)\n",
      "325 tensor(81136.7734, grad_fn=<MseLossBackward0>)\n",
      "326 tensor(81135.8672, grad_fn=<MseLossBackward0>)\n",
      "327 tensor(81134.9766, grad_fn=<MseLossBackward0>)\n",
      "328 tensor(81134.0938, grad_fn=<MseLossBackward0>)\n",
      "329 tensor(81133.2422, grad_fn=<MseLossBackward0>)\n",
      "330 tensor(81132.3750, grad_fn=<MseLossBackward0>)\n",
      "331 tensor(81131.5391, grad_fn=<MseLossBackward0>)\n",
      "332 tensor(81130.7188, grad_fn=<MseLossBackward0>)\n",
      "333 tensor(81129.8906, grad_fn=<MseLossBackward0>)\n",
      "334 tensor(81129.0859, grad_fn=<MseLossBackward0>)\n",
      "335 tensor(81128.2812, grad_fn=<MseLossBackward0>)\n",
      "336 tensor(81127.5078, grad_fn=<MseLossBackward0>)\n",
      "337 tensor(81126.7266, grad_fn=<MseLossBackward0>)\n",
      "338 tensor(81125.9766, grad_fn=<MseLossBackward0>)\n",
      "339 tensor(81125.2109, grad_fn=<MseLossBackward0>)\n",
      "340 tensor(81124.4844, grad_fn=<MseLossBackward0>)\n",
      "341 tensor(81123.7422, grad_fn=<MseLossBackward0>)\n",
      "342 tensor(81123.0391, grad_fn=<MseLossBackward0>)\n",
      "343 tensor(81122.3281, grad_fn=<MseLossBackward0>)\n",
      "344 tensor(81121.6172, grad_fn=<MseLossBackward0>)\n",
      "345 tensor(81120.9375, grad_fn=<MseLossBackward0>)\n",
      "346 tensor(81120.2422, grad_fn=<MseLossBackward0>)\n",
      "347 tensor(81119.5859, grad_fn=<MseLossBackward0>)\n",
      "348 tensor(81118.9141, grad_fn=<MseLossBackward0>)\n",
      "349 tensor(81118.2656, grad_fn=<MseLossBackward0>)\n",
      "350 tensor(81117.6250, grad_fn=<MseLossBackward0>)\n",
      "351 tensor(81116.9922, grad_fn=<MseLossBackward0>)\n",
      "352 tensor(81116.3750, grad_fn=<MseLossBackward0>)\n",
      "353 tensor(81115.7578, grad_fn=<MseLossBackward0>)\n",
      "354 tensor(81115.1562, grad_fn=<MseLossBackward0>)\n",
      "355 tensor(81114.5625, grad_fn=<MseLossBackward0>)\n",
      "356 tensor(81113.9688, grad_fn=<MseLossBackward0>)\n",
      "357 tensor(81113.3906, grad_fn=<MseLossBackward0>)\n",
      "358 tensor(81112.8203, grad_fn=<MseLossBackward0>)\n",
      "359 tensor(81112.2578, grad_fn=<MseLossBackward0>)\n",
      "360 tensor(81111.7031, grad_fn=<MseLossBackward0>)\n",
      "361 tensor(81111.1562, grad_fn=<MseLossBackward0>)\n",
      "362 tensor(81110.6172, grad_fn=<MseLossBackward0>)\n",
      "363 tensor(81110.0859, grad_fn=<MseLossBackward0>)\n",
      "364 tensor(81109.5547, grad_fn=<MseLossBackward0>)\n",
      "365 tensor(81109.0469, grad_fn=<MseLossBackward0>)\n",
      "366 tensor(81108.5391, grad_fn=<MseLossBackward0>)\n",
      "367 tensor(81108.0312, grad_fn=<MseLossBackward0>)\n",
      "368 tensor(81107.5391, grad_fn=<MseLossBackward0>)\n",
      "369 tensor(81107.0469, grad_fn=<MseLossBackward0>)\n",
      "370 tensor(81106.5703, grad_fn=<MseLossBackward0>)\n",
      "371 tensor(81106.1016, grad_fn=<MseLossBackward0>)\n",
      "372 tensor(81105.6406, grad_fn=<MseLossBackward0>)\n",
      "373 tensor(81105.1719, grad_fn=<MseLossBackward0>)\n",
      "374 tensor(81104.7266, grad_fn=<MseLossBackward0>)\n",
      "375 tensor(81104.2734, grad_fn=<MseLossBackward0>)\n",
      "376 tensor(81103.8281, grad_fn=<MseLossBackward0>)\n",
      "377 tensor(81103.3984, grad_fn=<MseLossBackward0>)\n",
      "378 tensor(81102.9688, grad_fn=<MseLossBackward0>)\n",
      "379 tensor(81102.5469, grad_fn=<MseLossBackward0>)\n",
      "380 tensor(81102.1406, grad_fn=<MseLossBackward0>)\n",
      "381 tensor(81101.7266, grad_fn=<MseLossBackward0>)\n",
      "382 tensor(81101.3359, grad_fn=<MseLossBackward0>)\n",
      "383 tensor(81100.9297, grad_fn=<MseLossBackward0>)\n",
      "384 tensor(81100.5391, grad_fn=<MseLossBackward0>)\n",
      "385 tensor(81100.1484, grad_fn=<MseLossBackward0>)\n",
      "386 tensor(81099.7656, grad_fn=<MseLossBackward0>)\n",
      "387 tensor(81099.3984, grad_fn=<MseLossBackward0>)\n",
      "388 tensor(81099.0234, grad_fn=<MseLossBackward0>)\n",
      "389 tensor(81098.6641, grad_fn=<MseLossBackward0>)\n",
      "390 tensor(81098.3047, grad_fn=<MseLossBackward0>)\n",
      "391 tensor(81097.9531, grad_fn=<MseLossBackward0>)\n",
      "392 tensor(81097.6016, grad_fn=<MseLossBackward0>)\n",
      "393 tensor(81097.2578, grad_fn=<MseLossBackward0>)\n",
      "394 tensor(81096.9219, grad_fn=<MseLossBackward0>)\n",
      "395 tensor(81096.5859, grad_fn=<MseLossBackward0>)\n",
      "396 tensor(81096.2734, grad_fn=<MseLossBackward0>)\n",
      "397 tensor(81095.9297, grad_fn=<MseLossBackward0>)\n",
      "398 tensor(81095.6172, grad_fn=<MseLossBackward0>)\n",
      "399 tensor(81095.3125, grad_fn=<MseLossBackward0>)\n",
      "400 tensor(81095., grad_fn=<MseLossBackward0>)\n",
      "401 tensor(81094.7031, grad_fn=<MseLossBackward0>)\n",
      "402 tensor(81094.3984, grad_fn=<MseLossBackward0>)\n",
      "403 tensor(81094.0938, grad_fn=<MseLossBackward0>)\n",
      "404 tensor(81093.8125, grad_fn=<MseLossBackward0>)\n",
      "405 tensor(81093.5234, grad_fn=<MseLossBackward0>)\n",
      "406 tensor(81093.2266, grad_fn=<MseLossBackward0>)\n",
      "407 tensor(81092.9609, grad_fn=<MseLossBackward0>)\n",
      "408 tensor(81092.6875, grad_fn=<MseLossBackward0>)\n",
      "409 tensor(81092.4141, grad_fn=<MseLossBackward0>)\n",
      "410 tensor(81092.1328, grad_fn=<MseLossBackward0>)\n",
      "411 tensor(81091.8828, grad_fn=<MseLossBackward0>)\n",
      "412 tensor(81091.6250, grad_fn=<MseLossBackward0>)\n",
      "413 tensor(81091.3672, grad_fn=<MseLossBackward0>)\n",
      "414 tensor(81091.1094, grad_fn=<MseLossBackward0>)\n",
      "415 tensor(81090.8672, grad_fn=<MseLossBackward0>)\n",
      "416 tensor(81090.6250, grad_fn=<MseLossBackward0>)\n",
      "417 tensor(81090.3828, grad_fn=<MseLossBackward0>)\n",
      "418 tensor(81090.1641, grad_fn=<MseLossBackward0>)\n",
      "419 tensor(81089.9141, grad_fn=<MseLossBackward0>)\n",
      "420 tensor(81089.6875, grad_fn=<MseLossBackward0>)\n",
      "421 tensor(81089.4609, grad_fn=<MseLossBackward0>)\n",
      "422 tensor(81089.2344, grad_fn=<MseLossBackward0>)\n",
      "423 tensor(81089.0312, grad_fn=<MseLossBackward0>)\n",
      "424 tensor(81088.8047, grad_fn=<MseLossBackward0>)\n",
      "425 tensor(81088.5938, grad_fn=<MseLossBackward0>)\n",
      "426 tensor(81088.3750, grad_fn=<MseLossBackward0>)\n",
      "427 tensor(81088.1797, grad_fn=<MseLossBackward0>)\n",
      "428 tensor(81087.9688, grad_fn=<MseLossBackward0>)\n",
      "429 tensor(81087.7656, grad_fn=<MseLossBackward0>)\n",
      "430 tensor(81087.5781, grad_fn=<MseLossBackward0>)\n",
      "431 tensor(81087.3828, grad_fn=<MseLossBackward0>)\n",
      "432 tensor(81087.1797, grad_fn=<MseLossBackward0>)\n",
      "433 tensor(81087., grad_fn=<MseLossBackward0>)\n",
      "434 tensor(81086.8125, grad_fn=<MseLossBackward0>)\n",
      "435 tensor(81086.6250, grad_fn=<MseLossBackward0>)\n",
      "436 tensor(81086.4453, grad_fn=<MseLossBackward0>)\n",
      "437 tensor(81086.2656, grad_fn=<MseLossBackward0>)\n",
      "438 tensor(81086.1016, grad_fn=<MseLossBackward0>)\n",
      "439 tensor(81085.9219, grad_fn=<MseLossBackward0>)\n",
      "440 tensor(81085.7500, grad_fn=<MseLossBackward0>)\n",
      "441 tensor(81085.5781, grad_fn=<MseLossBackward0>)\n",
      "442 tensor(81085.4062, grad_fn=<MseLossBackward0>)\n",
      "443 tensor(81085.2656, grad_fn=<MseLossBackward0>)\n",
      "444 tensor(81085.1016, grad_fn=<MseLossBackward0>)\n",
      "445 tensor(81084.9375, grad_fn=<MseLossBackward0>)\n",
      "446 tensor(81084.7812, grad_fn=<MseLossBackward0>)\n",
      "447 tensor(81084.6250, grad_fn=<MseLossBackward0>)\n",
      "448 tensor(81084.4766, grad_fn=<MseLossBackward0>)\n",
      "449 tensor(81084.3203, grad_fn=<MseLossBackward0>)\n",
      "450 tensor(81084.1875, grad_fn=<MseLossBackward0>)\n",
      "451 tensor(81084.0391, grad_fn=<MseLossBackward0>)\n",
      "452 tensor(81083.8906, grad_fn=<MseLossBackward0>)\n",
      "453 tensor(81083.7578, grad_fn=<MseLossBackward0>)\n",
      "454 tensor(81083.6172, grad_fn=<MseLossBackward0>)\n",
      "455 tensor(81083.4844, grad_fn=<MseLossBackward0>)\n",
      "456 tensor(81083.3516, grad_fn=<MseLossBackward0>)\n",
      "457 tensor(81083.2188, grad_fn=<MseLossBackward0>)\n",
      "458 tensor(81083.0859, grad_fn=<MseLossBackward0>)\n",
      "459 tensor(81082.9688, grad_fn=<MseLossBackward0>)\n",
      "460 tensor(81082.8438, grad_fn=<MseLossBackward0>)\n",
      "461 tensor(81082.7188, grad_fn=<MseLossBackward0>)\n",
      "462 tensor(81082.5938, grad_fn=<MseLossBackward0>)\n",
      "463 tensor(81082.4688, grad_fn=<MseLossBackward0>)\n",
      "464 tensor(81082.3516, grad_fn=<MseLossBackward0>)\n",
      "465 tensor(81082.2344, grad_fn=<MseLossBackward0>)\n",
      "466 tensor(81082.1250, grad_fn=<MseLossBackward0>)\n",
      "467 tensor(81082.0234, grad_fn=<MseLossBackward0>)\n",
      "468 tensor(81081.9062, grad_fn=<MseLossBackward0>)\n",
      "469 tensor(81081.7969, grad_fn=<MseLossBackward0>)\n",
      "470 tensor(81081.6797, grad_fn=<MseLossBackward0>)\n",
      "471 tensor(81081.5781, grad_fn=<MseLossBackward0>)\n",
      "472 tensor(81081.4766, grad_fn=<MseLossBackward0>)\n",
      "473 tensor(81081.3672, grad_fn=<MseLossBackward0>)\n",
      "474 tensor(81081.2734, grad_fn=<MseLossBackward0>)\n",
      "475 tensor(81081.1562, grad_fn=<MseLossBackward0>)\n",
      "476 tensor(81081.0703, grad_fn=<MseLossBackward0>)\n",
      "477 tensor(81080.9766, grad_fn=<MseLossBackward0>)\n",
      "478 tensor(81080.8750, grad_fn=<MseLossBackward0>)\n",
      "479 tensor(81080.7812, grad_fn=<MseLossBackward0>)\n",
      "480 tensor(81080.6953, grad_fn=<MseLossBackward0>)\n",
      "481 tensor(81080.6016, grad_fn=<MseLossBackward0>)\n",
      "482 tensor(81080.5156, grad_fn=<MseLossBackward0>)\n",
      "483 tensor(81080.4297, grad_fn=<MseLossBackward0>)\n",
      "484 tensor(81080.3359, grad_fn=<MseLossBackward0>)\n",
      "485 tensor(81080.2500, grad_fn=<MseLossBackward0>)\n",
      "486 tensor(81080.1719, grad_fn=<MseLossBackward0>)\n",
      "487 tensor(81080.0859, grad_fn=<MseLossBackward0>)\n",
      "488 tensor(81079.9922, grad_fn=<MseLossBackward0>)\n",
      "489 tensor(81079.9297, grad_fn=<MseLossBackward0>)\n",
      "490 tensor(81079.8438, grad_fn=<MseLossBackward0>)\n",
      "491 tensor(81079.7656, grad_fn=<MseLossBackward0>)\n",
      "492 tensor(81079.6875, grad_fn=<MseLossBackward0>)\n",
      "493 tensor(81079.6172, grad_fn=<MseLossBackward0>)\n",
      "494 tensor(81079.5469, grad_fn=<MseLossBackward0>)\n",
      "495 tensor(81079.4688, grad_fn=<MseLossBackward0>)\n",
      "496 tensor(81079.3984, grad_fn=<MseLossBackward0>)\n",
      "497 tensor(81079.3203, grad_fn=<MseLossBackward0>)\n",
      "498 tensor(81079.2578, grad_fn=<MseLossBackward0>)\n",
      "499 tensor(81079.1797, grad_fn=<MseLossBackward0>)\n",
      "500 tensor(81079.1172, grad_fn=<MseLossBackward0>)\n",
      "501 tensor(81079.0547, grad_fn=<MseLossBackward0>)\n",
      "502 tensor(81078.9844, grad_fn=<MseLossBackward0>)\n",
      "503 tensor(81078.9219, grad_fn=<MseLossBackward0>)\n",
      "504 tensor(81078.8594, grad_fn=<MseLossBackward0>)\n",
      "505 tensor(81078.7969, grad_fn=<MseLossBackward0>)\n",
      "506 tensor(81078.7344, grad_fn=<MseLossBackward0>)\n",
      "507 tensor(81078.6797, grad_fn=<MseLossBackward0>)\n",
      "508 tensor(81078.6172, grad_fn=<MseLossBackward0>)\n",
      "509 tensor(81078.5547, grad_fn=<MseLossBackward0>)\n",
      "510 tensor(81078.5000, grad_fn=<MseLossBackward0>)\n",
      "511 tensor(81078.4375, grad_fn=<MseLossBackward0>)\n",
      "512 tensor(81078.3906, grad_fn=<MseLossBackward0>)\n",
      "513 tensor(81078.3359, grad_fn=<MseLossBackward0>)\n",
      "514 tensor(81078.2734, grad_fn=<MseLossBackward0>)\n",
      "515 tensor(81078.2266, grad_fn=<MseLossBackward0>)\n",
      "516 tensor(81078.1641, grad_fn=<MseLossBackward0>)\n",
      "517 tensor(81078.1172, grad_fn=<MseLossBackward0>)\n",
      "518 tensor(81078.0703, grad_fn=<MseLossBackward0>)\n",
      "519 tensor(81078.0234, grad_fn=<MseLossBackward0>)\n",
      "520 tensor(81077.9688, grad_fn=<MseLossBackward0>)\n",
      "521 tensor(81077.9141, grad_fn=<MseLossBackward0>)\n",
      "522 tensor(81077.8750, grad_fn=<MseLossBackward0>)\n",
      "523 tensor(81077.8281, grad_fn=<MseLossBackward0>)\n",
      "524 tensor(81077.7812, grad_fn=<MseLossBackward0>)\n",
      "525 tensor(81077.7188, grad_fn=<MseLossBackward0>)\n",
      "526 tensor(81077.6875, grad_fn=<MseLossBackward0>)\n",
      "527 tensor(81077.6406, grad_fn=<MseLossBackward0>)\n",
      "528 tensor(81077.6016, grad_fn=<MseLossBackward0>)\n",
      "529 tensor(81077.5547, grad_fn=<MseLossBackward0>)\n",
      "530 tensor(81077.5078, grad_fn=<MseLossBackward0>)\n",
      "531 tensor(81077.4688, grad_fn=<MseLossBackward0>)\n",
      "532 tensor(81077.4297, grad_fn=<MseLossBackward0>)\n",
      "533 tensor(81077.3906, grad_fn=<MseLossBackward0>)\n",
      "534 tensor(81077.3516, grad_fn=<MseLossBackward0>)\n",
      "535 tensor(81077.3203, grad_fn=<MseLossBackward0>)\n",
      "536 tensor(81077.2812, grad_fn=<MseLossBackward0>)\n",
      "537 tensor(81077.2422, grad_fn=<MseLossBackward0>)\n",
      "538 tensor(81077.1953, grad_fn=<MseLossBackward0>)\n",
      "539 tensor(81077.1641, grad_fn=<MseLossBackward0>)\n",
      "540 tensor(81077.1250, grad_fn=<MseLossBackward0>)\n",
      "541 tensor(81077.0938, grad_fn=<MseLossBackward0>)\n",
      "542 tensor(81077.0547, grad_fn=<MseLossBackward0>)\n",
      "543 tensor(81077.0234, grad_fn=<MseLossBackward0>)\n",
      "544 tensor(81076.9922, grad_fn=<MseLossBackward0>)\n",
      "545 tensor(81076.9453, grad_fn=<MseLossBackward0>)\n",
      "546 tensor(81076.9141, grad_fn=<MseLossBackward0>)\n",
      "547 tensor(81076.8828, grad_fn=<MseLossBackward0>)\n",
      "548 tensor(81076.8594, grad_fn=<MseLossBackward0>)\n",
      "549 tensor(81076.8281, grad_fn=<MseLossBackward0>)\n",
      "550 tensor(81076.7969, grad_fn=<MseLossBackward0>)\n",
      "551 tensor(81076.7656, grad_fn=<MseLossBackward0>)\n",
      "552 tensor(81076.7500, grad_fn=<MseLossBackward0>)\n",
      "553 tensor(81076.7031, grad_fn=<MseLossBackward0>)\n",
      "554 tensor(81076.6875, grad_fn=<MseLossBackward0>)\n",
      "555 tensor(81076.6406, grad_fn=<MseLossBackward0>)\n",
      "556 tensor(81076.6250, grad_fn=<MseLossBackward0>)\n",
      "557 tensor(81076.6016, grad_fn=<MseLossBackward0>)\n",
      "558 tensor(81076.5703, grad_fn=<MseLossBackward0>)\n",
      "559 tensor(81076.5391, grad_fn=<MseLossBackward0>)\n",
      "560 tensor(81076.5156, grad_fn=<MseLossBackward0>)\n",
      "561 tensor(81076.4844, grad_fn=<MseLossBackward0>)\n",
      "562 tensor(81076.4688, grad_fn=<MseLossBackward0>)\n",
      "563 tensor(81076.4375, grad_fn=<MseLossBackward0>)\n",
      "564 tensor(81076.4219, grad_fn=<MseLossBackward0>)\n",
      "565 tensor(81076.3906, grad_fn=<MseLossBackward0>)\n",
      "566 tensor(81076.3594, grad_fn=<MseLossBackward0>)\n",
      "567 tensor(81076.3516, grad_fn=<MseLossBackward0>)\n",
      "568 tensor(81076.3203, grad_fn=<MseLossBackward0>)\n",
      "569 tensor(81076.3047, grad_fn=<MseLossBackward0>)\n",
      "570 tensor(81076.2734, grad_fn=<MseLossBackward0>)\n",
      "571 tensor(81076.2578, grad_fn=<MseLossBackward0>)\n",
      "572 tensor(81076.2344, grad_fn=<MseLossBackward0>)\n",
      "573 tensor(81076.2109, grad_fn=<MseLossBackward0>)\n",
      "574 tensor(81076.1953, grad_fn=<MseLossBackward0>)\n",
      "575 tensor(81076.1719, grad_fn=<MseLossBackward0>)\n",
      "576 tensor(81076.1562, grad_fn=<MseLossBackward0>)\n",
      "577 tensor(81076.1328, grad_fn=<MseLossBackward0>)\n",
      "578 tensor(81076.1094, grad_fn=<MseLossBackward0>)\n",
      "579 tensor(81076.0938, grad_fn=<MseLossBackward0>)\n",
      "580 tensor(81076.0703, grad_fn=<MseLossBackward0>)\n",
      "581 tensor(81076.0547, grad_fn=<MseLossBackward0>)\n",
      "582 tensor(81076.0312, grad_fn=<MseLossBackward0>)\n",
      "583 tensor(81076.0234, grad_fn=<MseLossBackward0>)\n",
      "584 tensor(81075.9922, grad_fn=<MseLossBackward0>)\n",
      "585 tensor(81075.9922, grad_fn=<MseLossBackward0>)\n",
      "586 tensor(81075.9609, grad_fn=<MseLossBackward0>)\n",
      "587 tensor(81075.9453, grad_fn=<MseLossBackward0>)\n",
      "588 tensor(81075.9297, grad_fn=<MseLossBackward0>)\n",
      "589 tensor(81075.9141, grad_fn=<MseLossBackward0>)\n",
      "590 tensor(81075.8984, grad_fn=<MseLossBackward0>)\n",
      "591 tensor(81075.8828, grad_fn=<MseLossBackward0>)\n",
      "592 tensor(81075.8672, grad_fn=<MseLossBackward0>)\n",
      "593 tensor(81075.8516, grad_fn=<MseLossBackward0>)\n",
      "594 tensor(81075.8438, grad_fn=<MseLossBackward0>)\n",
      "595 tensor(81075.8281, grad_fn=<MseLossBackward0>)\n",
      "596 tensor(81075.8125, grad_fn=<MseLossBackward0>)\n",
      "597 tensor(81075.8047, grad_fn=<MseLossBackward0>)\n",
      "598 tensor(81075.7812, grad_fn=<MseLossBackward0>)\n",
      "599 tensor(81075.7656, grad_fn=<MseLossBackward0>)\n",
      "600 tensor(81075.7500, grad_fn=<MseLossBackward0>)\n",
      "601 tensor(81075.7422, grad_fn=<MseLossBackward0>)\n",
      "602 tensor(81075.7344, grad_fn=<MseLossBackward0>)\n",
      "603 tensor(81075.7188, grad_fn=<MseLossBackward0>)\n",
      "604 tensor(81075.7031, grad_fn=<MseLossBackward0>)\n",
      "605 tensor(81075.6875, grad_fn=<MseLossBackward0>)\n",
      "606 tensor(81075.6797, grad_fn=<MseLossBackward0>)\n",
      "607 tensor(81075.6641, grad_fn=<MseLossBackward0>)\n",
      "608 tensor(81075.6562, grad_fn=<MseLossBackward0>)\n",
      "609 tensor(81075.6406, grad_fn=<MseLossBackward0>)\n",
      "610 tensor(81075.6328, grad_fn=<MseLossBackward0>)\n",
      "611 tensor(81075.6172, grad_fn=<MseLossBackward0>)\n",
      "612 tensor(81075.6094, grad_fn=<MseLossBackward0>)\n",
      "613 tensor(81075.6016, grad_fn=<MseLossBackward0>)\n",
      "614 tensor(81075.5938, grad_fn=<MseLossBackward0>)\n",
      "615 tensor(81075.5703, grad_fn=<MseLossBackward0>)\n",
      "616 tensor(81075.5625, grad_fn=<MseLossBackward0>)\n",
      "617 tensor(81075.5625, grad_fn=<MseLossBackward0>)\n",
      "618 tensor(81075.5469, grad_fn=<MseLossBackward0>)\n",
      "619 tensor(81075.5391, grad_fn=<MseLossBackward0>)\n",
      "620 tensor(81075.5312, grad_fn=<MseLossBackward0>)\n",
      "621 tensor(81075.5156, grad_fn=<MseLossBackward0>)\n",
      "622 tensor(81075.5078, grad_fn=<MseLossBackward0>)\n",
      "623 tensor(81075.5000, grad_fn=<MseLossBackward0>)\n",
      "624 tensor(81075.4844, grad_fn=<MseLossBackward0>)\n",
      "625 tensor(81075.4844, grad_fn=<MseLossBackward0>)\n",
      "626 tensor(81075.4688, grad_fn=<MseLossBackward0>)\n",
      "627 tensor(81075.4688, grad_fn=<MseLossBackward0>)\n",
      "628 tensor(81075.4531, grad_fn=<MseLossBackward0>)\n",
      "629 tensor(81075.4453, grad_fn=<MseLossBackward0>)\n",
      "630 tensor(81075.4375, grad_fn=<MseLossBackward0>)\n",
      "631 tensor(81075.4219, grad_fn=<MseLossBackward0>)\n",
      "632 tensor(81075.4219, grad_fn=<MseLossBackward0>)\n",
      "633 tensor(81075.4141, grad_fn=<MseLossBackward0>)\n",
      "634 tensor(81075.4062, grad_fn=<MseLossBackward0>)\n",
      "635 tensor(81075.3906, grad_fn=<MseLossBackward0>)\n",
      "636 tensor(81075.3906, grad_fn=<MseLossBackward0>)\n",
      "637 tensor(81075.3828, grad_fn=<MseLossBackward0>)\n",
      "638 tensor(81075.3750, grad_fn=<MseLossBackward0>)\n",
      "639 tensor(81075.3750, grad_fn=<MseLossBackward0>)\n",
      "640 tensor(81075.3594, grad_fn=<MseLossBackward0>)\n",
      "641 tensor(81075.3516, grad_fn=<MseLossBackward0>)\n",
      "642 tensor(81075.3438, grad_fn=<MseLossBackward0>)\n",
      "643 tensor(81075.3438, grad_fn=<MseLossBackward0>)\n",
      "644 tensor(81075.3359, grad_fn=<MseLossBackward0>)\n",
      "645 tensor(81075.3203, grad_fn=<MseLossBackward0>)\n",
      "646 tensor(81075.3203, grad_fn=<MseLossBackward0>)\n",
      "647 tensor(81075.3203, grad_fn=<MseLossBackward0>)\n",
      "648 tensor(81075.3203, grad_fn=<MseLossBackward0>)\n",
      "649 tensor(81075.3125, grad_fn=<MseLossBackward0>)\n",
      "650 tensor(81075.3047, grad_fn=<MseLossBackward0>)\n",
      "651 tensor(81075.3047, grad_fn=<MseLossBackward0>)\n",
      "652 tensor(81075.2891, grad_fn=<MseLossBackward0>)\n",
      "653 tensor(81075.2891, grad_fn=<MseLossBackward0>)\n",
      "654 tensor(81075.2812, grad_fn=<MseLossBackward0>)\n",
      "655 tensor(81075.2734, grad_fn=<MseLossBackward0>)\n",
      "656 tensor(81075.2578, grad_fn=<MseLossBackward0>)\n",
      "657 tensor(81075.2578, grad_fn=<MseLossBackward0>)\n",
      "658 tensor(81075.2578, grad_fn=<MseLossBackward0>)\n",
      "659 tensor(81075.2578, grad_fn=<MseLossBackward0>)\n",
      "660 tensor(81075.2578, grad_fn=<MseLossBackward0>)\n",
      "661 tensor(81075.2422, grad_fn=<MseLossBackward0>)\n",
      "662 tensor(81075.2422, grad_fn=<MseLossBackward0>)\n",
      "663 tensor(81075.2266, grad_fn=<MseLossBackward0>)\n",
      "664 tensor(81075.2266, grad_fn=<MseLossBackward0>)\n",
      "665 tensor(81075.2266, grad_fn=<MseLossBackward0>)\n",
      "666 tensor(81075.2188, grad_fn=<MseLossBackward0>)\n",
      "667 tensor(81075.2109, grad_fn=<MseLossBackward0>)\n",
      "668 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "669 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "670 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "671 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "672 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "673 tensor(81075.1953, grad_fn=<MseLossBackward0>)\n",
      "674 tensor(81075.1875, grad_fn=<MseLossBackward0>)\n",
      "675 tensor(81075.1875, grad_fn=<MseLossBackward0>)\n",
      "676 tensor(81075.1797, grad_fn=<MseLossBackward0>)\n",
      "677 tensor(81075.1797, grad_fn=<MseLossBackward0>)\n",
      "678 tensor(81075.1719, grad_fn=<MseLossBackward0>)\n",
      "679 tensor(81075.1641, grad_fn=<MseLossBackward0>)\n",
      "680 tensor(81075.1641, grad_fn=<MseLossBackward0>)\n",
      "681 tensor(81075.1562, grad_fn=<MseLossBackward0>)\n",
      "682 tensor(81075.1562, grad_fn=<MseLossBackward0>)\n",
      "683 tensor(81075.1562, grad_fn=<MseLossBackward0>)\n",
      "684 tensor(81075.1484, grad_fn=<MseLossBackward0>)\n",
      "685 tensor(81075.1484, grad_fn=<MseLossBackward0>)\n",
      "686 tensor(81075.1484, grad_fn=<MseLossBackward0>)\n",
      "687 tensor(81075.1406, grad_fn=<MseLossBackward0>)\n",
      "688 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "689 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "690 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "691 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "692 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "693 tensor(81075.1328, grad_fn=<MseLossBackward0>)\n",
      "694 tensor(81075.1172, grad_fn=<MseLossBackward0>)\n",
      "695 tensor(81075.1172, grad_fn=<MseLossBackward0>)\n",
      "696 tensor(81075.1172, grad_fn=<MseLossBackward0>)\n",
      "697 tensor(81075.1094, grad_fn=<MseLossBackward0>)\n",
      "698 tensor(81075.1094, grad_fn=<MseLossBackward0>)\n",
      "699 tensor(81075.1094, grad_fn=<MseLossBackward0>)\n",
      "700 tensor(81075.1016, grad_fn=<MseLossBackward0>)\n",
      "701 tensor(81075.1016, grad_fn=<MseLossBackward0>)\n",
      "702 tensor(81075.1016, grad_fn=<MseLossBackward0>)\n",
      "703 tensor(81075.0938, grad_fn=<MseLossBackward0>)\n",
      "704 tensor(81075.0859, grad_fn=<MseLossBackward0>)\n",
      "705 tensor(81075.0859, grad_fn=<MseLossBackward0>)\n",
      "706 tensor(81075.0859, grad_fn=<MseLossBackward0>)\n",
      "707 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "708 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "709 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "710 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "711 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "712 tensor(81075.0781, grad_fn=<MseLossBackward0>)\n",
      "713 tensor(81075.0703, grad_fn=<MseLossBackward0>)\n",
      "714 tensor(81075.0703, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\shrinkage_prior.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# test_out = model(test_data)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# test_loss = F.mse_loss(test_out, test_data.y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# test_loss_l.append(test_loss.item())\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mprint\u001b[39m(epoch, train_loss)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m train_loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "train_data = ssp_obj.train_data.to(device)\n",
    "# test_data = ssp_obj.test_data.to(device)\n",
    "train_loss_l = []\n",
    "# test_loss_l = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(8000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    train_loss = F.mse_loss(out, train_data.y)\n",
    "    train_loss_l.append(train_loss.item())\n",
    "\n",
    "    # test_out = model(test_data)\n",
    "    # test_loss = F.mse_loss(test_out, test_data.y)\n",
    "    # test_loss_l.append(test_loss.item())\n",
    "\n",
    "    print(epoch, train_loss)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.3809e-01,  3.3799e-01,  3.3893e-01,  ..., -7.2965e-16,\n",
       "        -1.0928e-15, -1.0801e-15], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_final', 'wb')\n",
    "pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_final', 'rb')\n",
    "model_final = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN(\n",
       "  (conv1): GCNConv(-1, 36)\n",
       "  (conv2): GCNConv(36, 163800)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_12920\\938135185.py:3: UserWarning: Using a target size (torch.Size([163800])) that is different to the input size (torch.Size([39, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  train_loss = F.mse_loss(out, train_data.y)\n"
     ]
    }
   ],
   "source": [
    "train_data = ssp_obj.test_data\n",
    "out = model_final(train_data)\n",
    "train_loss = F.mse_loss(out, train_data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2394aa599a0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_l[50:], label='train')\n",
    "# plt.plot(test_loss_l[50:], label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model', 'rb')\n",
    "model = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_undirected', 'rb')\n",
    "model_undirected = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_undirected.edge_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(38**2 + 38) /2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.9519e-41, 1.9519e-41, 1.9519e-41,  ..., 1.9519e-41, 1.9519e-41,\n",
       "        1.9519e-41], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.edge_weight\n",
    "m = torch.zeros((39, 39))\n",
    "\n",
    "tril_indices = torch.tril_indices(row=39, col=39, offset=-1)\n",
    "triu_indices = torch.triu_indices(row=39, col=39, offset=1)\n",
    "m[triu_indices[0], triu_indices[1]] = x[:741]\n",
    "m[tril_indices[0], tril_indices[1]] = x[741:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x[741:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.4528,  1.3907,  ...,  1.4542,  1.3883,  1.3875],\n",
       "        [-3.0840,  0.0000,  1.1087,  ...,  1.1054,  1.1112,  1.0077],\n",
       "        [-3.0444, -3.1403,  0.0000,  ..., -2.9051, -2.7570, -2.7979],\n",
       "        ...,\n",
       "        [ 1.1960,  1.1942,  1.3180,  ...,  0.0000, -3.1409, -3.1400],\n",
       "        [ 3.4998, -3.3875, -3.3894,  ..., -3.3700,  0.0000, -3.1404],\n",
       "        [ 3.2827,  3.2811, -3.2070,  ...,  3.2826,  3.2251,  0.0000]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.4073, 0.0000, 0.5439,  ..., 0.5488, 0.5494, 0.5484],\n",
       "        [0.3927, 0.3941, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.9420, 0.9399, 0.9387,  ..., 0.0000, 0.4168, 0.3906],\n",
       "        [0.1002, 0.0000, 0.0000,  ..., 0.0424, 0.0000, 0.4158],\n",
       "        [0.4277, 0.4405, 0.4262,  ..., 0.4413, 0.4366, 0.0000]],\n",
       "       grad_fn=<IndexPutBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = m.clone()\n",
    "m1[m1.abs()<=1e-4] = 0\n",
    "m1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "t_np = m.detach().numpy() #convert to Numpy array\n",
    "df = pd.DataFrame(t_np) #convert to a dataframe\n",
    "df.to_csv(\"model_final_edgeweights.csv\",index=False) #save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.380936e-01</td>\n",
       "      <td>3.379887e-01</td>\n",
       "      <td>3.389341e-01</td>\n",
       "      <td>3.380899e-01</td>\n",
       "      <td>3.381739e-01</td>\n",
       "      <td>3.379431e-01</td>\n",
       "      <td>3.381668e-01</td>\n",
       "      <td>3.380589e-01</td>\n",
       "      <td>3.380114e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.389804e-01</td>\n",
       "      <td>3.379148e-01</td>\n",
       "      <td>3.378848e-01</td>\n",
       "      <td>3.380631e-01</td>\n",
       "      <td>3.381649e-01</td>\n",
       "      <td>3.389567e-01</td>\n",
       "      <td>3.388908e-01</td>\n",
       "      <td>3.389931e-01</td>\n",
       "      <td>3.381746e-01</td>\n",
       "      <td>3.380238e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.264789e-17</td>\n",
       "      <td>-2.276906e-17</td>\n",
       "      <td>-8.266973e-17</td>\n",
       "      <td>1.397577e-17</td>\n",
       "      <td>1.519550e-16</td>\n",
       "      <td>-7.741029e-17</td>\n",
       "      <td>-5.852152e-17</td>\n",
       "      <td>-2.564688e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.584123e-16</td>\n",
       "      <td>1.519494e-18</td>\n",
       "      <td>1.138338e-16</td>\n",
       "      <td>-5.539764e-17</td>\n",
       "      <td>-1.638700e-17</td>\n",
       "      <td>-4.994560e-17</td>\n",
       "      <td>-1.568154e-16</td>\n",
       "      <td>-1.660729e-16</td>\n",
       "      <td>-1.307816e-16</td>\n",
       "      <td>-9.889061e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.081637e-16</td>\n",
       "      <td>-5.981408e-17</td>\n",
       "      <td>-1.112302e-16</td>\n",
       "      <td>-1.078852e-17</td>\n",
       "      <td>-9.367875e-17</td>\n",
       "      <td>1.010828e-16</td>\n",
       "      <td>-1.146344e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>9.173442e-17</td>\n",
       "      <td>-6.492373e-17</td>\n",
       "      <td>-2.723410e-17</td>\n",
       "      <td>-9.754714e-17</td>\n",
       "      <td>7.342678e-17</td>\n",
       "      <td>1.116742e-16</td>\n",
       "      <td>-1.038701e-16</td>\n",
       "      <td>2.464274e-17</td>\n",
       "      <td>-1.117505e-16</td>\n",
       "      <td>1.003868e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-1.094153e-16</td>\n",
       "      <td>-1.431787e-18</td>\n",
       "      <td>-3.594433e-17</td>\n",
       "      <td>1.455652e+00</td>\n",
       "      <td>1.455694e+00</td>\n",
       "      <td>1.455698e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455695e+00</td>\n",
       "      <td>1.455652e+00</td>\n",
       "      <td>1.455697e+00</td>\n",
       "      <td>1.455698e+00</td>\n",
       "      <td>1.455699e+00</td>\n",
       "      <td>1.455658e+00</td>\n",
       "      <td>1.455654e+00</td>\n",
       "      <td>1.455654e+00</td>\n",
       "      <td>1.455652e+00</td>\n",
       "      <td>1.455696e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>1.455798e+00</td>\n",
       "      <td>1.455788e+00</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455697e+00</td>\n",
       "      <td>1.455655e+00</td>\n",
       "      <td>1.455656e+00</td>\n",
       "      <td>1.455654e+00</td>\n",
       "      <td>1.455695e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.081697e-16</td>\n",
       "      <td>8.487760e-17</td>\n",
       "      <td>-3.389900e-17</td>\n",
       "      <td>-1.039835e-16</td>\n",
       "      <td>-5.452874e-19</td>\n",
       "      <td>-1.056759e-16</td>\n",
       "      <td>4.571619e-17</td>\n",
       "      <td>-3.635393e-18</td>\n",
       "      <td>4.355314e-17</td>\n",
       "      <td>1.019608e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-8.883402e-17</td>\n",
       "      <td>-4.248173e-17</td>\n",
       "      <td>-1.100898e-16</td>\n",
       "      <td>2.120933e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.191731e-16</td>\n",
       "      <td>-4.854735e-17</td>\n",
       "      <td>-3.657205e-16</td>\n",
       "      <td>8.739392e-17</td>\n",
       "      <td>-6.127719e-16</td>\n",
       "      <td>1.739673e-16</td>\n",
       "      <td>-5.155946e-16</td>\n",
       "      <td>3.253659e-16</td>\n",
       "      <td>1.149268e-17</td>\n",
       "      <td>-1.700703e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>3.489459e-01</td>\n",
       "      <td>3.501279e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.953269e-16</td>\n",
       "      <td>-4.541706e-16</td>\n",
       "      <td>-1.084324e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>3.383787e-01</td>\n",
       "      <td>3.383615e-01</td>\n",
       "      <td>3.382569e-01</td>\n",
       "      <td>3.384507e-01</td>\n",
       "      <td>3.391536e-01</td>\n",
       "      <td>3.380173e-01</td>\n",
       "      <td>3.382829e-01</td>\n",
       "      <td>3.383028e-01</td>\n",
       "      <td>3.381111e-01</td>\n",
       "      <td>3.384517e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.502276e-01</td>\n",
       "      <td>3.495984e-01</td>\n",
       "      <td>3.502090e-01</td>\n",
       "      <td>3.501786e-01</td>\n",
       "      <td>3.489642e-01</td>\n",
       "      <td>3.501007e-01</td>\n",
       "      <td>3.501691e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.380382e-01</td>\n",
       "      <td>3.392220e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>4.746729e-17</td>\n",
       "      <td>7.934005e-17</td>\n",
       "      <td>8.515143e-17</td>\n",
       "      <td>-4.341651e-17</td>\n",
       "      <td>-3.603314e-17</td>\n",
       "      <td>-7.385548e-17</td>\n",
       "      <td>2.205330e-17</td>\n",
       "      <td>-8.145809e-17</td>\n",
       "      <td>-6.405159e-17</td>\n",
       "      <td>8.299182e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.502460e-01</td>\n",
       "      <td>3.501448e-01</td>\n",
       "      <td>3.501879e-01</td>\n",
       "      <td>3.495324e-01</td>\n",
       "      <td>3.489222e-01</td>\n",
       "      <td>3.501304e-01</td>\n",
       "      <td>3.501818e-01</td>\n",
       "      <td>3.489332e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-6.436151e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.556559e-17</td>\n",
       "      <td>8.002156e-17</td>\n",
       "      <td>-3.439884e-17</td>\n",
       "      <td>8.730762e-17</td>\n",
       "      <td>-6.678595e-17</td>\n",
       "      <td>3.753920e-17</td>\n",
       "      <td>-7.485077e-17</td>\n",
       "      <td>-7.164270e-17</td>\n",
       "      <td>-1.260545e-16</td>\n",
       "      <td>-1.310180e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.502010e-01</td>\n",
       "      <td>3.489465e-01</td>\n",
       "      <td>3.496193e-01</td>\n",
       "      <td>3.496123e-01</td>\n",
       "      <td>3.489270e-01</td>\n",
       "      <td>3.500915e-01</td>\n",
       "      <td>3.488952e-01</td>\n",
       "      <td>3.502184e-01</td>\n",
       "      <td>3.501343e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.335568e-16</td>\n",
       "      <td>1.272296e-16</td>\n",
       "      <td>-6.756040e-17</td>\n",
       "      <td>-8.143565e-17</td>\n",
       "      <td>1.223758e-16</td>\n",
       "      <td>-1.148016e-16</td>\n",
       "      <td>-2.181992e-17</td>\n",
       "      <td>-1.312996e-16</td>\n",
       "      <td>-1.349140e-16</td>\n",
       "      <td>-1.305739e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.502131e-01</td>\n",
       "      <td>3.496836e-01</td>\n",
       "      <td>3.496394e-01</td>\n",
       "      <td>3.489247e-01</td>\n",
       "      <td>3.489395e-01</td>\n",
       "      <td>3.501737e-01</td>\n",
       "      <td>3.501755e-01</td>\n",
       "      <td>3.496205e-01</td>\n",
       "      <td>3.496305e-01</td>\n",
       "      <td>3.496412e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.265673e-16</td>\n",
       "      <td>-1.537213e-16</td>\n",
       "      <td>-5.263211e-16</td>\n",
       "      <td>-5.278148e-16</td>\n",
       "      <td>-4.198308e-16</td>\n",
       "      <td>-3.324988e-16</td>\n",
       "      <td>-3.293825e-16</td>\n",
       "      <td>-2.323306e-16</td>\n",
       "      <td>-5.657400e-16</td>\n",
       "      <td>-4.610225e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.501096e-01</td>\n",
       "      <td>3.501700e-01</td>\n",
       "      <td>1.455707e+00</td>\n",
       "      <td>1.455730e+00</td>\n",
       "      <td>1.455733e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455730e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455733e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.686744e-15</td>\n",
       "      <td>8.638382e-15</td>\n",
       "      <td>8.290972e-15</td>\n",
       "      <td>8.791719e-15</td>\n",
       "      <td>8.411993e-15</td>\n",
       "      <td>8.100027e-15</td>\n",
       "      <td>8.485926e-15</td>\n",
       "      <td>7.740832e-15</td>\n",
       "      <td>8.114056e-15</td>\n",
       "      <td>8.169729e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455733e+00</td>\n",
       "      <td>1.455729e+00</td>\n",
       "      <td>1.455704e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455731e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455707e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.082872e-15</td>\n",
       "      <td>8.292655e-15</td>\n",
       "      <td>8.629567e-15</td>\n",
       "      <td>8.684439e-15</td>\n",
       "      <td>8.834426e-15</td>\n",
       "      <td>8.316832e-15</td>\n",
       "      <td>7.676871e-15</td>\n",
       "      <td>8.477289e-15</td>\n",
       "      <td>8.657762e-15</td>\n",
       "      <td>8.424713e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.455707e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455734e+00</td>\n",
       "      <td>1.455708e+00</td>\n",
       "      <td>1.455705e+00</td>\n",
       "      <td>1.455708e+00</td>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.244809e-14</td>\n",
       "      <td>5.253294e-14</td>\n",
       "      <td>5.246448e-14</td>\n",
       "      <td>5.256075e-14</td>\n",
       "      <td>5.075188e-14</td>\n",
       "      <td>5.210585e-14</td>\n",
       "      <td>5.132517e-14</td>\n",
       "      <td>5.201953e-14</td>\n",
       "      <td>5.185842e-14</td>\n",
       "      <td>5.251869e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.455706e+00</td>\n",
       "      <td>1.455707e+00</td>\n",
       "      <td>1.455732e+00</td>\n",
       "      <td>1.455731e+00</td>\n",
       "      <td>3.393088e-01</td>\n",
       "      <td>3.396507e-01</td>\n",
       "      <td>3.395580e-01</td>\n",
       "      <td>3.400970e-01</td>\n",
       "      <td>3.396836e-01</td>\n",
       "      <td>3.397031e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.254955e-14</td>\n",
       "      <td>1.452613e+00</td>\n",
       "      <td>1.454956e+00</td>\n",
       "      <td>1.455014e+00</td>\n",
       "      <td>1.450480e+00</td>\n",
       "      <td>1.454963e+00</td>\n",
       "      <td>1.454995e+00</td>\n",
       "      <td>1.452460e+00</td>\n",
       "      <td>1.454987e+00</td>\n",
       "      <td>1.454957e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.396914e-01</td>\n",
       "      <td>3.396244e-01</td>\n",
       "      <td>3.401741e-01</td>\n",
       "      <td>3.393255e-01</td>\n",
       "      <td>3.396999e-01</td>\n",
       "      <td>3.395622e-01</td>\n",
       "      <td>3.393539e-01</td>\n",
       "      <td>3.396464e-01</td>\n",
       "      <td>3.393015e-01</td>\n",
       "      <td>3.401915e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455042e+00</td>\n",
       "      <td>1.452122e+00</td>\n",
       "      <td>1.455049e+00</td>\n",
       "      <td>1.455002e+00</td>\n",
       "      <td>1.455137e+00</td>\n",
       "      <td>1.451702e+00</td>\n",
       "      <td>1.449524e+00</td>\n",
       "      <td>1.452971e+00</td>\n",
       "      <td>1.452079e+00</td>\n",
       "      <td>1.455016e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.395271e-01</td>\n",
       "      <td>3.396504e-01</td>\n",
       "      <td>3.402351e-01</td>\n",
       "      <td>3.401795e-01</td>\n",
       "      <td>3.393112e-01</td>\n",
       "      <td>3.393238e-01</td>\n",
       "      <td>3.395988e-01</td>\n",
       "      <td>3.397160e-01</td>\n",
       "      <td>3.401707e-01</td>\n",
       "      <td>3.400929e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.385845e-01</td>\n",
       "      <td>3.389156e-01</td>\n",
       "      <td>3.388899e-01</td>\n",
       "      <td>3.388650e-01</td>\n",
       "      <td>3.388893e-01</td>\n",
       "      <td>3.389354e-01</td>\n",
       "      <td>3.395714e-01</td>\n",
       "      <td>3.389086e-01</td>\n",
       "      <td>3.387950e-01</td>\n",
       "      <td>3.386038e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.508412e-16</td>\n",
       "      <td>1.519538e-16</td>\n",
       "      <td>1.498381e-16</td>\n",
       "      <td>1.189606e-16</td>\n",
       "      <td>2.199558e-17</td>\n",
       "      <td>8.166801e-17</td>\n",
       "      <td>1.516733e-16</td>\n",
       "      <td>1.280193e-16</td>\n",
       "      <td>-3.500326e-17</td>\n",
       "      <td>-7.558618e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.396497e-01</td>\n",
       "      <td>3.396034e-01</td>\n",
       "      <td>3.385830e-01</td>\n",
       "      <td>3.385865e-01</td>\n",
       "      <td>3.388240e-01</td>\n",
       "      <td>3.389423e-01</td>\n",
       "      <td>3.395862e-01</td>\n",
       "      <td>3.395131e-01</td>\n",
       "      <td>3.396243e-01</td>\n",
       "      <td>3.389534e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.504647e-16</td>\n",
       "      <td>1.490647e-16</td>\n",
       "      <td>1.399598e-16</td>\n",
       "      <td>5.749521e-17</td>\n",
       "      <td>1.264373e-16</td>\n",
       "      <td>3.111825e-17</td>\n",
       "      <td>9.990150e-17</td>\n",
       "      <td>9.254857e-17</td>\n",
       "      <td>1.389366e-16</td>\n",
       "      <td>1.339504e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.867858e-16</td>\n",
       "      <td>1.978064e-16</td>\n",
       "      <td>7.291097e-17</td>\n",
       "      <td>7.402949e-17</td>\n",
       "      <td>8.034222e-17</td>\n",
       "      <td>1.911201e-16</td>\n",
       "      <td>1.703514e-16</td>\n",
       "      <td>9.706314e-17</td>\n",
       "      <td>1.721545e-16</td>\n",
       "      <td>9.612674e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.521721e-01</td>\n",
       "      <td>3.546255e-01</td>\n",
       "      <td>3.547919e-01</td>\n",
       "      <td>3.531517e-01</td>\n",
       "      <td>3.548256e-01</td>\n",
       "      <td>3.548767e-01</td>\n",
       "      <td>3.522646e-01</td>\n",
       "      <td>3.547195e-01</td>\n",
       "      <td>3.545526e-01</td>\n",
       "      <td>3.548577e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.656044e-16</td>\n",
       "      <td>7.170833e-17</td>\n",
       "      <td>8.925018e-17</td>\n",
       "      <td>1.783492e-16</td>\n",
       "      <td>1.988216e-16</td>\n",
       "      <td>1.947320e-16</td>\n",
       "      <td>1.256947e-16</td>\n",
       "      <td>2.007035e-16</td>\n",
       "      <td>1.992291e-16</td>\n",
       "      <td>1.753032e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.531602e-01</td>\n",
       "      <td>3.521586e-01</td>\n",
       "      <td>3.532330e-01</td>\n",
       "      <td>3.521000e-01</td>\n",
       "      <td>3.548444e-01</td>\n",
       "      <td>3.549597e-01</td>\n",
       "      <td>3.548162e-01</td>\n",
       "      <td>3.552374e-01</td>\n",
       "      <td>3.533176e-01</td>\n",
       "      <td>3.531608e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>6.209304e-17</td>\n",
       "      <td>1.704270e-18</td>\n",
       "      <td>6.160297e-17</td>\n",
       "      <td>-1.541823e-16</td>\n",
       "      <td>-1.531877e-16</td>\n",
       "      <td>-1.793392e-16</td>\n",
       "      <td>9.239071e-18</td>\n",
       "      <td>-2.843482e-17</td>\n",
       "      <td>-1.737112e-16</td>\n",
       "      <td>-2.945718e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-4.688853e-17</td>\n",
       "      <td>6.806628e-17</td>\n",
       "      <td>-7.205320e-17</td>\n",
       "      <td>7.393530e-17</td>\n",
       "      <td>2.656376e-17</td>\n",
       "      <td>1.260746e-18</td>\n",
       "      <td>1.899531e-16</td>\n",
       "      <td>1.750643e-16</td>\n",
       "      <td>8.169404e-17</td>\n",
       "      <td>8.654098e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>1.677554e-16</td>\n",
       "      <td>1.044926e-16</td>\n",
       "      <td>1.100672e-16</td>\n",
       "      <td>-6.425736e-17</td>\n",
       "      <td>-1.220332e-16</td>\n",
       "      <td>-1.296682e-16</td>\n",
       "      <td>3.391752e-18</td>\n",
       "      <td>1.875252e-16</td>\n",
       "      <td>5.252686e-17</td>\n",
       "      <td>-7.614985e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.853343e-19</td>\n",
       "      <td>2.727098e-17</td>\n",
       "      <td>-7.330630e-17</td>\n",
       "      <td>1.206750e-16</td>\n",
       "      <td>1.362276e-16</td>\n",
       "      <td>6.829965e-17</td>\n",
       "      <td>-2.088143e-17</td>\n",
       "      <td>-3.561623e-17</td>\n",
       "      <td>-3.973848e-17</td>\n",
       "      <td>4.951489e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.408571e-01</td>\n",
       "      <td>3.405513e-01</td>\n",
       "      <td>3.405544e-01</td>\n",
       "      <td>3.401801e-01</td>\n",
       "      <td>3.405039e-01</td>\n",
       "      <td>3.405450e-01</td>\n",
       "      <td>3.405546e-01</td>\n",
       "      <td>3.404964e-01</td>\n",
       "      <td>3.405882e-01</td>\n",
       "      <td>3.408186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-3.446347e-17</td>\n",
       "      <td>3.666046e-16</td>\n",
       "      <td>-2.040859e-16</td>\n",
       "      <td>-5.598592e-16</td>\n",
       "      <td>9.019064e-17</td>\n",
       "      <td>-8.396935e-17</td>\n",
       "      <td>-3.430514e-16</td>\n",
       "      <td>-4.113867e-16</td>\n",
       "      <td>4.504269e-16</td>\n",
       "      <td>3.302409e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>3.408724e-01</td>\n",
       "      <td>3.401736e-01</td>\n",
       "      <td>3.408602e-01</td>\n",
       "      <td>3.401356e-01</td>\n",
       "      <td>3.405043e-01</td>\n",
       "      <td>3.401962e-01</td>\n",
       "      <td>3.405482e-01</td>\n",
       "      <td>3.404519e-01</td>\n",
       "      <td>3.405025e-01</td>\n",
       "      <td>3.408804e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.357560e-16</td>\n",
       "      <td>-2.589151e-16</td>\n",
       "      <td>-8.810900e-17</td>\n",
       "      <td>2.297098e-16</td>\n",
       "      <td>-5.859985e-16</td>\n",
       "      <td>3.543287e-16</td>\n",
       "      <td>-6.537923e-16</td>\n",
       "      <td>-7.734759e-16</td>\n",
       "      <td>4.941606e-16</td>\n",
       "      <td>6.778746e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>3.405237e-01</td>\n",
       "      <td>3.408601e-01</td>\n",
       "      <td>3.408664e-01</td>\n",
       "      <td>3.408650e-01</td>\n",
       "      <td>3.405228e-01</td>\n",
       "      <td>3.405105e-01</td>\n",
       "      <td>-7.592124e-17</td>\n",
       "      <td>-8.194743e-17</td>\n",
       "      <td>-1.870599e-17</td>\n",
       "      <td>8.690791e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-9.168805e-17</td>\n",
       "      <td>4.601256e-17</td>\n",
       "      <td>5.282785e-17</td>\n",
       "      <td>1.337722e-17</td>\n",
       "      <td>8.695499e-17</td>\n",
       "      <td>-9.371275e-17</td>\n",
       "      <td>-1.595705e-17</td>\n",
       "      <td>5.217646e-17</td>\n",
       "      <td>5.192435e-17</td>\n",
       "      <td>8.887386e-17</td>\n",
       "      <td>...</td>\n",
       "      <td>5.519543e-17</td>\n",
       "      <td>-2.849123e-17</td>\n",
       "      <td>3.707686e-17</td>\n",
       "      <td>8.220212e-17</td>\n",
       "      <td>-4.933628e-18</td>\n",
       "      <td>-8.561384e-17</td>\n",
       "      <td>-7.702188e-17</td>\n",
       "      <td>-7.658110e-17</td>\n",
       "      <td>-2.297982e-17</td>\n",
       "      <td>-8.196041e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.455380e+00</td>\n",
       "      <td>1.454887e+00</td>\n",
       "      <td>1.455371e+00</td>\n",
       "      <td>1.455361e+00</td>\n",
       "      <td>1.454853e+00</td>\n",
       "      <td>1.455364e+00</td>\n",
       "      <td>1.455379e+00</td>\n",
       "      <td>1.455381e+00</td>\n",
       "      <td>1.455374e+00</td>\n",
       "      <td>1.455367e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>8.392966e-17</td>\n",
       "      <td>-1.446715e-17</td>\n",
       "      <td>4.044008e-17</td>\n",
       "      <td>1.995331e-17</td>\n",
       "      <td>-7.831377e-17</td>\n",
       "      <td>8.283826e-17</td>\n",
       "      <td>-1.788392e-17</td>\n",
       "      <td>4.051473e-17</td>\n",
       "      <td>-4.592002e-17</td>\n",
       "      <td>7.925250e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.454936e+00</td>\n",
       "      <td>1.454815e+00</td>\n",
       "      <td>1.454790e+00</td>\n",
       "      <td>1.455351e+00</td>\n",
       "      <td>1.455379e+00</td>\n",
       "      <td>1.454893e+00</td>\n",
       "      <td>1.454883e+00</td>\n",
       "      <td>1.454936e+00</td>\n",
       "      <td>1.455361e+00</td>\n",
       "      <td>1.455354e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.559581e-17</td>\n",
       "      <td>1.233005e-17</td>\n",
       "      <td>1.886367e-17</td>\n",
       "      <td>2.635013e-17</td>\n",
       "      <td>4.669320e-17</td>\n",
       "      <td>-7.814216e-17</td>\n",
       "      <td>6.819877e-17</td>\n",
       "      <td>5.931619e-17</td>\n",
       "      <td>3.415999e-01</td>\n",
       "      <td>3.419475e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.455809e+00</td>\n",
       "      <td>1.455800e+00</td>\n",
       "      <td>1.455799e+00</td>\n",
       "      <td>1.455801e+00</td>\n",
       "      <td>1.455799e+00</td>\n",
       "      <td>1.455800e+00</td>\n",
       "      <td>1.455810e+00</td>\n",
       "      <td>1.455799e+00</td>\n",
       "      <td>1.455810e+00</td>\n",
       "      <td>1.455811e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.419385e-01</td>\n",
       "      <td>3.420704e-01</td>\n",
       "      <td>3.419711e-01</td>\n",
       "      <td>3.419861e-01</td>\n",
       "      <td>3.416254e-01</td>\n",
       "      <td>3.419606e-01</td>\n",
       "      <td>3.419381e-01</td>\n",
       "      <td>3.419530e-01</td>\n",
       "      <td>3.419570e-01</td>\n",
       "      <td>3.419541e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.421267e-01</td>\n",
       "      <td>3.421286e-01</td>\n",
       "      <td>3.421448e-01</td>\n",
       "      <td>3.421260e-01</td>\n",
       "      <td>3.421407e-01</td>\n",
       "      <td>3.422204e-01</td>\n",
       "      <td>3.418294e-01</td>\n",
       "      <td>3.421251e-01</td>\n",
       "      <td>3.421262e-01</td>\n",
       "      <td>3.418427e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.420794e-01</td>\n",
       "      <td>3.416060e-01</td>\n",
       "      <td>3.419591e-01</td>\n",
       "      <td>3.419358e-01</td>\n",
       "      <td>3.416266e-01</td>\n",
       "      <td>3.419636e-01</td>\n",
       "      <td>3.421004e-01</td>\n",
       "      <td>3.416068e-01</td>\n",
       "      <td>3.421010e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.421285e-01</td>\n",
       "      <td>3.421244e-01</td>\n",
       "      <td>3.397446e-01</td>\n",
       "      <td>3.402154e-01</td>\n",
       "      <td>3.401221e-01</td>\n",
       "      <td>3.405713e-01</td>\n",
       "      <td>3.402570e-01</td>\n",
       "      <td>3.402809e-01</td>\n",
       "      <td>3.398222e-01</td>\n",
       "      <td>3.402101e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>3.401826e-01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.415973e-01</td>\n",
       "      <td>3.419409e-01</td>\n",
       "      <td>3.416061e-01</td>\n",
       "      <td>3.419566e-01</td>\n",
       "      <td>3.418989e-01</td>\n",
       "      <td>3.419784e-01</td>\n",
       "      <td>3.421290e-01</td>\n",
       "      <td>3.420925e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.406988e-01</td>\n",
       "      <td>3.406730e-01</td>\n",
       "      <td>3.397644e-01</td>\n",
       "      <td>3.400846e-01</td>\n",
       "      <td>3.402409e-01</td>\n",
       "      <td>3.406831e-01</td>\n",
       "      <td>3.405939e-01</td>\n",
       "      <td>3.406723e-01</td>\n",
       "      <td>3.402238e-01</td>\n",
       "      <td>3.401946e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.898346e-16</td>\n",
       "      <td>-5.139290e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.416155e-01</td>\n",
       "      <td>3.416108e-01</td>\n",
       "      <td>3.419461e-01</td>\n",
       "      <td>3.419776e-01</td>\n",
       "      <td>3.421039e-01</td>\n",
       "      <td>3.420780e-01</td>\n",
       "      <td>3.421000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-3.924604e-16</td>\n",
       "      <td>-4.047074e-16</td>\n",
       "      <td>-3.912207e-16</td>\n",
       "      <td>-2.840552e-16</td>\n",
       "      <td>-5.301245e-16</td>\n",
       "      <td>-7.165123e-16</td>\n",
       "      <td>-5.815085e-16</td>\n",
       "      <td>-5.196465e-16</td>\n",
       "      <td>-4.647341e-16</td>\n",
       "      <td>-3.812751e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.361758e-16</td>\n",
       "      <td>-1.299837e-16</td>\n",
       "      <td>1.409082e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.419654e-01</td>\n",
       "      <td>3.419526e-01</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455797e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.291234e-16</td>\n",
       "      <td>6.328417e-17</td>\n",
       "      <td>4.928868e-17</td>\n",
       "      <td>-9.091201e-17</td>\n",
       "      <td>4.494395e-17</td>\n",
       "      <td>1.208453e-16</td>\n",
       "      <td>-6.060326e-17</td>\n",
       "      <td>-1.641983e-17</td>\n",
       "      <td>7.683108e-17</td>\n",
       "      <td>-1.147785e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455401e+00</td>\n",
       "      <td>1.455551e+00</td>\n",
       "      <td>1.455552e+00</td>\n",
       "      <td>1.455553e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.455552e+00</td>\n",
       "      <td>1.455545e+00</td>\n",
       "      <td>1.455400e+00</td>\n",
       "      <td>1.455403e+00</td>\n",
       "      <td>1.455550e+00</td>\n",
       "      <td>1.455549e+00</td>\n",
       "      <td>1.455398e+00</td>\n",
       "      <td>1.455549e+00</td>\n",
       "      <td>1.455410e+00</td>\n",
       "      <td>1.455395e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455738e+00</td>\n",
       "      <td>1.455741e+00</td>\n",
       "      <td>1.455718e+00</td>\n",
       "      <td>1.455739e+00</td>\n",
       "      <td>1.455739e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455795e+00</td>\n",
       "      <td>1.455787e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.455717e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>1.455739e+00</td>\n",
       "      <td>1.455737e+00</td>\n",
       "      <td>1.455714e+00</td>\n",
       "      <td>1.455716e+00</td>\n",
       "      <td>1.455739e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455717e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>1.455740e+00</td>\n",
       "      <td>1.455487e+00</td>\n",
       "      <td>1.455603e+00</td>\n",
       "      <td>1.455614e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "      <td>1.455797e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1.455494e+00</td>\n",
       "      <td>1.455605e+00</td>\n",
       "      <td>1.455607e+00</td>\n",
       "      <td>1.455496e+00</td>\n",
       "      <td>1.455606e+00</td>\n",
       "      <td>1.455607e+00</td>\n",
       "      <td>1.455608e+00</td>\n",
       "      <td>1.455608e+00</td>\n",
       "      <td>1.455601e+00</td>\n",
       "      <td>1.455493e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.455604e+00</td>\n",
       "      <td>1.455611e+00</td>\n",
       "      <td>1.455500e+00</td>\n",
       "      <td>1.455499e+00</td>\n",
       "      <td>1.455608e+00</td>\n",
       "      <td>1.455611e+00</td>\n",
       "      <td>-1.439055e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455786e+00</td>\n",
       "      <td>1.455796e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-4.960985e-17</td>\n",
       "      <td>1.495209e-16</td>\n",
       "      <td>-1.241795e-17</td>\n",
       "      <td>-6.061682e-18</td>\n",
       "      <td>-1.366172e-16</td>\n",
       "      <td>-4.347397e-19</td>\n",
       "      <td>1.502625e-16</td>\n",
       "      <td>-1.560936e-16</td>\n",
       "      <td>-8.540567e-18</td>\n",
       "      <td>-1.557827e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508711e-16</td>\n",
       "      <td>-1.545471e-16</td>\n",
       "      <td>-1.367068e-16</td>\n",
       "      <td>5.154507e-17</td>\n",
       "      <td>9.399793e-17</td>\n",
       "      <td>1.405400e-16</td>\n",
       "      <td>1.248162e-16</td>\n",
       "      <td>1.219012e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.455788e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-7.034652e-16</td>\n",
       "      <td>-9.993834e-16</td>\n",
       "      <td>-8.879999e-16</td>\n",
       "      <td>-9.737290e-16</td>\n",
       "      <td>-7.486604e-16</td>\n",
       "      <td>-8.330534e-16</td>\n",
       "      <td>-9.917830e-16</td>\n",
       "      <td>-4.245380e-16</td>\n",
       "      <td>-6.278724e-16</td>\n",
       "      <td>-7.622528e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.054094e-15</td>\n",
       "      <td>-9.382749e-16</td>\n",
       "      <td>-1.065179e-15</td>\n",
       "      <td>-9.411163e-16</td>\n",
       "      <td>-5.125083e-16</td>\n",
       "      <td>-9.812880e-16</td>\n",
       "      <td>-7.296491e-16</td>\n",
       "      <td>-1.092778e-15</td>\n",
       "      <td>-1.080115e-15</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3             4   \\\n",
       "0   0.000000e+00  3.380936e-01  3.379887e-01  3.389341e-01  3.380899e-01   \n",
       "1   1.455787e+00  0.000000e+00  3.264789e-17 -2.276906e-17 -8.266973e-17   \n",
       "2   1.455787e+00  1.455786e+00  0.000000e+00  1.081637e-16 -5.981408e-17   \n",
       "3   1.455797e+00  1.455787e+00  1.455797e+00  0.000000e+00 -1.094153e-16   \n",
       "4   1.455797e+00  1.455798e+00  1.455788e+00  1.455786e+00  0.000000e+00   \n",
       "5   1.455787e+00  1.455787e+00  1.455796e+00  1.455796e+00  1.455787e+00   \n",
       "6   1.455786e+00  1.455786e+00  1.455797e+00  1.455797e+00  3.489459e-01   \n",
       "7   3.502276e-01  3.495984e-01  3.502090e-01  3.501786e-01  3.489642e-01   \n",
       "8   3.502460e-01  3.501448e-01  3.501879e-01  3.495324e-01  3.489222e-01   \n",
       "9   3.502010e-01  3.489465e-01  3.496193e-01  3.496123e-01  3.489270e-01   \n",
       "10  3.502131e-01  3.496836e-01  3.496394e-01  3.489247e-01  3.489395e-01   \n",
       "11  3.501096e-01  3.501700e-01  1.455707e+00  1.455730e+00  1.455733e+00   \n",
       "12  1.455732e+00  1.455733e+00  1.455729e+00  1.455704e+00  1.455706e+00   \n",
       "13  1.455707e+00  1.455732e+00  1.455706e+00  1.455732e+00  1.455732e+00   \n",
       "14  1.455706e+00  1.455707e+00  1.455732e+00  1.455731e+00  3.393088e-01   \n",
       "15  3.396914e-01  3.396244e-01  3.401741e-01  3.393255e-01  3.396999e-01   \n",
       "16  3.395271e-01  3.396504e-01  3.402351e-01  3.401795e-01  3.393112e-01   \n",
       "17  1.508412e-16  1.519538e-16  1.498381e-16  1.189606e-16  2.199558e-17   \n",
       "18  1.504647e-16  1.490647e-16  1.399598e-16  5.749521e-17  1.264373e-16   \n",
       "19  3.521721e-01  3.546255e-01  3.547919e-01  3.531517e-01  3.548256e-01   \n",
       "20  3.531602e-01  3.521586e-01  3.532330e-01  3.521000e-01  3.548444e-01   \n",
       "21 -4.688853e-17  6.806628e-17 -7.205320e-17  7.393530e-17  2.656376e-17   \n",
       "22  2.853343e-19  2.727098e-17 -7.330630e-17  1.206750e-16  1.362276e-16   \n",
       "23 -3.446347e-17  3.666046e-16 -2.040859e-16 -5.598592e-16  9.019064e-17   \n",
       "24 -1.357560e-16 -2.589151e-16 -8.810900e-17  2.297098e-16 -5.859985e-16   \n",
       "25 -9.168805e-17  4.601256e-17  5.282785e-17  1.337722e-17  8.695499e-17   \n",
       "26  1.455380e+00  1.454887e+00  1.455371e+00  1.455361e+00  1.454853e+00   \n",
       "27  1.454936e+00  1.454815e+00  1.454790e+00  1.455351e+00  1.455379e+00   \n",
       "28  1.455809e+00  1.455800e+00  1.455799e+00  1.455801e+00  1.455799e+00   \n",
       "29  3.421267e-01  3.421286e-01  3.421448e-01  3.421260e-01  3.421407e-01   \n",
       "30  3.421285e-01  3.421244e-01  3.397446e-01  3.402154e-01  3.401221e-01   \n",
       "31  3.406988e-01  3.406730e-01  3.397644e-01  3.400846e-01  3.402409e-01   \n",
       "32 -3.924604e-16 -4.047074e-16 -3.912207e-16 -2.840552e-16 -5.301245e-16   \n",
       "33  1.291234e-16  6.328417e-17  4.928868e-17 -9.091201e-17  4.494395e-17   \n",
       "34  1.455552e+00  1.455545e+00  1.455400e+00  1.455403e+00  1.455550e+00   \n",
       "35  1.455717e+00  1.455740e+00  1.455740e+00  1.455740e+00  1.455739e+00   \n",
       "36  1.455494e+00  1.455605e+00  1.455607e+00  1.455496e+00  1.455606e+00   \n",
       "37 -4.960985e-17  1.495209e-16 -1.241795e-17 -6.061682e-18 -1.366172e-16   \n",
       "38 -7.034652e-16 -9.993834e-16 -8.879999e-16 -9.737290e-16 -7.486604e-16   \n",
       "\n",
       "              5             6             7             8             9   ...  \\\n",
       "0   3.381739e-01  3.379431e-01  3.381668e-01  3.380589e-01  3.380114e-01  ...   \n",
       "1   1.397577e-17  1.519550e-16 -7.741029e-17 -5.852152e-17 -2.564688e-16  ...   \n",
       "2  -1.112302e-16 -1.078852e-17 -9.367875e-17  1.010828e-16 -1.146344e-16  ...   \n",
       "3  -1.431787e-18 -3.594433e-17  1.455652e+00  1.455694e+00  1.455698e+00  ...   \n",
       "4   1.455697e+00  1.455655e+00  1.455656e+00  1.455654e+00  1.455695e+00  ...   \n",
       "5   0.000000e+00 -8.883402e-17 -4.248173e-17 -1.100898e-16  2.120933e-17  ...   \n",
       "6   3.501279e-01  0.000000e+00  1.953269e-16 -4.541706e-16 -1.084324e-15  ...   \n",
       "7   3.501007e-01  3.501691e-01  0.000000e+00  3.380382e-01  3.392220e-01  ...   \n",
       "8   3.501304e-01  3.501818e-01  3.489332e-01  0.000000e+00 -6.436151e-17  ...   \n",
       "9   3.500915e-01  3.488952e-01  3.502184e-01  3.501343e-01  0.000000e+00  ...   \n",
       "10  3.501737e-01  3.501755e-01  3.496205e-01  3.496305e-01  3.496412e-01  ...   \n",
       "11  1.455706e+00  1.455730e+00  1.455732e+00  1.455706e+00  1.455733e+00  ...   \n",
       "12  1.455732e+00  1.455731e+00  1.455706e+00  1.455732e+00  1.455707e+00  ...   \n",
       "13  1.455734e+00  1.455708e+00  1.455705e+00  1.455708e+00  1.455706e+00  ...   \n",
       "14  3.396507e-01  3.395580e-01  3.400970e-01  3.396836e-01  3.397031e-01  ...   \n",
       "15  3.395622e-01  3.393539e-01  3.396464e-01  3.393015e-01  3.401915e-01  ...   \n",
       "16  3.393238e-01  3.395988e-01  3.397160e-01  3.401707e-01  3.400929e-01  ...   \n",
       "17  8.166801e-17  1.516733e-16  1.280193e-16 -3.500326e-17 -7.558618e-17  ...   \n",
       "18  3.111825e-17  9.990150e-17  9.254857e-17  1.389366e-16  1.339504e-16  ...   \n",
       "19  3.548767e-01  3.522646e-01  3.547195e-01  3.545526e-01  3.548577e-01  ...   \n",
       "20  3.549597e-01  3.548162e-01  3.552374e-01  3.533176e-01  3.531608e-01  ...   \n",
       "21  1.260746e-18  1.899531e-16  1.750643e-16  8.169404e-17  8.654098e-17  ...   \n",
       "22  6.829965e-17 -2.088143e-17 -3.561623e-17 -3.973848e-17  4.951489e-17  ...   \n",
       "23 -8.396935e-17 -3.430514e-16 -4.113867e-16  4.504269e-16  3.302409e-16  ...   \n",
       "24  3.543287e-16 -6.537923e-16 -7.734759e-16  4.941606e-16  6.778746e-17  ...   \n",
       "25 -9.371275e-17 -1.595705e-17  5.217646e-17  5.192435e-17  8.887386e-17  ...   \n",
       "26  1.455364e+00  1.455379e+00  1.455381e+00  1.455374e+00  1.455367e+00  ...   \n",
       "27  1.454893e+00  1.454883e+00  1.454936e+00  1.455361e+00  1.455354e+00  ...   \n",
       "28  1.455800e+00  1.455810e+00  1.455799e+00  1.455810e+00  1.455811e+00  ...   \n",
       "29  3.422204e-01  3.418294e-01  3.421251e-01  3.421262e-01  3.418427e-01  ...   \n",
       "30  3.405713e-01  3.402570e-01  3.402809e-01  3.398222e-01  3.402101e-01  ...   \n",
       "31  3.406831e-01  3.405939e-01  3.406723e-01  3.402238e-01  3.401946e-01  ...   \n",
       "32 -7.165123e-16 -5.815085e-16 -5.196465e-16 -4.647341e-16 -3.812751e-16  ...   \n",
       "33  1.208453e-16 -6.060326e-17 -1.641983e-17  7.683108e-17 -1.147785e-16  ...   \n",
       "34  1.455549e+00  1.455398e+00  1.455549e+00  1.455410e+00  1.455395e+00  ...   \n",
       "35  1.455737e+00  1.455714e+00  1.455716e+00  1.455739e+00  1.455740e+00  ...   \n",
       "36  1.455607e+00  1.455608e+00  1.455608e+00  1.455601e+00  1.455493e+00  ...   \n",
       "37 -4.347397e-19  1.502625e-16 -1.560936e-16 -8.540567e-18 -1.557827e-16  ...   \n",
       "38 -8.330534e-16 -9.917830e-16 -4.245380e-16 -6.278724e-16 -7.622528e-16  ...   \n",
       "\n",
       "              29            30            31            32            33  \\\n",
       "0   3.389804e-01  3.379148e-01  3.378848e-01  3.380631e-01  3.381649e-01   \n",
       "1  -1.584123e-16  1.519494e-18  1.138338e-16 -5.539764e-17 -1.638700e-17   \n",
       "2   9.173442e-17 -6.492373e-17 -2.723410e-17 -9.754714e-17  7.342678e-17   \n",
       "3   1.455695e+00  1.455652e+00  1.455697e+00  1.455698e+00  1.455699e+00   \n",
       "4  -1.081697e-16  8.487760e-17 -3.389900e-17 -1.039835e-16 -5.452874e-19   \n",
       "5  -6.191731e-16 -4.854735e-17 -3.657205e-16  8.739392e-17 -6.127719e-16   \n",
       "6   3.383787e-01  3.383615e-01  3.382569e-01  3.384507e-01  3.391536e-01   \n",
       "7   4.746729e-17  7.934005e-17  8.515143e-17 -4.341651e-17 -3.603314e-17   \n",
       "8  -5.556559e-17  8.002156e-17 -3.439884e-17  8.730762e-17 -6.678595e-17   \n",
       "9  -1.335568e-16  1.272296e-16 -6.756040e-17 -8.143565e-17  1.223758e-16   \n",
       "10 -2.265673e-16 -1.537213e-16 -5.263211e-16 -5.278148e-16 -4.198308e-16   \n",
       "11  8.686744e-15  8.638382e-15  8.290972e-15  8.791719e-15  8.411993e-15   \n",
       "12  8.082872e-15  8.292655e-15  8.629567e-15  8.684439e-15  8.834426e-15   \n",
       "13  5.244809e-14  5.253294e-14  5.246448e-14  5.256075e-14  5.075188e-14   \n",
       "14  5.254955e-14  1.452613e+00  1.454956e+00  1.455014e+00  1.450480e+00   \n",
       "15  1.455042e+00  1.452122e+00  1.455049e+00  1.455002e+00  1.455137e+00   \n",
       "16  3.385845e-01  3.389156e-01  3.388899e-01  3.388650e-01  3.388893e-01   \n",
       "17  3.396497e-01  3.396034e-01  3.385830e-01  3.385865e-01  3.388240e-01   \n",
       "18  1.867858e-16  1.978064e-16  7.291097e-17  7.402949e-17  8.034222e-17   \n",
       "19  1.656044e-16  7.170833e-17  8.925018e-17  1.783492e-16  1.988216e-16   \n",
       "20  6.209304e-17  1.704270e-18  6.160297e-17 -1.541823e-16 -1.531877e-16   \n",
       "21  1.677554e-16  1.044926e-16  1.100672e-16 -6.425736e-17 -1.220332e-16   \n",
       "22  3.408571e-01  3.405513e-01  3.405544e-01  3.401801e-01  3.405039e-01   \n",
       "23  3.408724e-01  3.401736e-01  3.408602e-01  3.401356e-01  3.405043e-01   \n",
       "24  3.405237e-01  3.408601e-01  3.408664e-01  3.408650e-01  3.405228e-01   \n",
       "25  5.519543e-17 -2.849123e-17  3.707686e-17  8.220212e-17 -4.933628e-18   \n",
       "26  8.392966e-17 -1.446715e-17  4.044008e-17  1.995331e-17 -7.831377e-17   \n",
       "27 -8.559581e-17  1.233005e-17  1.886367e-17  2.635013e-17  4.669320e-17   \n",
       "28  3.419385e-01  3.420704e-01  3.419711e-01  3.419861e-01  3.416254e-01   \n",
       "29  0.000000e+00  3.420794e-01  3.416060e-01  3.419591e-01  3.419358e-01   \n",
       "30  3.401826e-01  0.000000e+00  3.415973e-01  3.419409e-01  3.416061e-01   \n",
       "31 -3.898346e-16 -5.139290e-16  0.000000e+00  3.416155e-01  3.416108e-01   \n",
       "32 -1.361758e-16 -1.299837e-16  1.409082e-16  0.000000e+00  3.419654e-01   \n",
       "33  1.455401e+00  1.455551e+00  1.455552e+00  1.455553e+00  0.000000e+00   \n",
       "34  1.455738e+00  1.455741e+00  1.455718e+00  1.455739e+00  1.455739e+00   \n",
       "35  1.455717e+00  1.455740e+00  1.455740e+00  1.455487e+00  1.455603e+00   \n",
       "36  1.455604e+00  1.455611e+00  1.455500e+00  1.455499e+00  1.455608e+00   \n",
       "37 -1.508711e-16 -1.545471e-16 -1.367068e-16  5.154507e-17  9.399793e-17   \n",
       "38 -1.054094e-15 -9.382749e-16 -1.065179e-15 -9.411163e-16 -5.125083e-16   \n",
       "\n",
       "              34            35            36            37            38  \n",
       "0   3.389567e-01  3.388908e-01  3.389931e-01  3.381746e-01  3.380238e-01  \n",
       "1  -4.994560e-17 -1.568154e-16 -1.660729e-16 -1.307816e-16 -9.889061e-17  \n",
       "2   1.116742e-16 -1.038701e-16  2.464274e-17 -1.117505e-16  1.003868e-16  \n",
       "3   1.455658e+00  1.455654e+00  1.455654e+00  1.455652e+00  1.455696e+00  \n",
       "4  -1.056759e-16  4.571619e-17 -3.635393e-18  4.355314e-17  1.019608e-16  \n",
       "5   1.739673e-16 -5.155946e-16  3.253659e-16  1.149268e-17 -1.700703e-16  \n",
       "6   3.380173e-01  3.382829e-01  3.383028e-01  3.381111e-01  3.384517e-01  \n",
       "7  -7.385548e-17  2.205330e-17 -8.145809e-17 -6.405159e-17  8.299182e-17  \n",
       "8   3.753920e-17 -7.485077e-17 -7.164270e-17 -1.260545e-16 -1.310180e-16  \n",
       "9  -1.148016e-16 -2.181992e-17 -1.312996e-16 -1.349140e-16 -1.305739e-16  \n",
       "10 -3.324988e-16 -3.293825e-16 -2.323306e-16 -5.657400e-16 -4.610225e-16  \n",
       "11  8.100027e-15  8.485926e-15  7.740832e-15  8.114056e-15  8.169729e-15  \n",
       "12  8.316832e-15  7.676871e-15  8.477289e-15  8.657762e-15  8.424713e-15  \n",
       "13  5.210585e-14  5.132517e-14  5.201953e-14  5.185842e-14  5.251869e-14  \n",
       "14  1.454963e+00  1.454995e+00  1.452460e+00  1.454987e+00  1.454957e+00  \n",
       "15  1.451702e+00  1.449524e+00  1.452971e+00  1.452079e+00  1.455016e+00  \n",
       "16  3.389354e-01  3.395714e-01  3.389086e-01  3.387950e-01  3.386038e-01  \n",
       "17  3.389423e-01  3.395862e-01  3.395131e-01  3.396243e-01  3.389534e-01  \n",
       "18  1.911201e-16  1.703514e-16  9.706314e-17  1.721545e-16  9.612674e-17  \n",
       "19  1.947320e-16  1.256947e-16  2.007035e-16  1.992291e-16  1.753032e-16  \n",
       "20 -1.793392e-16  9.239071e-18 -2.843482e-17 -1.737112e-16 -2.945718e-17  \n",
       "21 -1.296682e-16  3.391752e-18  1.875252e-16  5.252686e-17 -7.614985e-17  \n",
       "22  3.405450e-01  3.405546e-01  3.404964e-01  3.405882e-01  3.408186e-01  \n",
       "23  3.401962e-01  3.405482e-01  3.404519e-01  3.405025e-01  3.408804e-01  \n",
       "24  3.405105e-01 -7.592124e-17 -8.194743e-17 -1.870599e-17  8.690791e-17  \n",
       "25 -8.561384e-17 -7.702188e-17 -7.658110e-17 -2.297982e-17 -8.196041e-17  \n",
       "26  8.283826e-17 -1.788392e-17  4.051473e-17 -4.592002e-17  7.925250e-17  \n",
       "27 -7.814216e-17  6.819877e-17  5.931619e-17  3.415999e-01  3.419475e-01  \n",
       "28  3.419606e-01  3.419381e-01  3.419530e-01  3.419570e-01  3.419541e-01  \n",
       "29  3.416266e-01  3.419636e-01  3.421004e-01  3.416068e-01  3.421010e-01  \n",
       "30  3.419566e-01  3.418989e-01  3.419784e-01  3.421290e-01  3.420925e-01  \n",
       "31  3.419461e-01  3.419776e-01  3.421039e-01  3.420780e-01  3.421000e-01  \n",
       "32  3.419526e-01  1.455786e+00  1.455796e+00  1.455797e+00  1.455787e+00  \n",
       "33  1.455796e+00  1.455796e+00  1.455787e+00  1.455796e+00  1.455796e+00  \n",
       "34  0.000000e+00  1.455796e+00  1.455796e+00  1.455795e+00  1.455787e+00  \n",
       "35  1.455614e+00  0.000000e+00  1.455786e+00  1.455796e+00  1.455797e+00  \n",
       "36  1.455611e+00 -1.439055e-16  0.000000e+00  1.455786e+00  1.455796e+00  \n",
       "37  1.405400e-16  1.248162e-16  1.219012e-16  0.000000e+00  1.455788e+00  \n",
       "38 -9.812880e-16 -7.296491e-16 -1.092778e-15 -1.080115e-15  0.000000e+00  \n",
       "\n",
       "[39 rows x 39 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2394aac0c10>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f9891b1dc0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20fb46bac40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('model_undirected', 'wb')\n",
    "pickle.dump(model, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\code\\shrinkage_prior.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m edge_weights \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mtestfile.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jqcla/Documents/GitHub/Honours-Thesis/code/shrinkage_prior.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m edge_weights\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
