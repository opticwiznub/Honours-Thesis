{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "import torch_geometric.transforms as T\n",
    "from glob import glob\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ssp_data():\n",
    "    def __init__(self, n=39) -> None:\n",
    "        self.n = n\n",
    "        self.init_edge_list(n)\n",
    "        self.y_file = 'data\\\\tas_scenario_245\\\\tas_mon_mod_ssp245_192_000.nc'\n",
    "        self.x_file_list = [item for item in glob('data\\\\tas_scenario_245\\\\tas_mon_mod_ssp245_192_*.nc') if item not in [self.y_file]][0 : self.n]\n",
    "        self.create_df()\n",
    "        self.test_train_split()\n",
    "       \n",
    "        # self.split_data()\n",
    "        # self.mini_graphs()\n",
    "\n",
    "    def init_edge_list(self, n):\n",
    "        self.edge_index = []\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                if i != j:\n",
    "                    self.edge_index.append([i, j])\n",
    "        self.edge_index = torch.tensor(self.edge_index, dtype=torch.long)\n",
    "\n",
    "    def create_df(self):\n",
    "        self.x = pd.DataFrame()\n",
    "        i = 1\n",
    "        for filename in self.x_file_list:\n",
    "            print('Processing', filename)\n",
    "            if self.x.empty:\n",
    "                self.x = self.create_vector(filename).reset_index(drop=True)\n",
    "            else:\n",
    "                assert len(self.x) == len(w:= self.create_vector(filename)['tas'])\n",
    "                self.x[f'tas_{i}'] = w.reset_index(drop=True)\n",
    "                # self.x = self.x.merge(self.create_vector(filename), how='inner', on=['time', 'lat', 'lon'], suffixes=(None, f'_{i}'))\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        self.y = self.create_vector(self.y_file)['tas'].reset_index(drop=True)\n",
    "\n",
    "    def create_vector(self, filename):\n",
    "        data = xr.open_dataset(filename)\n",
    "        try:\n",
    "            datetimeindex = data.indexes['time'].to_datetimeindex()\n",
    "            data['time'] = datetimeindex\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "        df = data.to_dataframe().reset_index()\n",
    "        df = df.query('lat >= -44 & lat <= -12 & lon >= 288 & lon <= 336')\n",
    "        ret = df.loc[(df['time'].dt.year > 1960) & (df['time'].dt.year < 1980), ['time', 'lat', 'lon', 'tas']]\n",
    "\n",
    "        return ret\n",
    "    \n",
    "    def test_train_split(self, p=74100):\n",
    "        df = self.x.drop(columns=['time'], axis=1)\n",
    "        self.x_train = df[0:p]\n",
    "        self.x_test = df[p:]\n",
    "        self.y_train = df[0:p]\n",
    "        self.y_test = df[p:]\n",
    "\n",
    "        self.x_train = self.create_tensors(self.x_train).T\n",
    "        self.y_train = self.create_tensors(self.y_train)\n",
    "        self.train_data = torch_geometric.data.Data(x=self.x_train, edge_index=self.edge_index.t().contiguous(), y=self.y_train)\n",
    "\n",
    "        self.x_test = self.create_tensors(self.x_test).T\n",
    "        self.y_test = self.create_tensors(self.y_test)\n",
    "        self.test_data = torch_geometric.data.Data(x=self.x_test, edge_index=self.edge_index.t().contiguous(), y=self.y_test)\n",
    "\n",
    "    \n",
    "    def get_device(self):\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device('cuda:0')\n",
    "        else:\n",
    "            device = torch.device('cpu') # don't have GPU \n",
    "        return device\n",
    "\n",
    "    def create_tensors(self, df):\n",
    "        device = self.get_device()\n",
    "        return torch.from_numpy(df.values).float().to(device)\n",
    "    \n",
    "    def mini_graphs(self):\n",
    "        df = self.x\n",
    "        df['x_tensor'] = df.apply(lambda row: torch.tensor(row.values.flatten()), axis=1)\n",
    "        df['y'] = self.y\n",
    "        df['y_tensor'] = df['y'].apply(lambda y: torch.tensor(y))\n",
    "        df['data_obj'] = df.apply(lambda row: torch_geometric.data.Data(x=df['x_tensor'], edge_index=self.edge_index.t().contiguous(), y=df['y_tensor']), axis=1)\n",
    "        self.batch_graphs = df['data_obj']\n",
    "    \n",
    "    def split_data(self):\n",
    "        transform = T.Compose([T.RandomNodeSplit(num_test=1000, num_val=1000)])\n",
    "        self.data = transform(self.data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_001.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_002.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_003.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_004.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_005.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_006.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_007.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_008.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_009.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_010.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_011.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_012.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_013.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_014.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_015.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_016.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_017.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_018.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_019.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_020.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_021.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_022.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, '360_day', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_023.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_024.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_025.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_026.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, '360_day', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_027.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_028.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_029.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_030.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_031.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_032.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_033.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_034.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_035.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_036.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, '360_day', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_037.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, 'noleap', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_038.nc\n",
      "Processing data\\tas_scenario_245\\tas_mon_mod_ssp245_192_039.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\3434818901.py:40: RuntimeWarning: Converting a CFTimeIndex with dates from a non-standard calendar, '360_day', to a pandas.DatetimeIndex, which uses dates from the standard calendar.  This may lead to subtle errors in operations that depend on the length of time between dates.\n",
      "  datetimeindex = data.indexes['time'].to_datetimeindex()\n"
     ]
    }
   ],
   "source": [
    "ssp_obj = ssp_data(n=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('data_pickle', 'wb')\n",
    "pickle.dump(ssp_obj, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>tas</th>\n",
       "      <th>tas_2</th>\n",
       "      <th>tas_3</th>\n",
       "      <th>tas_4</th>\n",
       "      <th>tas_5</th>\n",
       "      <th>tas_6</th>\n",
       "      <th>tas_7</th>\n",
       "      <th>tas_8</th>\n",
       "      <th>...</th>\n",
       "      <th>tas_30</th>\n",
       "      <th>tas_31</th>\n",
       "      <th>tas_32</th>\n",
       "      <th>tas_33</th>\n",
       "      <th>tas_34</th>\n",
       "      <th>tas_35</th>\n",
       "      <th>tas_36</th>\n",
       "      <th>tas_37</th>\n",
       "      <th>tas_38</th>\n",
       "      <th>tas_39</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>286.400269</td>\n",
       "      <td>280.862762</td>\n",
       "      <td>286.771332</td>\n",
       "      <td>285.407745</td>\n",
       "      <td>283.856293</td>\n",
       "      <td>284.691101</td>\n",
       "      <td>284.222473</td>\n",
       "      <td>284.567688</td>\n",
       "      <td>...</td>\n",
       "      <td>282.111908</td>\n",
       "      <td>282.265228</td>\n",
       "      <td>281.129608</td>\n",
       "      <td>286.833252</td>\n",
       "      <td>285.880707</td>\n",
       "      <td>284.140472</td>\n",
       "      <td>284.725891</td>\n",
       "      <td>284.140472</td>\n",
       "      <td>285.263153</td>\n",
       "      <td>284.725891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>285.905518</td>\n",
       "      <td>281.284271</td>\n",
       "      <td>281.414459</td>\n",
       "      <td>284.798828</td>\n",
       "      <td>283.674713</td>\n",
       "      <td>284.747620</td>\n",
       "      <td>284.870758</td>\n",
       "      <td>285.316010</td>\n",
       "      <td>...</td>\n",
       "      <td>281.504333</td>\n",
       "      <td>282.548706</td>\n",
       "      <td>281.564545</td>\n",
       "      <td>286.903931</td>\n",
       "      <td>284.964691</td>\n",
       "      <td>286.738007</td>\n",
       "      <td>283.592102</td>\n",
       "      <td>286.738007</td>\n",
       "      <td>286.132538</td>\n",
       "      <td>283.592102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>284.728638</td>\n",
       "      <td>283.605560</td>\n",
       "      <td>281.929413</td>\n",
       "      <td>282.059021</td>\n",
       "      <td>281.492584</td>\n",
       "      <td>282.372467</td>\n",
       "      <td>282.833374</td>\n",
       "      <td>285.541168</td>\n",
       "      <td>...</td>\n",
       "      <td>279.986084</td>\n",
       "      <td>280.477509</td>\n",
       "      <td>280.007172</td>\n",
       "      <td>284.080078</td>\n",
       "      <td>285.290619</td>\n",
       "      <td>281.925079</td>\n",
       "      <td>281.761536</td>\n",
       "      <td>281.925079</td>\n",
       "      <td>287.348694</td>\n",
       "      <td>281.761536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>280.983887</td>\n",
       "      <td>276.310425</td>\n",
       "      <td>279.923767</td>\n",
       "      <td>279.065002</td>\n",
       "      <td>278.729950</td>\n",
       "      <td>278.684601</td>\n",
       "      <td>278.864471</td>\n",
       "      <td>286.656097</td>\n",
       "      <td>...</td>\n",
       "      <td>276.463318</td>\n",
       "      <td>277.716187</td>\n",
       "      <td>277.234680</td>\n",
       "      <td>280.085754</td>\n",
       "      <td>280.959534</td>\n",
       "      <td>280.333771</td>\n",
       "      <td>279.282410</td>\n",
       "      <td>280.333771</td>\n",
       "      <td>288.668671</td>\n",
       "      <td>279.282410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-43.125</td>\n",
       "      <td>288.750</td>\n",
       "      <td>279.186432</td>\n",
       "      <td>272.765076</td>\n",
       "      <td>278.642639</td>\n",
       "      <td>275.679047</td>\n",
       "      <td>275.733490</td>\n",
       "      <td>275.873016</td>\n",
       "      <td>275.867615</td>\n",
       "      <td>287.312958</td>\n",
       "      <td>...</td>\n",
       "      <td>274.361664</td>\n",
       "      <td>275.168488</td>\n",
       "      <td>276.429657</td>\n",
       "      <td>277.081879</td>\n",
       "      <td>278.714783</td>\n",
       "      <td>278.002899</td>\n",
       "      <td>275.879089</td>\n",
       "      <td>278.002899</td>\n",
       "      <td>289.741669</td>\n",
       "      <td>275.879089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148195</th>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>294.739410</td>\n",
       "      <td>295.901398</td>\n",
       "      <td>297.703033</td>\n",
       "      <td>296.290222</td>\n",
       "      <td>296.006287</td>\n",
       "      <td>296.114349</td>\n",
       "      <td>296.208649</td>\n",
       "      <td>296.394745</td>\n",
       "      <td>...</td>\n",
       "      <td>297.537598</td>\n",
       "      <td>295.884766</td>\n",
       "      <td>296.006897</td>\n",
       "      <td>296.684509</td>\n",
       "      <td>295.838593</td>\n",
       "      <td>294.373749</td>\n",
       "      <td>295.813171</td>\n",
       "      <td>294.373749</td>\n",
       "      <td>296.948700</td>\n",
       "      <td>295.813171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148196</th>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>294.692566</td>\n",
       "      <td>295.707916</td>\n",
       "      <td>297.600006</td>\n",
       "      <td>296.493225</td>\n",
       "      <td>295.870270</td>\n",
       "      <td>295.974457</td>\n",
       "      <td>296.031311</td>\n",
       "      <td>296.582794</td>\n",
       "      <td>...</td>\n",
       "      <td>297.362488</td>\n",
       "      <td>295.818451</td>\n",
       "      <td>295.926453</td>\n",
       "      <td>296.765686</td>\n",
       "      <td>295.840881</td>\n",
       "      <td>294.300812</td>\n",
       "      <td>295.637085</td>\n",
       "      <td>294.300812</td>\n",
       "      <td>297.087402</td>\n",
       "      <td>295.637085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148197</th>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>295.054901</td>\n",
       "      <td>296.138306</td>\n",
       "      <td>297.874847</td>\n",
       "      <td>296.958801</td>\n",
       "      <td>296.478088</td>\n",
       "      <td>296.565735</td>\n",
       "      <td>296.519348</td>\n",
       "      <td>296.831482</td>\n",
       "      <td>...</td>\n",
       "      <td>297.990479</td>\n",
       "      <td>296.596130</td>\n",
       "      <td>296.481384</td>\n",
       "      <td>297.795013</td>\n",
       "      <td>296.184540</td>\n",
       "      <td>294.528290</td>\n",
       "      <td>296.202637</td>\n",
       "      <td>294.528290</td>\n",
       "      <td>297.274567</td>\n",
       "      <td>296.202637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148198</th>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>295.820404</td>\n",
       "      <td>297.221680</td>\n",
       "      <td>298.484406</td>\n",
       "      <td>297.945587</td>\n",
       "      <td>297.443146</td>\n",
       "      <td>297.509857</td>\n",
       "      <td>297.399323</td>\n",
       "      <td>297.165375</td>\n",
       "      <td>...</td>\n",
       "      <td>298.557434</td>\n",
       "      <td>297.636230</td>\n",
       "      <td>297.550934</td>\n",
       "      <td>299.549622</td>\n",
       "      <td>297.094421</td>\n",
       "      <td>295.460297</td>\n",
       "      <td>296.916992</td>\n",
       "      <td>295.460297</td>\n",
       "      <td>297.539337</td>\n",
       "      <td>296.916992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148199</th>\n",
       "      <td>-13.125</td>\n",
       "      <td>335.625</td>\n",
       "      <td>296.729889</td>\n",
       "      <td>298.185516</td>\n",
       "      <td>299.366486</td>\n",
       "      <td>299.296753</td>\n",
       "      <td>298.408569</td>\n",
       "      <td>298.476410</td>\n",
       "      <td>298.392365</td>\n",
       "      <td>297.564270</td>\n",
       "      <td>...</td>\n",
       "      <td>299.609619</td>\n",
       "      <td>298.821991</td>\n",
       "      <td>297.897736</td>\n",
       "      <td>300.688416</td>\n",
       "      <td>298.054230</td>\n",
       "      <td>296.870697</td>\n",
       "      <td>297.735535</td>\n",
       "      <td>296.870697</td>\n",
       "      <td>297.869965</td>\n",
       "      <td>297.735535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148200 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           lat      lon         tas       tas_2       tas_3       tas_4  \\\n",
       "0      -43.125  288.750  286.400269  280.862762  286.771332  285.407745   \n",
       "1      -43.125  288.750  285.905518  281.284271  281.414459  284.798828   \n",
       "2      -43.125  288.750  284.728638  283.605560  281.929413  282.059021   \n",
       "3      -43.125  288.750  280.983887  276.310425  279.923767  279.065002   \n",
       "4      -43.125  288.750  279.186432  272.765076  278.642639  275.679047   \n",
       "...        ...      ...         ...         ...         ...         ...   \n",
       "148195 -13.125  335.625  294.739410  295.901398  297.703033  296.290222   \n",
       "148196 -13.125  335.625  294.692566  295.707916  297.600006  296.493225   \n",
       "148197 -13.125  335.625  295.054901  296.138306  297.874847  296.958801   \n",
       "148198 -13.125  335.625  295.820404  297.221680  298.484406  297.945587   \n",
       "148199 -13.125  335.625  296.729889  298.185516  299.366486  299.296753   \n",
       "\n",
       "             tas_5       tas_6       tas_7       tas_8  ...      tas_30  \\\n",
       "0       283.856293  284.691101  284.222473  284.567688  ...  282.111908   \n",
       "1       283.674713  284.747620  284.870758  285.316010  ...  281.504333   \n",
       "2       281.492584  282.372467  282.833374  285.541168  ...  279.986084   \n",
       "3       278.729950  278.684601  278.864471  286.656097  ...  276.463318   \n",
       "4       275.733490  275.873016  275.867615  287.312958  ...  274.361664   \n",
       "...            ...         ...         ...         ...  ...         ...   \n",
       "148195  296.006287  296.114349  296.208649  296.394745  ...  297.537598   \n",
       "148196  295.870270  295.974457  296.031311  296.582794  ...  297.362488   \n",
       "148197  296.478088  296.565735  296.519348  296.831482  ...  297.990479   \n",
       "148198  297.443146  297.509857  297.399323  297.165375  ...  298.557434   \n",
       "148199  298.408569  298.476410  298.392365  297.564270  ...  299.609619   \n",
       "\n",
       "            tas_31      tas_32      tas_33      tas_34      tas_35  \\\n",
       "0       282.265228  281.129608  286.833252  285.880707  284.140472   \n",
       "1       282.548706  281.564545  286.903931  284.964691  286.738007   \n",
       "2       280.477509  280.007172  284.080078  285.290619  281.925079   \n",
       "3       277.716187  277.234680  280.085754  280.959534  280.333771   \n",
       "4       275.168488  276.429657  277.081879  278.714783  278.002899   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "148195  295.884766  296.006897  296.684509  295.838593  294.373749   \n",
       "148196  295.818451  295.926453  296.765686  295.840881  294.300812   \n",
       "148197  296.596130  296.481384  297.795013  296.184540  294.528290   \n",
       "148198  297.636230  297.550934  299.549622  297.094421  295.460297   \n",
       "148199  298.821991  297.897736  300.688416  298.054230  296.870697   \n",
       "\n",
       "            tas_36      tas_37      tas_38      tas_39  \n",
       "0       284.725891  284.140472  285.263153  284.725891  \n",
       "1       283.592102  286.738007  286.132538  283.592102  \n",
       "2       281.761536  281.925079  287.348694  281.761536  \n",
       "3       279.282410  280.333771  288.668671  279.282410  \n",
       "4       275.879089  278.002899  289.741669  275.879089  \n",
       "...            ...         ...         ...         ...  \n",
       "148195  295.813171  294.373749  296.948700  295.813171  \n",
       "148196  295.637085  294.300812  297.087402  295.637085  \n",
       "148197  296.202637  294.528290  297.274567  296.202637  \n",
       "148198  296.916992  295.460297  297.539337  296.916992  \n",
       "148199  297.735535  296.870697  297.869965  297.735535  \n",
       "\n",
       "[148200 rows x 41 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_obj.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.edge_weight = torch.nn.Parameter(torch.ones(ssp_obj.train_data.num_edges))\n",
    "        self.conv1 = GCNConv(ssp_obj.train_data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, ssp_obj.train_data.num_node_features)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        # print(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "        x = self.conv2(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\1711369381.py:13: UserWarning: Using a target size (torch.Size([74100])) that is different to the input size (torch.Size([41, 74100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  train_loss = F.mse_loss(out, train_data.y)\n",
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_8308\\1711369381.py:17: UserWarning: Using a target size (torch.Size([74100])) that is different to the input size (torch.Size([41, 74100])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  test_loss = F.mse_loss(test_out, test_data.y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(83498.4297, grad_fn=<MseLossBackward0>) tensor(86686.7656, grad_fn=<MseLossBackward0>)\n",
      "1 tensor(6.3292e+10, grad_fn=<MseLossBackward0>) tensor(4.1631e+10, grad_fn=<MseLossBackward0>)\n",
      "2 tensor(9.6505e+10, grad_fn=<MseLossBackward0>) tensor(1.1690e+11, grad_fn=<MseLossBackward0>)\n",
      "3 tensor(6.5189e+08, grad_fn=<MseLossBackward0>) tensor(7.7834e+08, grad_fn=<MseLossBackward0>)\n",
      "4 tensor(1.1292e+10, grad_fn=<MseLossBackward0>) tensor(8.5566e+09, grad_fn=<MseLossBackward0>)\n",
      "5 tensor(10605637., grad_fn=<MseLossBackward0>) tensor(8295070.5000, grad_fn=<MseLossBackward0>)\n",
      "6 tensor(83484.0234, grad_fn=<MseLossBackward0>) tensor(86679.7578, grad_fn=<MseLossBackward0>)\n",
      "7 tensor(83490.8906, grad_fn=<MseLossBackward0>) tensor(86686.7422, grad_fn=<MseLossBackward0>)\n",
      "8 tensor(83496.9141, grad_fn=<MseLossBackward0>) tensor(86692.8750, grad_fn=<MseLossBackward0>)\n",
      "9 tensor(83502.2422, grad_fn=<MseLossBackward0>) tensor(86698.2969, grad_fn=<MseLossBackward0>)\n",
      "10 tensor(83506.9609, grad_fn=<MseLossBackward0>) tensor(86703.1172, grad_fn=<MseLossBackward0>)\n",
      "11 tensor(83511.1797, grad_fn=<MseLossBackward0>) tensor(86707.4141, grad_fn=<MseLossBackward0>)\n",
      "12 tensor(83514.9453, grad_fn=<MseLossBackward0>) tensor(86711.2578, grad_fn=<MseLossBackward0>)\n",
      "13 tensor(83518.3203, grad_fn=<MseLossBackward0>) tensor(86714.6953, grad_fn=<MseLossBackward0>)\n",
      "14 tensor(83521.3594, grad_fn=<MseLossBackward0>) tensor(86717.7734, grad_fn=<MseLossBackward0>)\n",
      "15 tensor(83524.0625, grad_fn=<MseLossBackward0>) tensor(86720.5469, grad_fn=<MseLossBackward0>)\n",
      "16 tensor(83526.5078, grad_fn=<MseLossBackward0>) tensor(86723.0312, grad_fn=<MseLossBackward0>)\n",
      "17 tensor(83528.6875, grad_fn=<MseLossBackward0>) tensor(86725.2578, grad_fn=<MseLossBackward0>)\n",
      "18 tensor(83530.6641, grad_fn=<MseLossBackward0>) tensor(86727.2656, grad_fn=<MseLossBackward0>)\n",
      "19 tensor(83532.4141, grad_fn=<MseLossBackward0>) tensor(86729.0625, grad_fn=<MseLossBackward0>)\n",
      "20 tensor(83534., grad_fn=<MseLossBackward0>) tensor(86730.6641, grad_fn=<MseLossBackward0>)\n",
      "21 tensor(83535.4141, grad_fn=<MseLossBackward0>) tensor(86732.1016, grad_fn=<MseLossBackward0>)\n",
      "22 tensor(83536.6719, grad_fn=<MseLossBackward0>) tensor(86733.3906, grad_fn=<MseLossBackward0>)\n",
      "23 tensor(83537.7969, grad_fn=<MseLossBackward0>) tensor(86734.5312, grad_fn=<MseLossBackward0>)\n",
      "24 tensor(83538.7891, grad_fn=<MseLossBackward0>) tensor(86735.5469, grad_fn=<MseLossBackward0>)\n",
      "25 tensor(83539.6797, grad_fn=<MseLossBackward0>) tensor(86736.4453, grad_fn=<MseLossBackward0>)\n",
      "26 tensor(83540.4531, grad_fn=<MseLossBackward0>) tensor(86737.2422, grad_fn=<MseLossBackward0>)\n",
      "27 tensor(83541.1328, grad_fn=<MseLossBackward0>) tensor(86737.9375, grad_fn=<MseLossBackward0>)\n",
      "28 tensor(83541.7344, grad_fn=<MseLossBackward0>) tensor(86738.5469, grad_fn=<MseLossBackward0>)\n",
      "29 tensor(83542.2500, grad_fn=<MseLossBackward0>) tensor(86739.0703, grad_fn=<MseLossBackward0>)\n",
      "30 tensor(83542.6875, grad_fn=<MseLossBackward0>) tensor(86739.5234, grad_fn=<MseLossBackward0>)\n",
      "31 tensor(83543.0703, grad_fn=<MseLossBackward0>) tensor(86739.9062, grad_fn=<MseLossBackward0>)\n",
      "32 tensor(83543.3828, grad_fn=<MseLossBackward0>) tensor(86740.2188, grad_fn=<MseLossBackward0>)\n",
      "33 tensor(83543.6328, grad_fn=<MseLossBackward0>) tensor(86740.4922, grad_fn=<MseLossBackward0>)\n",
      "34 tensor(83543.8516, grad_fn=<MseLossBackward0>) tensor(86740.7031, grad_fn=<MseLossBackward0>)\n",
      "35 tensor(83544.0156, grad_fn=<MseLossBackward0>) tensor(86740.8594, grad_fn=<MseLossBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10000\u001b[39m):\n\u001b[0;32m     11\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m     out \u001b[39m=\u001b[39m model(train_data)\n\u001b[0;32m     13\u001b[0m     train_loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmse_loss(out, train_data\u001b[39m.\u001b[39my)\n\u001b[0;32m     14\u001b[0m     train_loss_l\u001b[39m.\u001b[39mappend(train_loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[50], line 19\u001b[0m, in \u001b[0;36mGCN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     17\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(x, training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining)\n\u001b[0;32m     18\u001b[0m \u001b[39m# print(x, edge_index, torch.minimum(self.edge_weight.abs(),torch.ones(data.num_edges)))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index, torch\u001b[39m.\u001b[39;49mminimum(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medge_weight\u001b[39m.\u001b[39;49mabs(),torch\u001b[39m.\u001b[39;49mones(data\u001b[39m.\u001b[39;49mnum_edges)))\n\u001b[0;32m     21\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:229\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    227\u001b[0m             edge_index \u001b[39m=\u001b[39m cache\n\u001b[1;32m--> 229\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlin(x)\n\u001b[0;32m    231\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[0;32m    232\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpropagate(edge_index, x\u001b[39m=\u001b[39mx, edge_weight\u001b[39m=\u001b[39medge_weight,\n\u001b[0;32m    233\u001b[0m                      size\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\torch_geometric\\nn\\dense\\linear.py:132\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m    128\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(x, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "train_data = ssp_obj.train_data.to(device)\n",
    "test_data = ssp_obj.test_data.to(device)\n",
    "train_loss_l = []\n",
    "test_loss_l = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10000):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(train_data)\n",
    "    train_loss = F.mse_loss(out, train_data.y)\n",
    "    train_loss_l.append(train_loss.item())\n",
    "\n",
    "    test_out = model(test_data)\n",
    "    test_loss = F.mse_loss(test_out, test_data.y)\n",
    "    test_loss_l.append(test_loss.item())\n",
    "\n",
    "    print(epoch, train_loss, test_loss)\n",
    "    train_loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2459dde9160>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_l[5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00, 1.0281e+00,\n",
       "        1.0281e+00, 2.3427e-01, 2.3410e-01, 2.3374e-01, 2.3368e-01, 2.3573e-01,\n",
       "        2.3519e-01, 2.3605e-01, 2.3806e-01, 2.3909e-01, 2.3808e-01, 2.3746e-01,\n",
       "        2.4096e-01, 2.3891e-01, 2.4134e-01, 9.2244e-01, 9.2243e-01, 9.2242e-01,\n",
       "        9.2242e-01, 9.2242e-01, 9.2241e-01, 9.2243e-01, 9.2188e-01, 9.2189e-01,\n",
       "        9.2188e-01, 9.2188e-01, 9.2185e-01, 9.2185e-01, 9.2186e-01, 5.6408e-04,\n",
       "        5.8485e-04, 5.6915e-04, 5.9098e-04, 5.5358e-04, 5.0742e-04, 5.4165e-04,\n",
       "        1.1606e-05, 1.2645e-05, 1.1900e-05, 1.3083e-05, 1.1248e-05, 8.5484e-06,\n",
       "        1.0548e-05, 1.9385e-02, 1.9439e-02, 1.9907e-02, 1.9607e-02, 1.9089e-02,\n",
       "        1.9989e-02, 1.9699e-02], requires_grad=True)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0621346235275269,\n",
       " 1.061711072921753,\n",
       " 1.0619031190872192,\n",
       " 1.0618290901184082,\n",
       " 1.0618948936462402,\n",
       " 1.0618715286254883,\n",
       " 1.0617121458053589,\n",
       " 1.0494590997695923,\n",
       " 1.049369215965271,\n",
       " 1.0494438409805298,\n",
       " 1.0494590997695923,\n",
       " 1.049442172050476,\n",
       " 1.0494471788406372,\n",
       " 1.0493615865707397,\n",
       " 0.9245324730873108,\n",
       " 0.9244717955589294,\n",
       " 0.9245195984840393,\n",
       " 0.9244185090065002,\n",
       " 0.9245076179504395,\n",
       " 0.9244663715362549,\n",
       " 0.9243170619010925,\n",
       " 0.6722093820571899,\n",
       " 0.6717312335968018,\n",
       " 0.6721544861793518,\n",
       " 0.6738019585609436,\n",
       " 0.6734118461608887,\n",
       " 0.6734402775764465,\n",
       " 0.6730117797851562,\n",
       " 0.10454306751489639,\n",
       " 0.10630414634943008,\n",
       " 0.11099547147750854,\n",
       " 0.10787973552942276,\n",
       " 0.10195371508598328,\n",
       " 0.10563800483942032,\n",
       " 0.11204907298088074,\n",
       " 0.6113467812538147,\n",
       " 0.6118078827857971,\n",
       " 0.6131083369255066,\n",
       " 0.6117194294929504,\n",
       " 0.6119213104248047,\n",
       " 0.6113260984420776,\n",
       " 0.6138107776641846,\n",
       " 0.16995438933372498,\n",
       " 0.1700158566236496,\n",
       " 0.17485535144805908,\n",
       " 0.17009152472019196,\n",
       " 0.17025677859783173,\n",
       " 0.16579557955265045,\n",
       " 0.17730098962783813,\n",
       " 0.9164835214614868,\n",
       " 0.9164519906044006,\n",
       " 0.91632080078125,\n",
       " 0.916401207447052,\n",
       " 0.9163721203804016,\n",
       " 0.9164198040962219,\n",
       " 0.9163880944252014]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = model.edge_weight.tolist()\n",
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 84940.0234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jqcla\\AppData\\Local\\Temp\\ipykernel_17512\\121057100.py:3: UserWarning: Using a target size (torch.Size([70200])) that is different to the input size (torch.Size([8, 70200])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  mse = F.mse_loss(out, data.y)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "out = model(data)\n",
    "mse = F.mse_loss(out, data.y)\n",
    "print(f'MSE: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_AxesStack' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m data \u001b[39m=\u001b[39m torch_geometric\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mData(x\u001b[39m=\u001b[39mx, edge_index\u001b[39m=\u001b[39medge_index)\n\u001b[0;32m      7\u001b[0m g \u001b[39m=\u001b[39m torch_geometric\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_networkx(data, to_undirected\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m----> 9\u001b[0m nx\u001b[39m.\u001b[39;49mdraw(g)\n",
      "File \u001b[1;32mc:\\Users\\jqcla\\Documents\\GitHub\\Honours-Thesis\\.conda\\lib\\site-packages\\networkx\\drawing\\nx_pylab.py:113\u001b[0m, in \u001b[0;36mdraw\u001b[1;34m(G, pos, ax, **kwds)\u001b[0m\n\u001b[0;32m    111\u001b[0m cf\u001b[39m.\u001b[39mset_facecolor(\u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mif\u001b[39;00m ax \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m cf\u001b[39m.\u001b[39;49m_axstack() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    114\u001b[0m         ax \u001b[39m=\u001b[39m cf\u001b[39m.\u001b[39madd_axes((\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m    115\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: '_AxesStack' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "edge_index = ssp_data.data.edge_index\n",
    "x = ssp_data.data.x\n",
    "\n",
    "data = torch_geometric.data.Data(x=x, edge_index=edge_index)\n",
    "g = torch_geometric.utils.to_networkx(data, to_undirected=True)\n",
    "\n",
    "nx.draw(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "         3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "         6, 7, 7, 7, 7, 7, 7, 7],\n",
       "        [1, 2, 3, 4, 5, 6, 7, 0, 2, 3, 4, 5, 6, 7, 0, 1, 3, 4, 5, 6, 7, 0, 1, 2,\n",
       "         4, 5, 6, 7, 0, 1, 2, 3, 5, 6, 7, 0, 1, 2, 3, 4, 6, 7, 0, 1, 2, 3, 4, 5,\n",
       "         7, 0, 1, 2, 3, 4, 5, 6]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssp_data.data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
